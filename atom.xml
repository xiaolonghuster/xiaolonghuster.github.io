<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>NO WAY OUT | 无往不前</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://xiaolong.li/"/>
  <updated>2021-11-14T15:20:18.070Z</updated>
  <id>http://xiaolong.li/</id>
  
  <author>
    <name>xiaolong</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>分布式系统的 Raft 算法</title>
    <link href="http://xiaolong.li/2021/11/14/Introduction-to-Raft/"/>
    <id>http://xiaolong.li/2021/11/14/Introduction-to-Raft/</id>
    <published>2021-11-14T13:05:46.000Z</published>
    <updated>2021-11-14T15:20:18.070Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p>Raft 算法是一个共识的算法，在集群的分布式状态中，保证每个节点都处于一致的状态。</p><p>Raft 算法主要可以分为两个阶段：</p><blockquote><ol><li>领导者选举阶段</li><li>日志复制(数据同步)阶段</li></ol></blockquote><a id="more"></a><p>Raft 算法中的服务器节点只有 3 种状态，<strong>Leader（领导人）</strong>，<strong>Follower（跟随者）</strong>，<strong>Candidate（候选人）</strong>。</p><ol><li>Leader（领导者）：接受客户端的读、写请求，协调整个日志的持久化和推进</li><li>Follower（跟随者）：系统启动时默认的角色，一般来说不参与客户端读、写请求，接受 Leader 发送过来的心跳追加日志，在 Leader 挂了之后转变为 Candidate</li><li>Candidate（候选者）：如果当前没有 Leader，Follower 就转变为这个角色，这个角色会向其它节点发起投票请求，如果多数节点同意投票，则晋升为 Leader</li></ol><p>Leader 负责管理集群中的日志复制，在大多数时候 Candidate 这个状态是不存在的，只有当集群中没有 Leader 的时候其他节点才会产生 Candidate，然后 Candidate 会要求其他节点进行投票，获得大多数票数的节点就变为新的 Leader，其他所有节点的状态变为 Follower。</p><p>当客户端有请求进来，Leader 负责接收和处理，并且也只有 Leader 有资格进行这种操作，每一个服务器节点都在维护一个日志。假设客户端发送过来的是一个 add 请求，往服务器添加了一个数据，Leader 会更新它的日志，然后通过 AppendEntries 消息让 Follower 同步这个更新，Leader 会记录 Follower 返回成功的数目，如果超过半数的节点都成功了，Leader 才会通知客户端已经成功 add 了，并且 Leader 会进行日志提交的操作，并且让其他的服务器节点也进行提交。</p><h4 id="Leader-选举机制"><a href="#Leader-选举机制" class="headerlink" title="Leader 选举机制"></a>Leader 选举机制</h4><p><img src="/images/raft/2021-11-14-leader-election.jpg" alt="image" title="Leader 选举"></p><p>可以看出所有节点启动时都是 Follower 状态；在一段时间内如果没有收到来自 Leader 的心跳，从 Follower 切换到 Candidate，发起选举；如果收到超过一半的赞同票（含自己的一票）则切换到 Leader 状态；如果发现其他节点比自己更新，则主动切换到 Follower。<br>总之，系统中最多只有一个 Leader，如果在一段时间里发现没有 Leader，则大家通过选举-投票选出 Leader。Leader 会不停的给 Follower 发心跳消息，表明自己的存活状态。如果 Leader 故障，那么 Follower 会转换成 Candidate，重新选出 Leader。</p><h5 id="任期-Term"><a href="#任期-Term" class="headerlink" title="任期 - Term"></a>任期 - Term</h5><p>从上面可以看出，Leader 是大家投票选举出来的，每个 Leader 工作一段时间，然后选出新的 Leader 继续负责。在raft协议中，对应的术语叫 term（任期）。</p><p><img src="/images/raft/2021-11-14-term.jpg" alt="image" title="任期"></p><p>term（任期）以选举（election）开始，然后就是一段或长或短的稳定工作期（normal Operation）。从上图可以看到，任期是递增的，这就充当了逻辑时钟的作用；另外，term 3 任期期间没有 Leader，就是说没有选举出 Leader 就结束了，然后会发起新的选举，后面会解释这种 split vote 的情况。</p><h5 id="选举过程详解"><a href="#选举过程详解" class="headerlink" title="选举过程详解"></a>选举过程详解</h5><p><img src="/images/raft/2021-11-14-init-vote.jpg" alt="image" title="初始投票"></p><p>每个节点会维护一个 Term 值，即为当前是第几任领导，初始启动时是第 0 任，每个节点都会随机给一个 TIMEOUT 值，一般在 150ms 到 300ms 之间。当 TIMEOUT 值到达后，还没有收到 Leader 的心跳检测。首先变成 Candidate 的是 TIMEOUT 值先结束的节点，上图为节点 A（TIMEOUT 值是随机的），然后变成 Candidate 后首先会先将自己的 Term + 1，并且先给自己投一票，然后向其他节点发送信息，要求他们进行投票，其他节点会对比自己的 Term 值和被选举者的 Term ，如果小于 被选举者传过来的 Term，则同意其成为 Leader，并将自己的 Term 更新。投票的数量占据所有节点总数一半以上即变为 Leader，如果 A 节点成功变为了 Leader，那么它会向其他节点按一定频率发送心跳检测，如果其他节点发现发送心跳检测的 A 节点的 Term 是大于或者等于当前它节点维护的 Term 的，他就会更新 Term 并且成为 A 的追随者。</p><p>上面已经说过，如果 Follower 在 election timeout 内没有收到来自 Leader 的心跳（也许此时还没有选出 Leader；也许leader挂了；也许 Leader 与该 Follower 之间网络故障），则会主动发起选举。步骤如下：</p><ol><li>增加节点本地的 current term ，切换到candidate状态</li><li>投自己一票</li><li>并行给其他节点发送 RequestVote RPCs</li><li>等待其他节点的回复</li></ol><p>在这个过程中，根据来自其他节点的消息，可能出现三种结果</p><ol><li>收到大多数的同意投票（含自己的一票），则赢得选举，成为 Leader</li><li>被告知别人已当选，那么自行切换到 Follower</li><li>一段时间内没有收到大多数的同意投票，则保持 Candidate 状态，重新发出选举</li></ol><blockquote><p>第一种情况，赢得了选举之后，新的 Leader 会立刻给所有节点发消息，广而告之，避免其余节点触发新的选举。在这里，先回到投票者的视角，投票者如何决定是否给一个选举请求投票，有以下约束：</p></blockquote><ol><li>在任一任期内，单个节点最多只能投一票</li><li>候选人知道的信息不能比自己的少</li><li>first-come-first-served 先来先得</li></ol><blockquote><p>第二种情况，比如有三个节点A B C。A B 同时发起选举，而 A 的选举消息先到达 C，C 给 A 投了一票，当 B 的消息到达 C 时，已经不能满足上面提到的第一个约束，即 C 不会给 B 投票，而 A 和 B 显然都不会给对方投票。A 胜出之后，会给 B,C 发心跳消息，节点 B 发现节点 A 的 term 不低于自己的 term，知道有已经有 Leader 了，于是转换成 Follower。</p></blockquote><blockquote><p>第三种情况，没有任何节点获得大多数节点投票，比如下图这种情况：</p></blockquote><p><img src="/images/raft/2021-11-14-vote-term.jpg" alt="image" title="初始投票"></p><p>总共有四个节点，Node C、Node D 同时成为了 Candidate，进入了term 4，但 Node A 投了 Node D 一票，Node B 投了 Node C 一票，这就出现了平票 split vote 的情况。这个时候所有节点会一直等，直到超时后重新发起选举。如果出现平票的情况，那么就延长了系统不可用的时间（没有 Leader 是不能处理客户端写请求的），因此 raft 引入了 randomized election timeouts 来尽量避免平票情况。同时，leader-based 共识算法中，节点的数目都是奇数个，尽量保证大多数节点的出现。</p><p>关于选举还有其它一些规则：</p><ol><li>针对 Follower</li></ol><p>如果在超过选举超时时间的情况之前都没有收到 Leader 的心跳，或者是 Candidate 请求投票的，就自己变成 Candidate;</p><ol start="2"><li>针对 Candidate</li></ol><p>开始选举后的动作如下：自增当前的任期号（current Term）; 给自己投票; 重置选举超时计时器;发送请求投票的 RPC 给其他所有服务器;<br>收到响应后的规则：如果接收到大多数服务器的选票，那么就变成 Leader；如果接收到来自新的 Leader 的心跳信息，则转变成 Leader；如果选举过程超时，再次发起一轮选举; </p><ol start="3"><li>针对 Leader</li></ol><p>一旦成为 Leader：发送空的附加日志 RPC（心跳）给其他所有的服务器；在一定的空余时间之后不停的重复发送，以阻止跟随者超时。</p><h4 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h4><p>当有了 Leader，系统应该进入对外工作期了。客户端的一切请求来发送到 Leader，Leader 来调度这些并发请求的顺序，并且保证 Leader 与 Followers 状态的一致性。raft 中的做法是，将这些请求以及执行顺序告知 Followers。Leader 和 Followers 以相同的顺序来执行这些请求，保证状态一致。</p><h5 id="复制状态机"><a href="#复制状态机" class="headerlink" title="复制状态机"></a>复制状态机</h5><h5 id="请求完整流程"><a href="#请求完整流程" class="headerlink" title="请求完整流程"></a>请求完整流程</h5><p>当系统（Leader）收到一个来自客户端的写请求，到返回给客户端，整个过程从 Leader 的视角来看会经历以下步骤：</p><ol><li>leader append log entry</li><li>leader issue AppendEntries RPC in parallel</li><li>leader wait for majority response</li><li>leader apply entry to state machine</li><li>leader reply to client</li><li>leader notify follower apply log</li></ol><p>可以看到日志的提交过程有点类似两阶段提交 (2PC)，不过与 2PC 的区别在于，Leader 只需要大多数（majority）节点的回复即可，这样只要超过一半节点处于工作状态则系统就是可用的。</p><p>日志在每个节点上是状态如下图：</p><p><img src="/images/raft/2021-11-14-node-log.jpg" alt="image" title="节点日志状态"></p><h5 id="特殊状态下的复制"><a href="#特殊状态下的复制" class="headerlink" title="特殊状态下的复制"></a>特殊状态下的复制</h5><p>正常来说客户端一个请求过来，领导者接收，更新日志，然后通知其他节点进行更新，接收到大多数成功的信息后，就告诉客户端成功，提交日志，让其他节点也提交日志。再看看比较特殊或者极端的情况。</p><blockquote><p>特殊情况1：假设现在有A,B,C三个节点，领导者A接收了一个add请求，现在自己日志add了，然后发送信息让节点B和C也add到日志了。这个时候领导者A宕机了，也就是说接收不到其他节点的成功信息，不能进行commit操作，那咋办？这个add操作还有效吗？现在B的TIMEOUT时间为150ms，C的TIMEOUT时间为160ms，所以B先变成候选人发起投票，C给B投票（如果在请求达到C之前，C也变成候选人，就等待下一次选举呗，先TIMEOUT的再次Term + 1，这里假设C还没有变为候选人），B变为了领导者，这个时候B和C都存在有下标未更新的日志8（如上图），但是Raft算法要求领导者不能删除或者覆盖自己的日志文件，所以新领导者B是不会删除下标未更新的日志8，并且会履行原来A的职责让追随者们更新日志8，但不会进行commit操作，只有在下一次客户端请求进来对日志进行操作时，让追随者们更新日志9，领导者B得到大多数的成功信息后，才会把两个日志都进行一个commit操作。</p></blockquote><blockquote><p>特殊情况2：现在有A,B,C三个节点，领导者A接收了一个add请求，现在自己日志add了，然后发送信息让节点B进行更新，还没对节点C发送，这个时候领导者A挂了咋办？如果这时候还是C先到了过期时间，C向B发送了投票请求会发生什么？因为Raft算法要求新的领导者需要更具有完整性的日志，所以会拒绝向C进行投票，会等待下一次B自己选举的时候向C发送投票请求。</p></blockquote><blockquote><p>特殊情况3：如果有A,B,C,D,E五个节点，A为领导者，接收了一个请求，让B更新了，还没有让C,D,E更新就宕机了，这个时候还是C先TIMEOUT了，会发生什么？这个和特殊情况2有什么不同？特殊情况2的时候A和B是已经存在有日志更新了，占据了绝大多数；但是在特殊情况3更新日志的情况只是占据少数，如果这个时候让没有更新日志的C来发起投票，那么C,D,E都会投给C，而B会拒绝投给C，但是C也拿到了绝大多数的票数，所以当选领导者，并且会检查其他节点的日志是否是最新的了，发现B存在它没有的日志，领导者首先不会去理会，在下一次进行更新的时候，因为会维护一个日志的index，并且是按照领导者index来执行，所以B更新的日志会被覆盖。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Raft 算法是一个共识的算法，在集群的分布式状态中，保证每个节点都处于一致的状态。&lt;/p&gt;
&lt;p&gt;Raft 算法主要可以分为两个阶段：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;领导者选举阶段&lt;/li&gt;
&lt;li&gt;日志复制(数据同步)阶段&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="数据一致性" scheme="http://xiaolong.li/categories/%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    
    
      <category term="Raft" scheme="http://xiaolong.li/tags/Raft/"/>
    
      <category term="选举" scheme="http://xiaolong.li/tags/%E9%80%89%E4%B8%BE/"/>
    
      <category term="数据同步" scheme="http://xiaolong.li/tags/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/"/>
    
  </entry>
  
  <entry>
    <title>数据一致性算法</title>
    <link href="http://xiaolong.li/2021/11/10/Data-Consistency-Algorithm/"/>
    <id>http://xiaolong.li/2021/11/10/Data-Consistency-Algorithm/</id>
    <published>2021-11-10T15:53:13.000Z</published>
    <updated>2021-11-11T08:37:36.773Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p>Zab（Zookeeper 采用的一致性协议）、或 Paxos 算法来保证 kafka 副本的数据一致性，而是采用另一套 ISR 副本管理机制来保证数据一致性呢？</p><p>redis raft协议数据一致性</p><h4 id="Zab-协议-广播模式"><a href="#Zab-协议-广播模式" class="headerlink" title="Zab 协议 - 广播模式"></a>Zab 协议 - 广播模式</h4><p>客户端每发送一个更新请求，ZooKeeper 都会生成一个全局唯一的递增编号，这个编号反映了所有事务操作的先后顺序，这个唯一编号就是事务 ID(ZXID)，只有更新请求才算是事务请求。<br>为保证按照事务的 ZXID 先后顺序来处理，Leader服务器会分别为每个 Follower 服务器创建一个队列，并将事务的先后顺序放入队列中，并按照 FIFO 的策略进行消息发送。收到需要处理的事务后，Follower 服务器会首先以事务日志的形式写入服务器的磁盘中，写入成功后会向 Leader 服务器发送 ACK 响应。当 Leader 服务器收到超过一半的 Follower 服务器的 ACK 响应后，会向所有 Follower 服务器广播 Commit 消息，收到 Commit 消息的 Follower 服务器也会完成对事务的提交。<br>如果接收到事务请求的是 Follower 服务器，它会将请求转发给 Leader 服务器处理。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;p&gt;Zab（Zookeeper 采用的一致性协议）、或 Paxos 算法来保证 kafka 副本的数据一致性，而是采用另一套 ISR 副本管理机制来保证数据一致性呢？&lt;/p&gt;
&lt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Introduction-to-RocketMQ</title>
    <link href="http://xiaolong.li/2021/10/29/Introduction-to-RocketMQ/"/>
    <id>http://xiaolong.li/2021/10/29/Introduction-to-RocketMQ/</id>
    <published>2021-10-29T01:19:07.000Z</published>
    <updated>2021-10-29T01:19:07.079Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Kafka 核心架构机制总结</title>
    <link href="http://xiaolong.li/2021/10/28/Introduction-to-Kafka/"/>
    <id>http://xiaolong.li/2021/10/28/Introduction-to-Kafka/</id>
    <published>2021-10-28T01:54:03.000Z</published>
    <updated>2021-11-11T08:16:20.429Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p>Kafka 是一个分布式流平台。是一种高吞吐量的分布式发布订阅消息系统。</p><p>消息中间件一般支持两种模式的队列：</p><blockquote><p>一是消息队列模式<br>二是发布订阅 (Pub-Sub) 模式</p></blockquote><p>Kafka 是发布订阅模式的轻量级消息系统、流平台。</p><p>这个系统需要满足如下三个特性：</p><ol><li>能够对流记录（每条消息）进行发布、订阅。</li><li>能够支持容错地持久化每一条流记录。（注：采用时间复杂度O(1)的磁盘存储结构，即使TB级别以上的数据也可以常数时间访问）</li><li>能够及实地处理每一条实时的流记录消息。</li></ol><a id="more"></a><h4 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h4><ol><li>Broker</li></ol><p>即代理服务器，kafka 部署在集群中的多台机器上，其中的每一台服务器即 Broker，它代表 kafka 的一个实例或节点，多个 Broker 构成一个 kafka 集群。</p><ol start="2"><li>Topic</li></ol><p>即话题，生产或消费流记录（消息），都需要指定特定的 Topic，一般将同一业务数据、同一类型数据写入同一 Topic。</p><ol start="3"><li>Partition</li></ol><p>即分区，因为一个 Topic 下可能会有大量的数据，一个 Broker 可能存不下，故一个 Topic 可以有多个分区，相当于把一个大流数据集分为多份，分别存在隶属于同一个 Topic 下的不同分区中。<br>（注：Topic 是逻辑概念，Partition 是物理概念，每个分区对应于一个物理文件夹，存储分区数据及索引文件）</p><ol start="4"><li>Producer</li></ol><p>即生产者，向 Broker 某一 Topic 主题发送数据的客户端。</p><ol start="5"><li>Consumer</li></ol><p>即消费者，消费指定 Topic 下的数据。</p><ol start="6"><li>Consumer Group</li></ol><p>即消费者组，每个 Consumer 隶属于某个特定的 Consumer Group，Producer 将一条消息发送给所有的 Consumer Group，但最终只能被 Consumer Group 下的唯一的一个 Consumer 消费。<br>（注：分组的目的是为了加快读取速度）</p><ol start="7"><li>Replication</li></ol><p>即副本，一个 Partition 分区可以有多个副本，存在不同的 Broker 中，提供容错保证。</p><blockquote><p>一个 Topic 可以被多个 Consumer Group 订阅，但是只能被其中的一个 Consumer 消费。这里 Consumer Group A 和 Consumer Group B 都订阅了 Topic 1 和 Topic 2。在Consumer Group 中所有 Consumer 是竞争关系，一个流记录（消息）只能被一个 Consumer 消费。</p></blockquote><h4 id="如何保证百万级写入速度"><a href="#如何保证百万级写入速度" class="headerlink" title="如何保证百万级写入速度"></a>如何保证百万级写入速度</h4><p>Kafka 底层的页缓存技术的使用，磁盘顺序写的思路，以及零拷贝技术的运用是做到每秒几十万的吞吐量的保证。</p><h5 id="页缓存技术-amp-磁盘顺序写（生产端）"><a href="#页缓存技术-amp-磁盘顺序写（生产端）" class="headerlink" title="页缓存技术 &amp; 磁盘顺序写（生产端）"></a>页缓存技术 &amp; 磁盘顺序写（生产端）</h5><p>由于 Kafka 每次接收到数据都会往磁盘上写，如果把数据基于磁盘来存储，频繁的往磁盘文件里写数据，那么无疑这个写操作的性能会非常差，无法达到百万级别的效率。</p><p>为了保证数据写入性能，Kafka 采取 <strong>基于操作系统的页缓存来实现文件写入</strong> 。操作系统本身有一层缓存，叫做 page cache，是在内存里的缓存，也可以称之为 os cache，意思就是操作系统自己管理的缓存。当写入磁盘文件的时候，可以直接写入 os cache 里，也就是仅仅写入内存中，接下来由操作系统自己决定什么时候把 os cache 里的数据真的刷入磁盘文件中。仅仅这一个步骤，就可以将磁盘文件写性能提升很多了，因为其实这里相当于是在写内存，不是在写磁盘。</p><p><img src="/images/kafka/2021-11-10-write-page-cache.png" alt="image" title="Kafka 消息写入机制"></p><p>还有一个保证 kafka 有百万级别写入数据的关键点是 <strong>磁盘顺序写</strong> 技术，仅仅将数据追加到文件的末尾，不是在文件的随机位置来修改数据。</p><p>所以 Kafka 在写数据的时候，基于以下两个方面实现写入数据的超高性能：</p><blockquote><ol><li><p>基于操作系统层面的 page cache 来写数据，所以性能很高，本质就是在写内存。</p></li><li><p>采用磁盘顺序写的方式，所以即使数据刷入磁盘的时候，性能也是极高的，和写内存是差不多的。</p></li></ol></blockquote><h5 id="零拷贝（消费端）"><a href="#零拷贝（消费端）" class="headerlink" title="零拷贝（消费端）"></a>零拷贝（消费端）</h5><p>Kafka 在消费数据的时候实际上就是要从磁盘文件里读取某条数据然后发送给下游的消费者，这里如果频繁的进行磁盘的读写操作，无疑性能也是级低的。</p><p>Kafka 为了解决这个问题，在读数据的时候是引入 <strong>零拷贝技术</strong>。</p><p>也就是直接让操作系统的 cache 中的数据发送到网卡后传输给下游的消费者，中间跳过了两次拷贝数据的步骤，Socket 缓存中仅仅会拷贝一个描述符过去，不会拷贝数据到 Socket 缓存。</p><p><img src="/images/kafka/2021-11-10-read-zero-copy.png" alt="image" title="Kafka 消息消费机制"></p><p>通过零拷贝技术，就不需要把 os cache 里的数据拷贝到应用缓存，再从应用缓存拷贝到 Socket 缓存了，两次拷贝都省略了，所以叫做零拷贝。</p><p>对 Socket 缓存仅仅就是拷贝数据的描述符过去，然后数据就直接从 os cache 中发送到网卡上去了，这个过程大大的提升了数据消费时读取文件数据的性能。</p><p>而且大家会注意到，在从磁盘读数据的时候，会先看看 os cache 内存中是否有，如果有的话，其实读数据都是直接读内存的。</p><p>如果kafka集群经过良好的调优，可以使得大量的数据都是直接写入 os cache 中，然后读数据的时候也是从 os cache 中读。</p><p>相当于是 Kafka 完全基于内存提供数据的读写操作，所以这个整体性能会极其的高。</p><h4 id="如何做到不丢失数据"><a href="#如何做到不丢失数据" class="headerlink" title="如何做到不丢失数据"></a>如何做到不丢失数据</h4><blockquote><ol><li>对kafka进行限速，平滑流量</li><li>启用重试机制，重试间隔时间设置长一些</li><li>Kafka 设置 acks=all，即需要相应的所有处于 ISR 的分区都确认收到该消息后，才算发送成功。</li></ol></blockquote><h5 id="Kafka-的-ISR-机制"><a href="#Kafka-的-ISR-机制" class="headerlink" title="Kafka 的 ISR 机制"></a>Kafka 的 ISR 机制</h5><p>ISR 机制是 Kafka 集群保证高可用的核心机制，这个机制简单来说，就是会自动给每个 Partition 维护一个 ISR 列表，这个列表里一定会有 Leader，然后还会包含跟 Leader 保持同步的 Follower。也就是说，只要 Leader 的某个 Follower 一直跟他保持数据同步，那么就会存在于 ISR 列表里。但是如果 Follower 因为自身发生一些问题，导致不能及时的从 Leader 同步数据过去，那么这个 Follower 就会被认为是 “out-of-sync”，被从 ISR 列表里踢出去。</p><blockquote><p>在做主备切换时，直接且只允许从 ISR 集合中选取将要转正的副本即可</p></blockquote><h5 id="核心关键点"><a href="#核心关键点" class="headerlink" title="核心关键点"></a>核心关键点</h5><ol><li>必须要求至少一个 Follower 在 ISR 列表里</li><li>每次写入数据的时候，要求 Leader 写入成功以外，至少保证 ISR 里有一个 Follower 也写成功</li></ol><h4 id="如何做到不重复消费"><a href="#如何做到不重复消费" class="headerlink" title="如何做到不重复消费"></a>如何做到不重复消费</h4><p>生产者不重复生产消息，精确一次，<br>消费者不重复消费消息，精确一次，业务去重</p><p>首先要了解的是 message delivery semantic 也就是消息传递语义。这是一个通用的概念，也就是消息传递过程中消息传递的保证性。</p><p>分为三种：</p><ol><li>最多一次（at most once）: 消息可能丢失也可能被处理，但最多只会被处理一次。</li></ol><p>可能丢失 不会重复</p><ol start="2"><li>至少一次（at least once）: 消息不会丢失，但可能被处理多次。</li></ol><p>可能重复 不会丢失</p><ol start="3"><li>精确传递一次（exactly once）: 消息被处理且只会被处理一次。</li></ol><p>不丢失 不重复 就一次</p><p>而kafka其实有两次消息传递，一次生产者发送消息给kafka，一次消费者去kafka消费消息。</p><p>两次传递都会影响最终结果，两次都是精确一次，最终结果才是精确一次。两次中有一次会丢失消息，或者有一次会重复，那么最终的结果就是可能丢失或者重复的。</p><p>去重问题：消息可以使用唯一id标识</p><blockquote><p>保证不重复消费：落表（主键或者唯一索引的方式，避免重复数据）<br>业务逻辑处理（选择唯一主键存储到Redis或者mongdb中，先查询是否存在，若存在则不处理；若不存在，先插入Redis或Mongdb,再进行业务逻辑处理）</p></blockquote><h4 id="高可用策略"><a href="#高可用策略" class="headerlink" title="高可用策略"></a>高可用策略</h4><p>kafka 使用 ISR 副本管理机制来保证其高可用性。首先需要明确 kafka 副本基本管理单位是 Partition 分区，如果我们指定了多个副本策略，则这些副本里只有一个为主副本（Leader），其他为次级副本 （Follower），所有读写均和主副本来响应。<br>ISR 具体运行机制是：将所有的次级副本（偶数）放到两个集合，其中一个集合被称为 ISR 集合，该集合里的数据始终与主节点数据保持一致，数据写入时，只有 ISR 集合中全部成功写入才算写入成功，在做主备切换时，直接且只允许从 ISR集合中选取将要转正的副本即可。</p><p>那么为何不采用 Zab（Zookeeper 采用的一致性协议）、或 Paxos 算法来保证 kafka 副本的数据一致性，而是采用另一套 ISR 副本管理机制来保证数据一致性呢？</p><p>原因其实很简单，因为在相同的副本容错条件下， ISR 机制可以维护更少的数据副本。比如 ISR 集合大小为 n+1（1主，n副，n为偶数），那么最多可以允许n个副本故障，而对于其他基于投票的一致性算法来说，则需要 2n + 1 个副本才能达到相同的容错性。</p><h4 id="选举规则"><a href="#选举规则" class="headerlink" title="选举规则"></a>选举规则</h4><p>Kafka 的 Leader 选举思路很简单，基于上述提到的 ISR 列表，当宕机后会从所有副本中顺序查找，如果查找到的副本在 ISR 列表中，则当选为 Leader。另外还要保证前任 Leader 已经是退位状态了，否则会出现脑裂情况（有两个 Leader ）。</p><h4 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h4><ol><li>多少个副本才算够用？</li></ol><p>副本肯定越多越能保证Kafka的高可用，但越多的副本意味着网络、磁盘资源的消耗更多，性能会有所下降，通常来说副本数为3即可保证高可用，极端情况下将 replication-factor 参数调大即可。</p><ol start="2"><li>Follower 和 Leader 之间没有完全同步怎么办？</li></ol><p>Follower 和 Leader 之间并不是完全同步，但也不是完全异步，而是采用一种 ISR 机制（ In-Sync Replica）。每个 Leader 会动态维护一个 ISR 列表，该列表里存储的是和 Leader 基本同步的 Follower。如果有 Follower 由于网络、GC 等原因而没有向 Leader 发起拉取数据请求，此时 Follower 相对于 Leader 是不同步的，则会被踢出 ISR 列表。所以说，ISR 列表中的 Follower 都是跟得上 Leader 的副本。</p><ol start="3"><li>Kafka 的 offset 机制？</li></ol><p>由于 Consumer 在消费过程中可能会出现断电宕机等故障，Consumer 恢复后，需要从故障前的位置继续消费。所以 Consumer 需要实时记录自己消费到了哪个 Offset，以便故障恢复后继续消费。</p><p>Kafka 0.9 版本之前，Consumer 默认将 Offset 保存在 Zookeeper 中，从 0.9 版本开始，Consumer 默认将 Offset 保存在 Kafka 一个内置的 Topic 中，该 Topic 为 __consumer_offsets。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kafka 是一个分布式流平台。是一种高吞吐量的分布式发布订阅消息系统。&lt;/p&gt;
&lt;p&gt;消息中间件一般支持两种模式的队列：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一是消息队列模式&lt;br&gt;二是发布订阅 (Pub-Sub) 模式&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Kafka 是发布订阅模式的轻量级消息系统、流平台。&lt;/p&gt;
&lt;p&gt;这个系统需要满足如下三个特性：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;能够对流记录（每条消息）进行发布、订阅。&lt;/li&gt;
&lt;li&gt;能够支持容错地持久化每一条流记录。（注：采用时间复杂度O(1)的磁盘存储结构，即使TB级别以上的数据也可以常数时间访问）&lt;/li&gt;
&lt;li&gt;能够及实地处理每一条实时的流记录消息。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>分布式锁的 Redisson 实现</title>
    <link href="http://xiaolong.li/2021/10/18/Redisson-for-Distributed-lock/"/>
    <id>http://xiaolong.li/2021/10/18/Redisson-for-Distributed-lock/</id>
    <published>2021-10-18T06:36:51.000Z</published>
    <updated>2021-10-18T12:09:12.672Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p>本文主要介绍 Redisson 如何实现分布式锁的原理</p><a id="more"></a><h4 id="高效分布式锁"><a href="#高效分布式锁" class="headerlink" title="高效分布式锁"></a>高效分布式锁</h4><p>在设计分布式锁的时候，应该考虑分布式锁至少要满足的一些条件，同时考虑如何高效的设计分布式锁，以下几点是必须要考虑的。</p><h5 id="互斥"><a href="#互斥" class="headerlink" title="互斥"></a>互斥</h5><p>在分布式高并发的条件下，我们最需要保证，同一时刻只能有一个线程获得锁，这是最基本的一点。</p><h5 id="防止死锁"><a href="#防止死锁" class="headerlink" title="防止死锁"></a>防止死锁</h5><p>在分布式高并发的条件下，比如有个线程获得锁的同时，还没有来得及去释放锁，就因为系统故障或者其它原因使它无法执行释放锁的命令,导致其它线程都无法获得锁，造成死锁。</p><p>所以分布式非常有必要设置锁的有效时间，确保系统出现故障后，在一定时间内能够主动去释放锁，避免造成死锁的情况。</p><h5 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h5><p>对于访问量大的共享资源，需要考虑减少锁等待的时间，避免导致大量线程阻塞。</p><p>所以在锁的设计时，需要考虑两点。</p><ol><li>锁的颗粒度要尽量小。比如你要通过锁来减库存，那这个锁的名称你可以设置成是商品的 ID，而不是任取名称。这样这个锁只对当前商品有效，锁的颗粒度小。</li><li>锁的范围尽量要小。比如只要锁 2 行代码就可以解决问题的，那就不要去锁 10 行代码了。</li></ol><h5 id="重入"><a href="#重入" class="headerlink" title="重入"></a>重入</h5><p>我们知道 ReentrantLock 是可重入锁，那它的特点就是：同一个线程可以重复拿到同一个资源的锁。重入锁非常有利于资源的高效利用。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要介绍 Redisson 如何实现分布式锁的原理&lt;/p&gt;
    
    </summary>
    
      <category term="分布式锁" scheme="http://xiaolong.li/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    
    
      <category term="Redis" scheme="http://xiaolong.li/tags/Redis/"/>
    
      <category term="Distributed-lock" scheme="http://xiaolong.li/tags/Distributed-lock/"/>
    
      <category term="Redisson" scheme="http://xiaolong.li/tags/Redisson/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 索引及优化技巧</title>
    <link href="http://xiaolong.li/2021/09/16/mysql-index/"/>
    <id>http://xiaolong.li/2021/09/16/mysql-index/</id>
    <published>2021-09-16T11:17:59.000Z</published>
    <updated>2021-09-16T14:23:28.586Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h4 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h4><p>MySQL 性能优化包括很多方面，比如数据库设计、参数配置(软&amp;硬)、sql语句、读写分离、分表技术（水平拆分、垂直拆分）等，完整的 MySQL 优化需要很深的功底，掌握这些知识不是一朝一夕可以完成的事情。本文章主要针对 sql 语句优化中的索引优化开展。</p><a id="more"></a><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><h5 id="什么是索引？"><a href="#什么是索引？" class="headerlink" title="什么是索引？"></a>什么是索引？</h5><p>MySQL 官方对索引的定义：索引是帮助 MySQL 高效获取数据的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。我们可以理解索引就是一本书的目录，它会让你更快的找到需要的内容。</p><h5 id="为什么要用索引？"><a href="#为什么要用索引？" class="headerlink" title="为什么要用索引？"></a>为什么要用索引？</h5><p>在无索引的情况下，MySQL 会扫描整张表来查找符合 sql 条件的记录，其时间开销与表中数据量呈正相关，使用索引主要为了加快查询速度和保证数据的唯一性。</p><h5 id="索引种类"><a href="#索引种类" class="headerlink" title="索引种类"></a>索引种类</h5><p>从数据结构角度： </p><ol><li>B-Tree树索引(O(log(n)))</li><li>hash索引O(1)</li><li>fulltext索引 </li><li>R-Tree索引 </li></ol><p>从物理存储角度： </p><ol><li>聚集索引（clustered index） </li><li>非聚集索引（non-clustered index） </li></ol><p>从逻辑角度： </p><ol><li>主键索引：主键索引是一种特殊的唯一索引，不允许有空值 </li><li>普通索引或者单列索引 </li><li>多列索引（复合索引）：复合索引指多个字段上创建的索引</li><li>唯一索引或者非唯一索引 </li><li>空间索引：空间索引是对空间数据类型的字段建立的索引，MYSQL 中的空间数据类型有4种，分别是 GEOMETRY、POINT、LINESTRING、POLYGON。MYSQL 使用 SPATIAL 关键字进行扩展，使得能够用于创建正规索引类型的语法创建空间索引。创建空间索引的列，必须将其声明为 NOT NULL</li></ol><h5 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点:"></a>优缺点:</h5><p>优点：</p><ol><li>可以通过建立唯一索引或者主键索引,保证数据库表中每一行数据的唯一性</li><li>建立索引可以大大提高检索的数据,以及减少表的检索行数</li><li>在表连接的连接条件可以加速表与表直接的相连 4.减少查询中分组和排序的时间 5.建立索引,在查询中使用索引可以提高性能</li></ol><p>缺点：</p><ol><li>在创建索引和维护索引会耗费时间,随着数据量的增加而增加</li><li>索引文件会占用物理空间,除了数据表需要占用物理空间之外,每一个索引还会占用一定的物理空间</li></ol><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>此处不进行描述，具体参考：<a href="http://blog.codinglabs.org/articles/theory-of-mysql-index.html" target="_blank" rel="noopener">http://blog.codinglabs.org/articles/theory-of-mysql-index.html</a></p><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><h5 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h5><table><thead><tr><th>场景</th><th>描述</th></tr></thead><tbody><tr><td>全值匹配</td><td>查询条件和索引列完全匹配，如：联合索引(a,b),查询 a=? and b=?</td></tr><tr><td>匹配最左前缀</td><td>查询条件中的所有字段需要从左边起按顺序出现在多列索引中，如：联合索引(a,b),查询 a=?</td></tr><tr><td>匹配列前缀</td><td>查询条件只匹配某一索引列的开头部分，如：联合索引(a,b),查询 a like ’?%’</td></tr><tr><td>匹配范围值</td><td>查询条件匹配索引列的范围，如：联合索引(a,b),查询 a &gt; ?</td></tr><tr><td>精确匹配某一列并范围匹配另外一列</td><td>如：联合索引(a,b),查询 a =? and b&gt;?</td></tr><tr><td>多表做join操作时</td><td>如：表t1,索引(a),表t2,索引(b),查询 t1 left join t2 on t2.b = t1.a</td></tr><tr><td>order by操作时</td><td>如：联合索引(a,b),查询 a = ? order by b desc</td></tr><tr><td>group by操作时</td><td>如：联合索引(a,b),查询 a = ? group by b desc</td></tr></tbody></table><h5 id="explain介绍"><a href="#explain介绍" class="headerlink" title="explain介绍"></a>explain介绍</h5><p>和大家普及一下如何查看sql的索引使用情况，即sql的执行计划： Explain详解</p><table><thead><tr><th>属性名称</th><th>说明</th></tr></thead><tbody><tr><td>id</td><td>SELECT识别符。这是SELECT的查询序列号</td></tr><tr><td>select_type</td><td>SELECT类型,可以为以下任何一种: SIMPLE:简单SELECT(不使用UNION或子查询) PRIMARY:最外面的SELECT UNION:UNION中的第二个或后面的SELECT语句 DEPENDENT UNION:UNION中的第二个或后面的SELECT语句,取决于外面的查询 UNION RESULT:UNION 的结果 SUBQUERY:子查询中的第一个SELECT DEPENDENT SUBQUERY:子查询中的第一个SELECT,取决于外面的查询 DERIVED:导出表的SELECT(FROM子句的子查询)</td></tr><tr><td>table</td><td>输出的行所引用的表</td></tr><tr><td>type</td><td>联接类型。下面给出各种联接类型,按照从最佳类型到最坏类型进行排序: system:表仅有一行(=系统表)。这是const联接类型的一个特例。 const:表最多有一个匹配行,它将在查询开始时被读取。因为仅有一行,在这行的列值可被优化器剩余部分认为是常数。const表很快,因为它们只读取一次! eq_ref:对于每个来自于前面的表的行组合,从该表中读取一行。这可能是最好的联接类型,除了const类型。 ref:对于每个来自于前面的表的行组合,所有有匹配索引值的行将从这张表中读取。 ref_or_null:该联接类型如同ref,但是添加了MySQL可以专门搜索包含NULL值的行。 index_merge:该联接类型表示使用了索引合并优化方法。 unique_subquery:该类型替换了下面形式的IN子查询的ref: value IN (SELECT primary_key FROM single_table WHERE some_expr) unique_subquery是一个索引查找函数,可以完全替换子查询,效率更高。 index_subquery:该联接类型类似于unique_subquery。可以替换IN子查询,但只适合下列形式的子查询中的非唯一索引: value IN (SELECT key_column FROM single_table WHERE some_expr) range:只检索给定范围的行,使用一个索引来选择行。 index:该联接类型与ALL相同,除了只有索引树被扫描。这通常比ALL快,因为索引文件通常比数据文件小。 ALL:对于每个来自于先前的表的行组合,进行完整的表扫描。</td></tr><tr><td>possible_keys</td><td>查询可能使用的索引</td></tr><tr><td>key</td><td>查询真正使用到的索引，select_type为index_merge时，这里可能出现两个以上的索引，其他的 select_type 这里只会出现一个</td></tr><tr><td>key_len</td><td>用于处理查询的索引长度</td></tr><tr><td>ref</td><td>显示使用哪个列或常数与key一起从表中选择行</td></tr><tr><td>rows</td><td>查询中应该检索的记录数</td></tr><tr><td>extra</td><td>该列包含MySQL解决查询的详细信息 Distinct:MySQL发现第1个匹配行后,停止为当前的行组合搜索更多的行。 Not exists:MySQL能够对查询进行LEFT JOIN优化,发现1个匹配LEFT JOIN标准的行后,不再为前面的的行组合在该表内检查更多的行。 range checked for each record (index map: #):MySQL没有发现好的可以使用的索引,但发现如果来自前面的表的列值已知,可能部分索引可以使用。 Using filesort:MySQL需要额外的一次传递,以找出如何按排序顺序检索行。 Using index:从只使用索引树中的信息而不需要进一步搜索读取实际的行来检索表中的列信息。 Using temporary:为了解决查询,MySQL需要创建一个临时表来容纳结果。 Using where:WHERE 子句用于限制哪一个行匹配下一个表或发送到客户。 Using sort_union(…), Using union(…), Using intersect(…):这些函数说明如何为index_merge联接类型合并索引扫描。 Using index for group-by:类似于访问表的Using index方式,Using index for group-by表示MySQL发现了一个索引,可以用来查 询GROUP BY或DISTINCT查询的所有列,而不要额外搜索硬盘访问实际的表。</td></tr></tbody></table><h5 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h5><p>一般情况：一次查询至多使用一个索引，即每次查询时，不管建立了多少个索引，最多只会用到其中一个，如：<br>单列索引(a),(b),©,查询 a=? and b=? and c=?，只会用到单列索引(a)。特殊情况：索引合并会使用多个索引，如果执行计划中type列显示index_merge,则说明出现了索引合并；<br>建立索引的列，索引的选择性要高，即指索引中不重复的值的数目（也称基数，a）与整个表该列记录总数（b）的比值，比如一个列表（1,2,2,3），总数是4，不重复值数目为3，选择性为3/4，选择性的取值范围为(0, 1]，这个值越大，表示列中不重复值越多，越适合作为前缀索引，唯一索引（UNIQUE KEY）的选择性是1;<br>sql查询时一定不要出现隐式转换，当产生隐式转换时，查询不走索引，所谓隐式转换，即指where条件语句里，字段属性和赋给的条件，当数据类型不一样，这时候是没法直接比较的，需要进行一致转换,如：单列索引(a),字符类型，查询 a=1 ,这样的查询会把表中的a字段全部转换成整型，并且无法使用索引(a);<br>使用索引需要满足最左前缀原则，如：联合索引(a,b,c),查询 a=?或者a=? and b=? 或者a=? and b=? and c=?可以使用联合索引(a,b,c) ，但是b=?或者c=?或者b=? and c=?不能使用联合索引(a,b,c) ;<br>当查询条件是范围时，范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引，如：联合索引(a,b),查询 a&gt;? and b&gt;?，这样的查询可以用到联合索引中的a部分，b部分没有使用；<br>当查询条件是范围时，范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引，如：联合索引(a,b),查询 a&gt;? and b&gt;?，这样的查询可以用到联合索引中的a部分，b部分没有使用；<br>使用order by进行查询排序时，如果排序字段非索引列，执行计划的extra列会是“Using filesort”；<br>使用group by进行分组查询时，一般是先根据分组字段排序再进行分组，如果分组字段非索引列，执行计划的extra列会是“Using temporary; Using filesort”；<br>查询时优先使用覆盖索引，何为覆盖索引？即指所有数据都可以从索引中得到，而不需要去读物理记录。例如某个联合索引(a,b,c)建立在表tb1 的 a、b、c 列上，那么对于如下的sql 语句select a,b from tb1 where a = ? and b = ? and c =?,mysql可以直接从索引(a,b,c)中获取数据。使用explain 命令输出查询计划，如果extra列是“using index ”那就表示使用的是覆盖索引;<br>查询条件中含有函数或者表达式，mysql不会使用索引，如：索引(a),查询 left(a,6)=?, 同时 !=、&lt;&gt;不走索引，or前后的条件都要有索引整个SQL才会使用索引，只要有一个条件没索引那么整个SQL都不使用索引；<br>每个查询是否使用索引，不仅取决于索引建立是否合适，同时也取决于查询筛选记录占全表记录的大小，优化器会判断利用索引筛选出来的记录是否小于全表记录的30%，如果小于，使用索引，反之不会；<br>mysql不能使用索引中范围条件右边的列，如：联合索引(a,b,c),查询 a=? and b&gt;? and c=?,其中索引的a,b列可以用到，但是c列用不到；<br>索引数据类型选择通常遵循以下指导原则： 1)越小的数据类型通常更好：越小的数据类型通常在磁盘、内存和CPU缓存中都需要更少的空间，处理起来更快。2)简单的数据类型更好：整型数据比起字符，处理开销更小，因为字符串的比较更复杂。在MySQL中，应该用内置的日期和时间数据类型，而不是用字符串来存储时间；3)尽量避免NULL：应该指定列为NOT NULL，除非你想存储NULL。在MySQL中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂，同时NULL存储也是需要占用空间的。应该用0、一个特殊的值或者一个空串代替空值。</p><h4 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h4><ol><li>联合索引(a,b),查询 a=? and b=? 和b=? and a=?,哪个会命中索引？查询a=?和b=?，哪个会使用索引？ </li><li>联合索引(a,b),查询 a&gt;? and b&gt;? 和b&gt;? and a&gt;?, 索引是如何使用的？ </li><li>联合索引(end_time,user_id)，查询select type from um_user_vip_record where user_id =? and end_time &gt; now() order by end_time limit 1，索引的使用情况？ </li><li>以下sql如何优化：  </li><li>联合索引(a,b,c,d),以下查询的索引使用情况 A、where a=? and b=? and d&gt;? and c=? B、where a=? and b=? and d=? order by c C、where a=? and d=? group by c,b D、where a=? and e=? order by b,c E、where a=? and b=? and e=? order by b,c </li></ol><p>注：如何知道具体使用了索引的哪一列，可以根据执行计划的key_len得出！</p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h4&gt;&lt;p&gt;MySQL 性能优化包括很多方面，比如数据库设计、参数配置(软&amp;amp;硬)、sql语句、读写分离、分表技术（水平拆分、垂直拆分）等，完整的 MySQL 优化需要很深的功底，掌握这些知识不是一朝一夕可以完成的事情。本文章主要针对 sql 语句优化中的索引优化开展。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>gRPC 对比 WebSocket</title>
    <link href="http://xiaolong.li/2021/09/16/grpc-vs-websocket/"/>
    <id>http://xiaolong.li/2021/09/16/grpc-vs-websocket/</id>
    <published>2021-09-16T09:45:03.000Z</published>
    <updated>2021-09-16T14:11:41.996Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h4 id="gRPC"><a href="#gRPC" class="headerlink" title="gRPC"></a>gRPC</h4><p>gRPC 是一个远程过程调用框架，默认使用 protobuf3 进行数据的高效序列化与 service 定义，使用 HTTP/2 进行数据传输。 这里讨论的是 <a href="https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md" target="_blank" rel="noopener">gRPC over HTTP/2</a> 协议。</p><p>目前 gRPC 主要被用在微服务通信中，但是因为其优越的性能，它也很契合游戏、loT 等需要高性能低延迟的场景。</p><p>其实从协议先进程度上讲，gRPC 基本全面超越 REST:</p><ol><li>使用二进制进行数据序列化，比 json 更节约流量、序列化与反序列化也更快。</li><li>protobuf3 要求 api 被完全清晰的定义好，而 REST api 只能靠程序员自觉定义。</li><li>gRPC 官方就支持从 api 定义生成代码，而 REST api 需要借助 openapi-codegen 等第三方工具。</li><li>支持 4 种通信模式：一对一(unary)、客户端流、服务端流、双端流。更灵活</li></ol><a id="more"></a><p>只是 <strong>目前 gRPC 对 broswer 的支持仍然不是很好</strong>，如果你需要通过浏览器访问 api，那 gRPC 可能不是你的菜。 如果你的产品只打算面向 App 等可控的客户端，可以考虑上 gRPC。</p><p>对同时需要为浏览器和 APP 提供服务应用而言，也可以考虑 APP 使用 gRPC 协议，而浏览器使用 API 网关提供的 HTTP 接口，在 API 网关上进行 HTTP - gRPC 协议转换。</p><h5 id="gRPC-over-HTTP-2-定义"><a href="#gRPC-over-HTTP-2-定义" class="headerlink" title="gRPC over HTTP/2 定义"></a>gRPC over HTTP/2 定义</h5><p>详细的定义参见官方文档 <a href="https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md" target="_blank" rel="noopener">gRPC over HTTP/2</a> .</p><p>这里是简要说明几点：</p><ol><li>gRPC 完全隐藏了 HTTP/2 本身的 method、headers、path 等语义，这些信息对用户而言完全不可见了。<br>请求统一使用 POST，响应状态统一为 200。只要响应是标准的 gRPC 格式，响应中的 HTTP 状态码将被完全忽略。</li><li>gRPC 定义了自己的 status 状态码、格式固定的 path、还有它自己的 headers。</li></ol><h4 id="WebSocket"><a href="#WebSocket" class="headerlink" title="WebSocket"></a>WebSocket</h4><p>WebSocket 是一个双向通信协议，它在握手阶段采用 HTTP/1.1 协议（暂时不支持 HTTP/2）。</p><p>握手过程如下：</p><ol><li>首先客户端向服务端发起一个特殊的 HTTP 请求，其消息头如下：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /chat HTTP/1.1  // 请求行</span><br><span class="line">Host: server.example.com</span><br><span class="line">Upgrade: websocket  // required</span><br><span class="line">Connection: Upgrade // required</span><br><span class="line">Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ== // required，一个 16bits 编码得到的 base64 串</span><br><span class="line">Origin: http://example.com  // 用于防止未认证的跨域脚本使用浏览器 websocket api 与服务端进行通信</span><br><span class="line">Sec-WebSocket-Protocol: chat, superchat  // optional, 子协议协商字段</span><br><span class="line">Sec-WebSocket-Version: 13</span><br></pre></td></tr></table></figure><ol start="2"><li>如果服务端支持该版本的 WebSocket，会返回 101 响应，响应标头如下：</li></ol><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 <span class="number">101</span> Switching Protocols  // 状态行</span><br><span class="line"><span class="attribute">Upgrade</span>: websocket   // required</span><br><span class="line"><span class="attribute">Connection</span>: Upgrade  // required</span><br><span class="line"><span class="attribute">Sec-WebSocket-Accept</span>: s3pPLMBiTxaQ9kYGzzhZRbK+xOo= // required，加密后的 Sec-WebSocket-Key</span><br><span class="line"><span class="attribute">Sec-WebSocket-Protocol</span>: chat // 表明选择的子协议</span><br></pre></td></tr></table></figure><p>握手完成后，接下来的 TCP 数据包就都是 WebSocket 协议的帧了。</p><p>可以看到，这里的握手不是 TCP 的握手，而是在 TCP 连接内部，从 HTTP/1.1 upgrade 到 WebSocket 的握手。</p><p>WebSocket 提供两种协议：不加密的 ws:// 和 加密的 wss://. 因为是用 HTTP 握手，它和 HTTP 使用同样的端口：ws 是 80（HTTP），wss 是 443（HTTPS）</p><h4 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h4><p>gRPC 实际上并不是比较的相关部分，而是 gRPC 使用 的 HTTP/2 与 WebSockets 进行比较。这里借鉴 InfoQ 上的一篇文章 <a href="https://www.infoq.com/articles/websocket-and-http2-coexist/" target="_blank" rel="noopener">WebSocket 能否在 HTTP/2 中存活下来？</a></p><p>虽然 HTTP/2 提供了很多机制，它并不能完全取代现有的推/流媒体技术的需要。</p><p>关于 HTTP/2 的第一个重要的事情是它并不能替代所有的 HTTP 。verb、状态码和大部分头信息将保持与目前版本一致。HTTP/2 是意在提升数据在线路上传输的效率。</p><p>比较 HTTP/2 和 WebSocket ，可以看到很多类似之处：</p><table><thead><tr><th>-</th><th>HTTP/2</th><th>WebSocket</th></tr></thead><tbody><tr><td>Headers</td><td>Compressed (HPACK)</td><td>None</td></tr><tr><td>Binary</td><td>Yes</td><td>Binary or Textual</td></tr><tr><td>Multiplexing</td><td>Yes</td><td>Yes</td></tr><tr><td>Prioritization</td><td>Yes</td><td>No</td></tr><tr><td>Compression</td><td>Yes</td><td>Yes</td></tr><tr><td>Direction</td><td>CLient/Server + Server Push</td><td>Bidirectional</td></tr><tr><td>Full-duplex</td><td>Yes</td><td>Yes</td></tr></tbody></table><h4 id="如何选择"><a href="#如何选择" class="headerlink" title="如何选择"></a>如何选择</h4><p>WebSockets 肯定会在 HTTP/2 + SSE 的领域中生存下来，主要是因为它是一种已经被很好地应用的技术，并且在非常具体的使用情况下，它比 HTTP/2 更具优势，因为它已经被构建用于具有较少开销(如报头)的双向功能。</p><p>假设你想建立一个大型多人在线游戏，需要来自连接两端的大量消息。在这种情况下，WebSockets 的性能会好很多。</p><p>一般情况下，只要需要客户端和服务器之间的真正 <strong>低延迟</strong> ，接近实时的连接，就使用 WebSocket 。请记住，这可能需要重新考虑如何构建服务器端应用程序，以及将焦点转移到队列事件等技术上。</p><p>如果你使用的方案需要显示实时的市场消息，市场数据，聊天应用程序等，依靠 HTTP/2 + SSE 将为你提供高效的双向通信渠道，同时获得留在 HTTP 领域的各种好处：</p><p>当考虑到与现有 Web 基础设施的兼容性时，WebSocket 通常会变成一个痛苦的源头，因为它将 HTTP 连接升级到完全不同于 HTTP 的协议。</p><p>规模和安全性：Web 组件（防火墙，入侵检测，负载均衡）是以 HTTP 为基础构建，维护和配置的，这是大型/关键应用程序在弹性，安全性和可伸缩性方面更喜欢的环境。</p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;gRPC&quot;&gt;&lt;a href=&quot;#gRPC&quot; class=&quot;headerlink&quot; title=&quot;gRPC&quot;&gt;&lt;/a&gt;gRPC&lt;/h4&gt;&lt;p&gt;gRPC 是一个远程过程调用框架，默认使用 protobuf3 进行数据的高效序列化与 service 定义，使用 HTTP/2 进行数据传输。 这里讨论的是 &lt;a href=&quot;https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;gRPC over HTTP/2&lt;/a&gt; 协议。&lt;/p&gt;
&lt;p&gt;目前 gRPC 主要被用在微服务通信中，但是因为其优越的性能，它也很契合游戏、loT 等需要高性能低延迟的场景。&lt;/p&gt;
&lt;p&gt;其实从协议先进程度上讲，gRPC 基本全面超越 REST:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用二进制进行数据序列化，比 json 更节约流量、序列化与反序列化也更快。&lt;/li&gt;
&lt;li&gt;protobuf3 要求 api 被完全清晰的定义好，而 REST api 只能靠程序员自觉定义。&lt;/li&gt;
&lt;li&gt;gRPC 官方就支持从 api 定义生成代码，而 REST api 需要借助 openapi-codegen 等第三方工具。&lt;/li&gt;
&lt;li&gt;支持 4 种通信模式：一对一(unary)、客户端流、服务端流、双端流。更灵活&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Redis 高可用方案</title>
    <link href="http://xiaolong.li/2021/09/14/High-Availability-for-Redis/"/>
    <id>http://xiaolong.li/2021/09/14/High-Availability-for-Redis/</id>
    <published>2021-09-14T15:24:03.000Z</published>
    <updated>2021-09-16T14:11:58.571Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p>Redis 中为了实现高可用（High Availability，简称 HA ），采用了如下两个方式：</p><ol><li>哨兵( Sentinel )：可以管理多个 Redis 服务器，它提供了监控，提醒以及自动的故障转移的功能。</li><li>复制( Replication )：则是负责让一个 Redis 服务器可以配备多个备份的服务器。</li></ol><blockquote><p>主从模式（Redis 2.8 版本之前的模式）、哨兵 sentinel 模式（Redis 2.8 及之后的模式）、redis cluster模式（Redis 3.0版本之后）</p></blockquote><a id="more"></a><h4 id="主从模式"><a href="#主从模式" class="headerlink" title="主从模式"></a>主从模式</h4><p>同 Mysql 主从复制的原因一样，Redis 虽然读取写入的速度都特别快，但是也会产生读压力特别大的情况。为了分担读压力，Redis 支持主从复制，主从结构可以采用一主多从或者级联结构，Redis 主从复制可以根据是否是全量分为全量同步和增量同步。下图为级联结构。</p><p>全量同步<br>Redis全量复制- -般发生在Slave初始化阶段，这时Slave需 要将Master,上的所有数据都复制-份。具体步骤如下:<br>-从服务器连接主服务器，发送SYNC命令;<br>-主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令;<br>-主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令;<br>-从服务器收到快照文件后丢弃所有旧数据，载入收到的快照;<br>-主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令;<br>-从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令;</p><h4 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h4><h4 id="集群模式"><a href="#集群模式" class="headerlink" title="集群模式"></a>集群模式</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Redis 中为了实现高可用（High Availability，简称 HA ），采用了如下两个方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;哨兵( Sentinel )：可以管理多个 Redis 服务器，它提供了监控，提醒以及自动的故障转移的功能。&lt;/li&gt;
&lt;li&gt;复制( Replication )：则是负责让一个 Redis 服务器可以配备多个备份的服务器。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;主从模式（Redis 2.8 版本之前的模式）、哨兵 sentinel 模式（Redis 2.8 及之后的模式）、redis cluster模式（Redis 3.0版本之后）&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://xiaolong.li/categories/Redis/"/>
    
    
      <category term="高可用" scheme="http://xiaolong.li/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    
      <category term="redis" scheme="http://xiaolong.li/tags/redis/"/>
    
      <category term="哨兵" scheme="http://xiaolong.li/tags/%E5%93%A8%E5%85%B5/"/>
    
  </entry>
  
  <entry>
    <title>Redis 缓存穿透、缓存击穿、缓存雪崩和解决方案</title>
    <link href="http://xiaolong.li/2021/09/04/Redis-Cache-Penetration-Breakdown-Avalanches-and-Solutions/"/>
    <id>http://xiaolong.li/2021/09/04/Redis-Cache-Penetration-Breakdown-Avalanches-and-Solutions/</id>
    <published>2021-09-04T13:42:29.000Z</published>
    <updated>2021-09-04T14:28:40.325Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p>设计一个缓存系统，不得不要考虑的问题就是：缓存穿透、缓存击穿与失效时的雪崩效应。</p><h4 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h4><h5 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h5><blockquote><p>缓存穿透：是指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，进而给数据库带来压力。</p></blockquote><a id="more"></a><h5 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h5><p>解决穿透一般有三种方法：</p><ol><li>如果是非法请求，可以在API入口，对参数进行校验，过滤非法值。</li><li>如果查询数据库为空，可以给缓存设置个空值，或者默认值。但是如有有写请求进来的话，需要更新缓存哈，以保证缓存一致性，同时，最后给缓存设置适当的过期时间。（业务上比较常用，简单有效）</li><li>使用 布隆过滤器 快速判断数据是否存在。即一个查询请求过来时，先通过布隆过滤器判断值是否存在，存在才继续往下查。</li></ol><blockquote><p>布隆过滤器原理：它由初始值为 0 的位图数组和 N 个哈希函数组成。一个对一个 key 进行 N 个 hash 算法获取 N 个值，在比特数组中将这 N 个值散列后设定为 1，然后查的时候如果特定的这几个位置都为 1，那么布隆过滤器判断该 key 存在。</p></blockquote><h4 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h4><h5 id="原因-1"><a href="#原因-1" class="headerlink" title="原因"></a>原因</h5><blockquote><p>缓存雪奔：是指缓存中数据大批量到过期时间，而查询数据量巨大，请求都直接访问数据库，引起数据库压力过大甚至 down 机。</p></blockquote><p>当然，Redis 故障宕机也可能引起缓存雪奔。</p><h5 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h5><ol><li>考虑用加锁或者队列的方式保证缓存的单线程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。</li><li>可以给缓存设置过期时间时加上一个随机值时间，使得每个 key 的过期时间分布开来，不会集中在同一时刻失效。</li><li>Redis 高可用集群。</li></ol><h4 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h4><h5 id="原因-2"><a href="#原因-2" class="headerlink" title="原因"></a>原因</h5><blockquote><p>缓存击穿：是指热点 key 在某个时间点过期的时候，而恰好在这个时间点对这个 Key 有大量的并发请求过来，从而大量的请求打到数据库，进而给数据库带来压力。</p></blockquote><h5 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h5><ol><li>使用互斥锁方案。缓存失效时，不是立即去加载 db 数据，而是先使用某些带成功返回的原子操作命令，如 (Redis的setnx) 去操作，成功则再去加载 db 数据库数据和设置缓存，否则就去重试获取缓存。</li><li>“永不过期”，是指没有设置过期时间，但是热点数据快要过期时，异步线程去更新和设置过期时间。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;设计一个缓存系统，不得不要考虑的问题就是：缓存穿透、缓存击穿与失效时的雪崩效应。&lt;/p&gt;
&lt;h4 id=&quot;缓存穿透&quot;&gt;&lt;a href=&quot;#缓存穿透&quot; class=&quot;headerlink&quot; title=&quot;缓存穿透&quot;&gt;&lt;/a&gt;缓存穿透&lt;/h4&gt;&lt;h5 id=&quot;原因&quot;&gt;&lt;a href=&quot;#原因&quot; class=&quot;headerlink&quot; title=&quot;原因&quot;&gt;&lt;/a&gt;原因&lt;/h5&gt;&lt;blockquote&gt;
&lt;p&gt;缓存穿透：是指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，进而给数据库带来压力。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://xiaolong.li/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://xiaolong.li/tags/Redis/"/>
    
      <category term="缓存穿透" scheme="http://xiaolong.li/tags/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F/"/>
    
      <category term="缓存雪崩" scheme="http://xiaolong.li/tags/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9/"/>
    
      <category term="缓存击穿" scheme="http://xiaolong.li/tags/%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/"/>
    
  </entry>
  
  <entry>
    <title>布隆过滤器</title>
    <link href="http://xiaolong.li/2021/09/01/Introduction-to-Bloom-Filter/"/>
    <id>http://xiaolong.li/2021/09/01/Introduction-to-Bloom-Filter/</id>
    <published>2021-09-01T13:15:31.000Z</published>
    <updated>2021-10-12T07:43:30.497Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><blockquote><p>Data structures are nothing different. They are like the bookshelves of your application where you can organize your data. Different data structures will give you different facility and benefits. To properly use the power and accessibility of the data structures you need to know the trade-offs of using one.</p></blockquote><blockquote class="blockquote-center"><p>不同的数据结构有不同的适用场景和优缺点，你需要仔细权衡自己的需求之后妥善适用它们</p></blockquote><p><strong>布隆过滤器就是践行这句话的代表</strong></p><a id="more"></a><h4 id="什么是布隆过滤器"><a href="#什么是布隆过滤器" class="headerlink" title="什么是布隆过滤器"></a>什么是布隆过滤器</h4><p>布隆过滤器本质上是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure），特点是高效地插入和查询，可以用来告诉你 <strong>某样东西一定不存在或者可能存在</strong>。</p><p>相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。</p><ul><li><p>优点：</p><blockquote><p>不需要存储 key ，空间占用很小<br>高效地插入和查询</p></blockquote></li><li><p>缺点：</p><blockquote><p>返回具有不确定性<br>元素删除相对困难</p></blockquote></li></ul><h4 id="布隆过滤器的原理"><a href="#布隆过滤器的原理" class="headerlink" title="布隆过滤器的原理"></a>布隆过滤器的原理</h4><p>假设有个集合 A，A 中有 n 个元素。利用 k 个哈希散列函数，将 A 中的每个元素映射到一个长度为 a 位的数组 B 中的不同位置上，这些位置上的二进制数均设置为 1 。如果待检查的元素，经过这 k 个哈希散列函数的映射后，发现其 k 个位置上的二进制数全部为 1 ，这个元素很可能属于集合 A ，反之，一定不属于集合 A。</p><h5 id="布隆过滤器的数据结构"><a href="#布隆过滤器的数据结构" class="headerlink" title="布隆过滤器的数据结构"></a>布隆过滤器的数据结构</h5><p>布隆过滤器是一个 bit 向量或者说 bit 数组：</p><p><img src="/images/algorithm/2021-09-01-bloom-origin.jpg" alt="image" title="布隆过滤器原始状态"></p><p>如果要映射一个 key 值到布隆过滤器中，需要使用多个不同的哈希函数生成多个哈希值，并对每个生成的哈希值指向的 bit 位置 1，例如针对值 <strong>Chinese</strong> 和三个不同的哈希函数分别生成了哈希值 1、4、7，则数据结构状态转变为：</p><p><img src="/images/algorithm/2021-09-01-bloom-status-chinese.jpg" alt="image" title="布隆过滤器添加 key 值 Chinese 后的状态"></p><p>现在再存一个 key 值为 <strong>English</strong>，三个哈希函数返回值分别是 2、4、8 ，则数据结构继续变为：</p><p><img src="/images/algorithm/2021-09-01-bloom-status-english.jpg" alt="image" title="布隆过滤器添加 key 值 English 后的状态"></p><blockquote><p>值得注意的是，4 这个 bit 位由于两个值的哈希函数都返回了这个 bit 位，因此它被覆盖了。</p></blockquote><p>现在，</p><ol><li>查询 <strong>Math</strong> 这个 key 值是否存在，如果三个哈希函数返回了 1、5、8 三个值，因为 5 这个 bit 位上的值为 0，说明没有任何一个值映射到这个 bit 位上，因此可以很确定地说 <strong>Math 这个 key 值不存在</strong>。</li><li>查询 <strong>Physics</strong> 这个 key 值是否存在，如果三个哈希函数返回了 1、7、8，检查发现这三个 bit 位上的值均为 1，那么可以说 <strong>Physics</strong> 存在了么？答案是不可以，只能是 <strong>Physics 这个 key 值可能存在</strong>。</li></ol><p>因为随着增加的值越来越多，被置为 1 的 bit 位也会越来越多，这样某个值 <strong>Chemistry</strong> 即使没有被存储过，但是万一哈希函数返回的三个 bit 位都被其他值置位了 1 ，那么程序还是会判断 Chemistry 这个值存在。</p><h5 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h5><blockquote><ol><li>首先需要 k 个 hash 函数，每个函数可以把 key 散列成为 1 个整数。</li><li>初始化时，需要一个长度为 n 比特的数组，每个比特位初始化为 0。</li><li>某个 key 加入集合时，用 k 个 hash 函数计算出k个散列值，并把数组中对应的比特位置为 1。</li><li>判断某个 key 是否在集合时，用 k 个 hash 函数计算出 k 个散列值，并查询数组中对应的比特位，如果所有的比特位都是 1 ，认为在集合中。</li></ol></blockquote><h5 id="支持删除吗"><a href="#支持删除吗" class="headerlink" title="支持删除吗"></a>支持删除吗</h5><p>传统的布隆过滤器并不支持删除操作。但是名为 Counting Bloom filter 的变种可以用来测试元素计数个数是否绝对小于某个阈值，它支持元素删除。</p><h5 id="如何选择哈希函数个数和布隆过滤器长度"><a href="#如何选择哈希函数个数和布隆过滤器长度" class="headerlink" title="如何选择哈希函数个数和布隆过滤器长度"></a>如何选择哈希函数个数和布隆过滤器长度</h5><p>很显然，过小的布隆过滤器很快所有的 bit 位均为 1，那么查询任何值都会返回“可能存在”，起不到过滤的目的了。布隆过滤器的长度会直接影响误报率，布隆过滤器越长其误报率越小。</p><p>另外，哈希函数的个数也需要权衡，个数越多则布隆过滤器 bit 位置位 1 的速度越快，且布隆过滤器的效率越低；但是如果太少的话，那么误报率会变高。</p><blockquote><p>k 为哈希函数个数，m 为布隆过滤器长度，n 为插入的元素个数，p 为误报率</p></blockquote><p>如何选择适合业务的 k 和 m 值：</p><p><img src="/images/algorithm/2021-09-01-bloom-m.jpg" alt="image"></p><p><img src="/images/algorithm/2021-09-01-bloom-k.jpg" alt="image"></p><p>布隆过滤器误报率 p 与位数组大小 m 和集合中插入元素个数 n 的关系图:</p><p><img src="/images/algorithm/2021-09-01-bloom.jpg" alt="image" title="布隆过滤器"></p><h4 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h4><p>常见的适用常见有，利用布隆过滤器减少磁盘 IO 或者网络请求，因为一旦一个值必定不存在的话，可以不用进行后续昂贵的查询请求。</p><p>另外，既然使用布隆过滤器来加速查找和判断是否存在，那么性能很低的哈希函数不是个好选择，推荐 MurmurHash、Fnv 这些。</p><p>目前布隆过滤器已经有相应实现的开源类库啦，如 Google 的 Guava 类库，Twitter 的 Algebird 类库，信手拈来即可，或者基于 Redis 自带的 Bitmaps 自行实现设计也是可以的。</p><h5 id="大-Value-拆分"><a href="#大-Value-拆分" class="headerlink" title="大 Value 拆分"></a>大 Value 拆分</h5><p>Redis 因其支持 setbit 和 getbit 操作，且纯内存性能高等特点，因此天然就可以作为布隆过滤器来使用。但是布隆过滤器的不当使用极易产生大 Value，增加 Redis 阻塞风险，因此生成环境中建议对体积庞大的布隆过滤器进行拆分。</p><p>拆分的形式方法多种多样，但是本质是不要将 Hash(Key) 之后的请求分散在多个节点的多个小 bitmap 上，而是应该拆分成多个小 bitmap 之后，对一个 Key 的所有哈希函数都落在这一个小 bitmap 上。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Data structures are nothing different. They are like the bookshelves of your application where you can organize your data. Different data structures will give you different facility and benefits. To properly use the power and accessibility of the data structures you need to know the trade-offs of using one.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;不同的数据结构有不同的适用场景和优缺点，你需要仔细权衡自己的需求之后妥善适用它们&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;布隆过滤器就是践行这句话的代表&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="布隆过滤器" scheme="http://xiaolong.li/tags/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>TCP 的粘包拆包以及解决方案</title>
    <link href="http://xiaolong.li/2021/08/23/TCP-stick-package-unpacking/"/>
    <id>http://xiaolong.li/2021/08/23/TCP-stick-package-unpacking/</id>
    <published>2021-08-22T16:01:48.000Z</published>
    <updated>2021-08-22T17:31:23.522Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p>TCP（transport control protocol，传输控制协议）是面向连接的，面向流的，提供高可靠性服务。收发两端（客户端和服务器端）都要有一一成对的socket，因此，发送端为了将多个发往接收端的包，更有效的发到对方，使用了优化方法（Nagle算法），将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包。这样，接收端，就难于分辨出来了，必须提供科学的拆包机制。即面向流的通信是无消息保护边界的。</p><p>TCP 底层并不了解上层业务数据的具体含义，它会根据 TCP 缓冲区的实际情况进行包的划分，所以在业务上认为一个完整的包可能会被 TCP 拆分为多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这就是 TCP <strong>粘包</strong> 和 <strong>拆包</strong>。</p><a id="more"></a><h4 id="为什么-UDP没有粘包？"><a href="#为什么-UDP没有粘包？" class="headerlink" title="为什么 UDP没有粘包？"></a>为什么 UDP没有粘包？</h4><p>粘包拆包问题在数据链路层、网络层以及传输层都有可能发生。日常的网络应用开发大都在传输层进行，由于 UDP 有消息保护边界，不会发生粘包拆包问题，因此粘包拆包问题只发生在 TCP 协议中。</p><h4 id="粘包拆包发生场景"><a href="#粘包拆包发生场景" class="headerlink" title="粘包拆包发生场景"></a>粘包拆包发生场景</h4><p>因为 TCP 是面向流，没有边界，而操作系统在发送 TCP 数据时，会通过缓冲区来进行优化，例如缓冲区为 1024 个字节大小。</p><p>如果一次请求发送的数据量比较小，没达到缓冲区大小，TCP 则会将多个请求合并为同一个请求进行发送，这就形成了粘包问题。</p><p>如果一次请求发送的数据量比较大，超过了缓冲区大小，TCP 就会将其拆分为多次发送，这就是拆包。</p><p>关于粘包和拆包可以参考下图的几种情况：</p><h5 id="正常数据包"><a href="#正常数据包" class="headerlink" title="正常数据包"></a>正常数据包</h5><blockquote><p>正常的理想情况，两个包恰好满足 TCP 缓冲区的大小或达到 TCP 等待时长，分别发送两个包</p></blockquote><p>服务端一共读到两个数据包，第一个包包含客户端发出的第一条消息的完整信息，第二个包包含客户端发出的第二条消息，那这种情况比较好处理，服务器只需要简单的从网络缓冲区去读就好了，第一次读到第一条消息的完整信息，消费完再从网络缓冲区将第二条完整消息读出来消费。这种情况没有发生粘包、拆包。</p><p><img src="/images/network/2021-08-23-tcp-packet-normal.png" alt="image"></p><h5 id="粘包"><a href="#粘包" class="headerlink" title="粘包"></a>粘包</h5><blockquote><p>两个包较小，间隔时间短，发生粘包，合并成一个包发送</p></blockquote><p>服务端一共就读到一个数据包，这个数据包包含客户端发出的两条消息的完整信息，这个时候服务端不知道如何区分原始的两个包，这种情况其实是发生了 TCP 粘包。</p><p><img src="/images/network/2021-08-23-tcp-packet-stick.png" alt="image"></p><h5 id="拆包"><a href="#拆包" class="headerlink" title="拆包"></a>拆包</h5><blockquote><p>一个包过大，超过缓存区大小，拆分成两个或多个包发送</p></blockquote><p><img src="/images/network/2021-08-23-tcp-packet-unpacking.png" alt="image"></p><h5 id="既有粘包又有拆包"><a href="#既有粘包又有拆包" class="headerlink" title="既有粘包又有拆包"></a>既有粘包又有拆包</h5><blockquote><p>packet_1 过大，进行了拆包处理，而拆出去的一部分又与 packet_2 进行粘包处理。</p></blockquote><p>服务端一共收到了两个数据包，第一个数据包只包含了第一条消息的一部分，第一条消息的后半部分和第二条消息都在第二个数据包中，或者是第一个数据包包含了第一条消息的完整信息和第二条消息的一部分信息，第二个数据包包含了第二条消息的剩下部分，这种情况其实是发送了 TCP 拆包，因为发生了一条消息被拆分在两个包里面发送了，同样上面的服务器逻辑对于这种情况是不好处理的。</p><p><img src="/images/network/2021-08-23-tcp-packet-stick-unpacking.png" alt="image"></p><h4 id="产生-TCP-粘包和拆包的原因"><a href="#产生-TCP-粘包和拆包的原因" class="headerlink" title="产生 TCP 粘包和拆包的原因"></a>产生 TCP 粘包和拆包的原因</h4><p>TCP 是以流的方式传输数据，传输的最小单位为一个报文段（segment）。TCP Header中有个 Options 标识位，常见的标识为 mss(Maximum Segment Size) 指的是，连接层每次传输的数据有个最大限制 MTU(Maximum Transmission Unit)，一般是 1500 比特，超过这个量要分成多个报文段，mss 则是这个最大限制减去 TCP 的 header，光是要传输的数据的大小，一般为 1460 比特。换算成字节，也就是 180 多字节。</p><p>TCP 为提高性能，发送端会将需要发送的数据发送到缓冲区，等待缓冲区满了之后，再将缓冲中的数据发送到接收方。同理，接收方也有缓冲区这样的机制，来接收数据。</p><p>发生 TCP 粘包、拆包主要是由于下面一些原因：</p><ol><li>应用程序写入的数据大于套接字缓冲区大小，这将会发生拆包。</li><li>应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发生粘包。</li><li>进行 mss（最大报文长度）大小的 TCP 分段，当 TCP 报文长度 - TCP 头部长度 &gt; mss 的时候将发生拆包。</li><li>接收方法不及时读取套接字缓冲区数据，这将发生粘包。</li></ol><h4 id="如何解决拆包粘包"><a href="#如何解决拆包粘包" class="headerlink" title="如何解决拆包粘包"></a>如何解决拆包粘包</h4><p>既然TCP 是无界的数据流，且协议本身无法避免粘包，拆包的发生，那么只能在应用层数据协议上加以控制。通常在制定传输数据时，可以使用如下方法：</p><ol><li>使用带消息头的协议、消息头存储消息开始标识及消息长度信息，服务端获取消息头的时候解析出消息长度，然后向后读取该长度的内容。</li><li>设置定长消息，服务端每次读取既定长度的内容作为一条完整消息。</li><li>设置消息边界，服务端从网络流中按消息编辑分离出消息内容。</li></ol><p>a)先基于第三种方法，假设区分数据边界的标识为换行符 “\n”（注意请求数据本身内部不能包含换行符），数据格式为 Json，例如下面是一个符合这个规则的请求包。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;type&quot;:&quot;message&quot;,&quot;content&quot;:&quot;hello&quot;&#125;\n</span><br></pre></td></tr></table></figure><p>注意上面的请求数据末尾有一个换行字符，代表一个请求的结束。</p><p>b)基于第一种方法，可以制定，首部固定 10 个字节长度用来保存整个数据包长度，位数不够则补 0 的数据协议</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0000000036&#123;&quot;type&quot;:&quot;message&quot;,&quot;content&quot;:&quot;hello&quot;&#125;</span><br></pre></td></tr></table></figure><p>c)基于第一种方法，可以制定，首部 4 字节网络字节序 unsigned int，标记整个包的长度</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">****&#123;&quot;type&quot;:&quot;message&quot;,&quot;content&quot;:&quot;hello all&quot;&#125;</span><br></pre></td></tr></table></figure><p>其中首部四字节 * 号代表一个网络字节序的 unsigned int 数据，为不可见字符，紧接着是 Json 的数据格式的包体数据。</p><h4 id="Netty对粘包和拆包问题的处理"><a href="#Netty对粘包和拆包问题的处理" class="headerlink" title="Netty对粘包和拆包问题的处理"></a>Netty对粘包和拆包问题的处理</h4><p>Netty 对解决粘包和拆包的方案做了抽象，提供了一些解码器（Decoder）来解决粘包和拆包的问题。如：</p><ul><li>LineBasedFrameDecoder：以行为单位进行数据包的解码；</li><li>DelimiterBasedFrameDecoder：以特殊的符号作为分隔来进行数据包的解码；</li><li>FixedLengthFrameDecoder：以固定长度进行数据包的解码；</li><li>LenghtFieldBasedFrameDecode：适用于消息头包含消息长度的协议（最常用）；</li></ul><p>基于 Netty 进行网络读写的程序，可以直接使用这些 Decoder 来完成数据包的解码。对于高并发、大流量的系统来说，每个数据包都不应该传输多余的数据（所以补齐的方式不可取），LenghtFieldBasedFrameDecode 更适合这样的场景。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>TCP 协议粘包拆包问题是因为 TCP 协议数据传输是基于字节流的，它不包含消息、数据包等概念，需要应用层协议自己设计消息的边界，即消息帧（Message Framing）。如果应用层协议没有使用基于长度、终结符信息或者消息边界等方式进行处理，则会导致多个消息的粘包和拆包。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;TCP（transport control protocol，传输控制协议）是面向连接的，面向流的，提供高可靠性服务。收发两端（客户端和服务器端）都要有一一成对的socket，因此，发送端为了将多个发往接收端的包，更有效的发到对方，使用了优化方法（Nagle算法），将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包。这样，接收端，就难于分辨出来了，必须提供科学的拆包机制。即面向流的通信是无消息保护边界的。&lt;/p&gt;
&lt;p&gt;TCP 底层并不了解上层业务数据的具体含义，它会根据 TCP 缓冲区的实际情况进行包的划分，所以在业务上认为一个完整的包可能会被 TCP 拆分为多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这就是 TCP &lt;strong&gt;粘包&lt;/strong&gt; 和 &lt;strong&gt;拆包&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="网络" scheme="http://xiaolong.li/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="TCP" scheme="http://xiaolong.li/tags/TCP/"/>
    
      <category term="粘包" scheme="http://xiaolong.li/tags/%E7%B2%98%E5%8C%85/"/>
    
      <category term="拆包" scheme="http://xiaolong.li/tags/%E6%8B%86%E5%8C%85/"/>
    
  </entry>
  
  <entry>
    <title>一文彻底搞懂 TCP 三次握手、四次挥手过程及原理</title>
    <link href="http://xiaolong.li/2021/08/20/Introduction-to-TCP/"/>
    <id>http://xiaolong.li/2021/08/20/Introduction-to-TCP/</id>
    <published>2021-08-20T03:23:39.000Z</published>
    <updated>2021-08-21T15:56:30.797Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h4 id="TCP-协议简述"><a href="#TCP-协议简述" class="headerlink" title="TCP 协议简述"></a>TCP 协议简述</h4><p>TCP 提供面向有连接的通信传输，面向有连接是指在传送数据之前必须先建立连接，数据传送完成后要释放连接。<br>无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在 TCP/IP 协议中，TCP 协议提供可靠的连接服务，连接是通过 <strong>三次握手</strong> 进行初始化的。<br>同时由于 TCP 协议是一种面向连接的、可靠的、基于字节流的运输层通信协议，TCP 是 <strong>全双工模式</strong>，所以需要 <strong>四次挥手</strong> 关闭连接。</p><a id="more"></a><h4 id="TCP-包首部"><a href="#TCP-包首部" class="headerlink" title="TCP 包首部"></a>TCP 包首部</h4><p>网络中传输的数据包由两部分组成：一部分是协议所要用到的首部，另一部分是上一层传过来的数据。首部的结构由协议的具体规范详细定义。在数据包的首部，明确标明了协议应该如何读取数据。反过来说，看到首部，也就能够了解该协议必要的信息以及所要处理的数据。包首部就像协议的脸。</p><p>所以在学习 TCP 协议之前，首先要知道 TCP 在网络传输中处于哪个位置，以及它的协议的规范，下面我们就看看 TCP 首部的网络传输起到的作用：</p><p><img src="/images/network/2021-08-20-tcp-msg.png" alt="image"></p><p>下面的图是 TCP 头部的规范定义，它定义了 TCP 协议如何读取和解析数据：</p><p><img src="/images/network/2021-08-20-tcp-header.png" alt="image"></p><p>TCP 首部承载这 TCP 协议需要的各项信息，下面我们来分析一下：</p><h5 id="TCP-端口号"><a href="#TCP-端口号" class="headerlink" title="TCP 端口号"></a>TCP 端口号</h5><p>TCP 的连接是需要四个要素确定唯一一个连接：</p><blockquote><p>（源IP，源端口号）+ （目地IP，目的端口号）</p></blockquote><p>所以 TCP 首部预留了两个 16 位作为端口号的存储，而 IP 地址由上一层 IP 协议负责传递，源端口号和目地端口各占 16 位两个字节，也就是端口的范围是 2^16=65535，另外 1024  以下是系统保留的，从 1024-65535 是用户使用的端口范围。</p><h5 id="TCP-的序号和确认号"><a href="#TCP-的序号和确认号" class="headerlink" title="TCP 的序号和确认号"></a>TCP 的序号和确认号</h5><p><strong>32位序号 seq</strong>：Sequence number 缩写 <strong>seq</strong> ，TCP 通信过程中某一个传输方向上的字节流的每个字节的序号，通过这个来确认发送的数据有序，比如现在序列号为 1000，发送了 1000，下一个序列号就是 2000。<br><strong>32位确认号 ack</strong>：Acknowledge number 缩写 <strong>ack</strong>，TCP 对上一次 seq 序号做出的确认号，用来响应 TCP 报文段，给收到的 TCP 报文段的序号 seq 加 1。</p><h4 id="TCP-的标志位"><a href="#TCP-的标志位" class="headerlink" title="TCP 的标志位"></a>TCP 的标志位</h4><p>每个 TCP 段都有一个目的，这是借助于 TCP 标志位选项来确定的，允许发送方或接收方指定哪些标志应该被使用，以便段被另一端正确处理。<br>用的最广泛的标志是 <strong>SYN</strong>，<strong>ACK</strong> 和 <strong>FIN</strong>，用于建立连接，确认成功的段传输，最后终止连接。</p><blockquote><p><strong>SYN</strong>：简写为S，同步标志位，用于建立会话连接，同步序列号；<br><strong>ACK</strong>：简写为.，确认标志位，对已接收的数据包进行确认；<br><strong>FIN</strong>：简写为F，完成标志位，表示我已经没有数据要发送了，即将关闭连接；<br><strong>PSH</strong>：简写为P，推送标志位，表示该数据包被对方接收后应立即交给上层应用，而不在缓冲区排队；<br><strong>RST</strong>：简写为R，重置标志位，用于连接复位、拒绝错误和非法的数据包；<br><strong>URG</strong>：简写为U，紧急标志位，表示数据包的紧急指针域有效，用来保证连接不被阻断，并督促中间设备尽快处理；</p></blockquote><h4 id="TCP-三次握手建立连接"><a href="#TCP-三次握手建立连接" class="headerlink" title="TCP 三次握手建立连接"></a>TCP 三次握手建立连接</h4><p>所谓三次握手 (Three-way Handshake)，是指建立一个 TCP 连接时，需要客户端和服务器总共发送3个报文。</p><p>三次握手的目的是连接服务器指定端口，建立 TCP 连接，并同步连接双方的序列号和确认号，交换 TCP 窗口大小信息。在 socket 编程中，客户端执行 connect() 时，将触发三次握手。</p><p>三次握手过程的示意图如下：</p><p><img src="/images/network/2021-08-20-tcp-established.png" alt="image"></p><h5 id="第一次握手"><a href="#第一次握手" class="headerlink" title="第一次握手"></a>第一次握手</h5><p>客户端将 TCP 报文标志位 SYN 置为 1，随机产生一个序号值 seq = J，保存在 TCP 首部的序列号 (Sequence Number) 字段里，指明客户端打算连接的服务器的端口，并将该数据包发送给服务器端，发送完毕后，客户端进入 SYN_SENT 状态，等待服务器端确认。</p><h5 id="第二次握手"><a href="#第二次握手" class="headerlink" title="第二次握手"></a>第二次握手</h5><p>服务器端收到数据包后由标志位 SYN = 1 知道客户端请求建立连接，服务器端将 TCP 报文标志位 SYN 和 ACK 都置为 1，ack = J + 1，随机产生一个序号值 seq = K ，并将该数据包发送给客户端以确认连接请求，服务器端进入 SYN_RCVD 状态。</p><h5 id="第三次握手"><a href="#第三次握手" class="headerlink" title="第三次握手"></a>第三次握手</h5><p>客户端收到确认后，检查 ack 是否为 J + 1 ，ACK 是否为 1，如果正确则将标志位 ACK 置为 1，ack=K+1，并将该数据包发送给服务器端，服务器端检查 ack 是否为 K+1，ACK 是否为 1，如果正确则连接建立成功，客户端和服务器端进入 ESTABLISHED 状态，完成三次握手，随后客户端与服务器端之间可以开始传输数据了。</p><blockquote class="blockquote-center"><p><strong>第三次握手允许携带数据</strong></p></blockquote><p>注意：上面写的 <strong>ack 和 ACK 不是同一个概念</strong>：</p><blockquote><p>小写的 ack 代表的是头部的确认号 Acknowledge number， 缩写 ack ，是对上一个包的序号进行确认的号，ack=seq+1。<br>大写的 ACK 是上面说的 TCP 首部的标志位，用于标志的 TCP 包是否对上一个包进行了确认操作，如果确认了，则把 ACK 标志位设置成1。</p></blockquote><p>下面我自己做实验，开一个 HTTP 服务，监听 80 端口，然后使用 Tcpdump 命令抓包，看一下 TCP 三次握手的过程：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">sudo tcpdump -n -t -S -i enp0s3  port 80 </span><br><span class="line"></span><br><span class="line">第一次握手，标志位Flags=S</span><br><span class="line">IP 10.0.2.2.51323 &gt; 10.0.2.15.80: Flags [S], seq 84689409, win 65535, options [mss 1460], length 0</span><br><span class="line">第二次握手，标志位Flags=[S.]</span><br><span class="line">IP 10.0.2.15.80 &gt; 10.0.2.2.51323: Flags [S.], seq 1893430205, ack 84689410, win 64240, options [mss 1460], length 0</span><br><span class="line">第三次握手，标志位Flags=[.]</span><br><span class="line">IP 10.0.2.2.51323 &gt; 10.0.2.15.80: Flags [.], ack 1893430206, win 65535, length 0</span><br><span class="line">建立连接后，客户端发送http请求 </span><br><span class="line">IP 10.0.2.2.51321 &gt; 10.0.2.15.80: Flags [P.], seq 1:753, ack 1, win 65535, length 752: HTTP: GET / HTTP/1.1</span><br></pre></td></tr></table></figure><p>tcpdump命令解析一下：</p><blockquote><p>-i: 指定抓包的网卡是enp0s3<br>-n: 把域名转成IP显示<br>-t: 不显示时间<br>-S: 序列号使用绝对数值，不指定-S的话，序列号会使用相对的数值<br>port: 指定监听端口是80<br>host: 指定监听的主机名</p></blockquote><p>实战中TCP的三次握手过程：</p><blockquote><p>第一次握手，客户端51323端口号向服务器端80号端口发起连接，此时标志位flags=S，即SYN=1标志，表示向服务端发起连接的请求，同时生成序列号seq=84689409<br>第二次握手，服务端标志位flags=[S.]，即SYN+ACK标志位设置为1，表示对上一个请求连接的报文进行确认，同时设置ack=seq+1=184689410，生成序列号seq=1893430205<br>第三次握手，客户端对服务端的响应进行确认，所以此时标志位是[.]即ACK=1，同时返回对上一个报文的seq的确认号，ack=1893430206<br>至此，三次握手完成，一个TCP连接建立完成，接下来就是双端传输数据了</p></blockquote><h5 id="为什么需要三次握手"><a href="#为什么需要三次握手" class="headerlink" title="为什么需要三次握手"></a>为什么需要三次握手</h5><p>假设 client 发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达 server。</p><p>本来这是一个早已失效的报文段。但 server 收到此失效的连接请求报文段后，就误认为是 client 再次发出的一个新的连接请求。于是就向 client 发出确认报文段，同意建立连接。</p><p>假设不采用“三次握手”，那么只要 server 发出确认，新的连接就建立了。由于现在 client 并没有发出建立连接的请求，因此不会理睬 server 的确认，也不会向 server 发送数据。但 server 却以为新的运输连接已经建立，并一直等待 client 发来数据。这样，server 的很多资源就白白浪费掉了。</p><p>所以，采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client 不会向 server 的确认发出确认。server 由于收不到确认，就知道 client 并没有要求建立连接。</p><h4 id="TCP-四次挥手关闭连接"><a href="#TCP-四次挥手关闭连接" class="headerlink" title="TCP 四次挥手关闭连接"></a>TCP 四次挥手关闭连接</h4><p>四次挥手即终止 TCP 连接，就是指断开一个 TCP 连接时，需要客户端和服务端总共发送 4 个包以确认连接的断开。</p><p>在 socket 编程中，这一过程由客户端或服务端任一方执行 close 来触发。</p><p>由于 TCP 连接是全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，A 发送一个 FIN 来终止连接，B 收到一个 FIN ，只是意味着 A-&gt;B 方向上没有数据流动了，即B不会再收到数据了，但是在这个 TCP 连接上 B 仍然能够发送数据，直到 B 也向 A 发送了 FIN ，才能说明需要关闭连接。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。</p><p>四次挥手过程的示意图如下：</p><p><img src="/images/network/2021-08-20-tcp-close.png" alt="image"></p><p>挥手请求可以是 Client 端，也可以是 Server 端发起的，我们假设是 Client 端发起：</p><h5 id="第一次挥手"><a href="#第一次挥手" class="headerlink" title="第一次挥手"></a>第一次挥手</h5><p>Client 端发起挥手请求，向 Server 端发送标志位是 FIN 报文段，设置序列号 seq ，此时，Client 端进入 FIN_WAIT_1 状态，这表示 Client 端没有数据要发送给 Server 端了。</p><h5 id="第二次挥手"><a href="#第二次挥手" class="headerlink" title="第二次挥手"></a>第二次挥手</h5><p>Server 端收到了 Client 端发送的 FIN 报文段，向 Client 端返回一个标志位是 ACK 的报文段，ack 设为 seq + 1，Client 端进入 FIN_WAIT_2 状态，Server 端告诉 Client 端，我确认并同意你的关闭请求。</p><h5 id="第三次挥手"><a href="#第三次挥手" class="headerlink" title="第三次挥手"></a>第三次挥手</h5><p>Server 端向 Client 端发送标志位是 FIN 的报文段，请求关闭连接，同时 Client 端进入 LAST_ACK 状态。</p><h5 id="第四次挥手"><a href="#第四次挥手" class="headerlink" title="第四次挥手"></a>第四次挥手</h5><p>Client 端收到 Server 端发送的 FIN 报文段，向 Server 端发送标志位是 ACK 的报文段，然后 Client 端进入 TIME_WAIT 状态。Server 端收到 Client 端的 ACK 报文段以后，就关闭连接。此时，Client 端 <strong>等待 2MSL</strong> 的时间后依然没有收到回复，则证明 Server 端已正常关闭，那好，Client 端也可以关闭连接了。</p><h5 id="为什么关闭的时候却是四次握手？"><a href="#为什么关闭的时候却是四次握手？" class="headerlink" title="为什么关闭的时候却是四次握手？"></a>为什么关闭的时候却是四次握手？</h5><p>建立连接时因为当 Server 端收到 Client 端的 SYN 连接请求报文后，可以直接发送 SYN + ACK 报文。其中 ACK 报文是用来应答的，SYN 报文是用来同步的，所以建立连接只需要三次握手。</p><p>由于TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议，TCP是全双工模式。这就意味着，关闭连接时，当 Client 端发出 FIN 报文段时，只是表示 Client 端告诉 Server 端数据已经发送完毕了。当 Server 端收到 FIN 报文并返回 ACK 报文段，表示它已经知道 Client 端没有数据发送了，但是 Server 端还是可以发送数据到 Client 端的，所以 Server 很可能并不会立即关闭 SOCKET ，直到 Server 端把数据也发送完毕。当 Server 端也发送了 FIN 报文段时，这个时候就表示 Server 端也没有数据要发送了，就会告诉 Client 端，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。</p><h5 id="为什么要等待-2MSL-？"><a href="#为什么要等待-2MSL-？" class="headerlink" title="为什么要等待 2MSL ？"></a>为什么要等待 2MSL ？</h5><p><strong>MSL</strong>：报文段最大生存时间，它是任何报文段被丢弃前在网络内的最长时间。</p><p>有以下两个原因：</p><p>第一点：保证 TCP 协议的全双工连接能够可靠关闭。由于 IP 协议的不可靠性或者是其它网络原因，导致了 Server 端没有收到 Client 端的 ACK 报文，那么 Server 端就会在超时之后重新发送 FIN ，如果此时 Client 端的连接已经关闭处于 CLOESD 状态，那么重发的 FIN 就找不到对应的连接了，从而导致连接错乱，所以，Client 端发送完最后的 ACK 不能直接进入 CLOSED 状态，而要保持 TIME_WAIT ，当再次收到 FIN 的收，能够保证对方收到 ACK ，最后正确关闭连接。</p><p>第二点：保证这次连接的重复数据段从网络中消失。如果 Client 端发送最后的 ACK 直接进入 CLOSED 状态，然后又再向 Server 端发起一个新连接，这时不能保证新连接的与刚关闭的连接的端口号是不同的，也就是新连接和老连接的端口号可能一样了，那么就可能出现问题：如果前一次的连接某些数据滞留在网络中，这些延迟数据在建立新连接后到达Client端，由于新老连接的端口号和IP都一样，TCP协议就认为延迟数据是属于新连接的，新连接就会接收到脏数据，这样就会导致数据包混乱。所以TCP连接需要在TIME_WAIT状态等待2倍MSL，才能保证本次连接的所有数据在网络中消失。</p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;TCP-协议简述&quot;&gt;&lt;a href=&quot;#TCP-协议简述&quot; class=&quot;headerlink&quot; title=&quot;TCP 协议简述&quot;&gt;&lt;/a&gt;TCP 协议简述&lt;/h4&gt;&lt;p&gt;TCP 提供面向有连接的通信传输，面向有连接是指在传送数据之前必须先建立连接，数据传送完成后要释放连接。&lt;br&gt;无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在 TCP/IP 协议中，TCP 协议提供可靠的连接服务，连接是通过 &lt;strong&gt;三次握手&lt;/strong&gt; 进行初始化的。&lt;br&gt;同时由于 TCP 协议是一种面向连接的、可靠的、基于字节流的运输层通信协议，TCP 是 &lt;strong&gt;全双工模式&lt;/strong&gt;，所以需要 &lt;strong&gt;四次挥手&lt;/strong&gt; 关闭连接。&lt;/p&gt;
    
    </summary>
    
      <category term="网络" scheme="http://xiaolong.li/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="TCP" scheme="http://xiaolong.li/tags/TCP/"/>
    
      <category term="三次握手" scheme="http://xiaolong.li/tags/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B/"/>
    
      <category term="四次挥手" scheme="http://xiaolong.li/tags/%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"/>
    
  </entry>
  
  <entry>
    <title>Redis 持久化机制</title>
    <link href="http://xiaolong.li/2021/08/15/Redis-Persistence/"/>
    <id>http://xiaolong.li/2021/08/15/Redis-Persistence/</id>
    <published>2021-08-15T15:15:23.000Z</published>
    <updated>2021-08-15T16:21:59.296Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p>Redis 是一个内存数据库，数据保存在内存中，但是我们都知道内存的数据变化是很快的，也容易发生丢失。幸好 Redis 还为我们提供了持久化的机制，分别是 RDB(Redis DataBase) 和 AOF(Append Only File)。</p><h4 id="持久化流程"><a href="#持久化流程" class="headerlink" title="持久化流程"></a>持久化流程</h4><p>Redis 的数据持久化就是可以将数据保存在磁盘上，主要有下面五个过程：</p><blockquote><p>（1）客户端向服务端发送写操作(数据在客户端的内存中)。</p><p>（2）数据库服务端接收到写请求的数据(数据在服务端的内存中)。</p><p>（3）服务端调用 write 这个系统调用，将数据往磁盘上写(数据在系统内存的缓冲区中)。</p><p>（4）操作系统将缓冲区中的数据转移到磁盘控制器上(数据在磁盘缓存中)。</p><p>（5）磁盘控制器将数据写到磁盘的物理介质中(数据真正落到磁盘上)。</p></blockquote><a id="more"></a><p>这 5 个过程是在理想条件下一个正常的保存流程，但是在大多数情况下，我们的机器等等都会有各种各样的故障，这里划分了两种情况：</p><blockquote><p>（1）Redis 数据库发生故障，只要在上面的第三步执行完毕，那么就可以持久化保存，剩下的两步由操作系统替我们完成。</p><p>（2）操作系统发生故障，必须上面 5 步都完成才可以。</p></blockquote><p>在这里只考虑了保存的过程可能发生的故障，其实保存的数据也有可能发生损坏，需要一定的恢复机制，不过在这里就不再延伸了。现在主要考虑的是 Redis 如何来实现上面 5 个保存磁盘的步骤。它提供了两种策略机制，也就是 RDB 和 AOF。</p><h4 id="RDB-机制"><a href="#RDB-机制" class="headerlink" title="RDB 机制"></a>RDB 机制</h4><p>RDB 其实就是把数据以快照的形式保存在磁盘上。什么是快照呢? 你可以理解成把当前时刻的数据拍成一张照片保存下来。</p><p>RDB 持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘。也是默认的持久化方式，这种方式是就是将内存中数据以快照的方式写入到二进制文件中,默认的文件名为 dump.rdb。</p><blockquote class="blockquote-center"><p>在安装了 Redis 之后，所有的配置都是在 redis.conf 文件中，里面保存了 RDB 和 AOF 两种持久化机制的各种配置</p></blockquote><p>既然 RDB 机制是通过把某个时刻的所有数据生成一个快照来保存，那么就应该有一种触发机制，是实现这个过程。对于 RDB 来说，提供了三种机制：save、bgsave、自动化。</p><h5 id="save-触发方式"><a href="#save-触发方式" class="headerlink" title="save 触发方式"></a>save 触发方式</h5><p>该命令会阻塞当前 Redis 服务器，执行 save 命令期间，Redis 不能处理其他命令，直到 RDB 过程完成为止。具体流程如下：</p><p><img src="/images/redis/2021-08-15-save-cmd.jpeg" alt="image" title="save命令"></p><p>执行完成时候如果存在老的 RDB 文件，就把新的替代掉旧的。我们的客户端可能都是几万或者是几十万，这种方式显然不可取。</p><h5 id="bgsave-触发方式"><a href="#bgsave-触发方式" class="headerlink" title="bgsave 触发方式"></a>bgsave 触发方式</h5><p>执行该命令时，Redis 会在后台异步进行快照操作，快照同时还可以响应客户端请求。具体流程如下：</p><p><img src="/images/redis/2021-08-15-bgsave-cmd.jpeg" alt="image" title="bgsave命令"></p><p>具体操作是 Redis 进程执行 fork 操作创建子进程，RDB 持久化过程由子进程负责，完成后自动结束。阻塞只发生在 fork 阶段，一般时间很短。基本上 Redis 内部所有的 RDB 操作都是采用 bgsave 命令。</p><h5 id="自动触发"><a href="#自动触发" class="headerlink" title="自动触发"></a>自动触发</h5><p>自动触发是由配置文件来完成的。在 redis.conf 配置文件中，有如下配置可以设置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt; 1、save：这里是用来配置触发 Redis的 RDB 持久化条件，也就是什么时候将内存中的数据保存到硬盘。比如“save m n”。表示m秒内数据集存在n次修改时，自动触发bgsave。</span><br><span class="line">默认如下配置：</span><br><span class="line"></span><br><span class="line">&apos;#&apos;  表示900 秒内如果至少有1个key的值发生变化，则保存save 900 </span><br><span class="line">&apos;1#&apos;  表示300 秒内如果至少有10个key的值变化，则保存save 300 </span><br><span class="line">&apos;10#&apos; 表示60 秒内如果至少有10000个key的值变化，则保存save 60 10000</span><br><span class="line"></span><br><span class="line">不需要持久化，那么你可以注释掉所有的 save 行来停用保存功能。</span><br><span class="line">&gt;</span><br><span class="line">&gt; 2、&apos;stop-writes-on-bgsave-error&apos;：默认值为yes。当启用了RDB且最后一次后台保存数据失败时，Redis是否停止接收数据，这会让用户意识到数据没有正确持久化到磁盘上，否则没有人会注意到灾难（disaster）发生了。如果Redis重启了，那么又可以重新开始接收数据了</span><br><span class="line">&gt;</span><br><span class="line">&gt; 3、&apos;rdbcompression&apos;：默认值是yes。对于存储到磁盘中的快照，可以设置是否进行压缩存储。</span><br><span class="line">&gt;</span><br><span class="line">&gt; 4、&apos;rdbchecksum&apos;：默认值是yes。在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。</span><br><span class="line">&gt;</span><br><span class="line">&gt; 5、&apos;dbfilename&apos;：设置快照的文件名，默认是 dump.rdb</span><br><span class="line">&gt;</span><br><span class="line">&gt; 6、&apos;dir&apos;：设置快照文件的存放路径，这个配置项一定是个目录，而不能是文件名。</span><br></pre></td></tr></table></figure><p>可以修改这些配置来实现我们想要的效果。因为第三种方式是配置的，所以对前两种进行一个对比：</p><table><thead><tr><th>命令</th><th>save</th><th>bgsave</th></tr></thead><tbody><tr><td>IO 类型</td><td>同步</td><td>异步</td></tr><tr><td>是否阻塞</td><td>是</td><td>是（阻塞发生在 fork 时）</td></tr><tr><td>复杂度</td><td>O(n)</td><td>O(n)</td></tr><tr><td>优点</td><td>不会消耗额外内存</td><td>不阻塞客户端命令</td></tr><tr><td>缺点</td><td>阻塞客户端命令</td><td>需要 fork ，消耗内存</td></tr></tbody></table><h4 id="RDB-的优势和劣势"><a href="#RDB-的优势和劣势" class="headerlink" title="RDB 的优势和劣势"></a>RDB 的优势和劣势</h4><p><strong>优势</strong> ：</p><blockquote><p>（1）RDB文件紧凑，全量备份，非常适合用于进行备份和灾难恢复。</p><p>（2）生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。</p><p>（3）RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</p></blockquote><p><strong>劣势</strong>：</p><p>RDB 快照是一次全量备份，存储的是内存数据的二进制序列化形式，存储上非常紧凑。当进行快照持久化时，会开启一个子进程专门负责快照持久化，子进程会拥有父进程的内存数据，父进程修改内存子进程不会反应出来，所以在快照持久化期间修改的数据不会被保存，可能丢失数据。</p><h4 id="AOF-机制"><a href="#AOF-机制" class="headerlink" title="AOF 机制"></a>AOF 机制</h4><p>全量备份总是耗时的，提供一种更加高效的方式 AOF，工作机制很简单，Redis 会将每一个收到的写命令都通过 write 函数追加到文件中。通俗的理解就是日志记录。</p><h5 id="持久化原理"><a href="#持久化原理" class="headerlink" title="持久化原理"></a>持久化原理</h5><p><img src="/images/redis/2021-08-15-aof-persistence.jpeg" alt="image" title="AOF 运行原理"></p><p>每当有一个写命令过来时，就直接保存在我们的 AOF 文件中。</p><h5 id="文件重写原理"><a href="#文件重写原理" class="headerlink" title="文件重写原理"></a>文件重写原理</h5><p>AOF 的方式也同时带来了另一个问题。持久化文件会变的越来越大。为了压缩 aof 的持久化文件。Redis提供了 bgrewriteaof 命令。将内存中的数据以命令的方式保存到临时文件中，同时会 fork 出一条新进程来将文件重写。</p><p><img src="/images/redis/2021-08-15-aof-rewrite-file.jpeg" alt="image" title="AOF文件重写原理"></p><p>重写 aof 文件的操作，并没有读取旧的 aof 文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的 aof 文件，这点和快照有点类似。</p><h5 id="触发机制"><a href="#触发机制" class="headerlink" title="触发机制"></a>触发机制</h5><p>AOF 也有三种触发机制，always、everysec、和 no。</p><blockquote><p>（1）每修改同步 always：同步持久化 每次发生数据变更会被立即记录到磁盘 性能较差但数据完整性比较好</p><p>（2）每秒同步 everysec：异步操作，每秒记录 如果一秒内宕机，有数据丢失</p><p>（3）不同 no：从不同步</p></blockquote><p>三种触发机制对比：</p><table><thead><tr><th>命令</th><th>always</th><th>everysec</th><th>no</th></tr></thead><tbody><tr><td>优点</td><td>不丢失数据</td><td>每秒一次 fsync <br> 最大丢一秒数据</td><td>不用运维</td></tr><tr><td>缺点</td><td>IO 开销较大<br>一般的 SATA 盘只有几百 TPS</td><td>丢一秒数据</td><td>不可控</td></tr></tbody></table><h5 id="AOF-的优势和劣势"><a href="#AOF-的优势和劣势" class="headerlink" title="AOF 的优势和劣势"></a>AOF 的优势和劣势</h5><p><strong>优势</strong>：</p><blockquote><p>（1）AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒通过一个后台线程执行一次 fsync 操作，最多丢失 1 秒钟的数据。</p><p>（2）AOF 日志文件没有任何磁盘寻址的开销，写入性能非常高，文件不容易破损。</p><p>（3）AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。</p><p>（4）AOF 日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如不小心用 flushall 命令清空了所有数据，只要这个时候后台 rewrite 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 flushall 命令给删了，然后再将该 AOF 文件放回去，就可以通过恢复机制，自动恢复所有数据。</p></blockquote><p><strong>劣势</strong>：</p><blockquote><p>（1）对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。</p><p>（2）AOF 开启后，支持的写 QPS 会比 RDB 支持的低，因为 AOF 一般会配置成每秒 fsync 一次日志文件，当然，每秒一次 fsync，性能也还是很高的</p><p>（3）AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。</p></blockquote><h4 id="RDB和AOF到底该如何选择"><a href="#RDB和AOF到底该如何选择" class="headerlink" title="RDB和AOF到底该如何选择"></a>RDB和AOF到底该如何选择</h4><p>一般根据需求不同选择的也不通，但是通常都是结合使用。总结：</p><table><thead><tr><th>命令</th><th>RDB</th><th>AOF</th></tr></thead><tbody><tr><td>启动优先级</td><td>低</td><td>高</td></tr><tr><td>体积</td><td>小</td><td>大</td></tr><tr><td>恢复速度</td><td>快</td><td>慢</td></tr><tr><td>数据安全性</td><td>宕机容易丢数据</td><td>根据策略决定</td></tr><tr><td>轻重</td><td>重</td><td>轻</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Redis 是一个内存数据库，数据保存在内存中，但是我们都知道内存的数据变化是很快的，也容易发生丢失。幸好 Redis 还为我们提供了持久化的机制，分别是 RDB(Redis DataBase) 和 AOF(Append Only File)。&lt;/p&gt;
&lt;h4 id=&quot;持久化流程&quot;&gt;&lt;a href=&quot;#持久化流程&quot; class=&quot;headerlink&quot; title=&quot;持久化流程&quot;&gt;&lt;/a&gt;持久化流程&lt;/h4&gt;&lt;p&gt;Redis 的数据持久化就是可以将数据保存在磁盘上，主要有下面五个过程：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;（1）客户端向服务端发送写操作(数据在客户端的内存中)。&lt;/p&gt;
&lt;p&gt;（2）数据库服务端接收到写请求的数据(数据在服务端的内存中)。&lt;/p&gt;
&lt;p&gt;（3）服务端调用 write 这个系统调用，将数据往磁盘上写(数据在系统内存的缓冲区中)。&lt;/p&gt;
&lt;p&gt;（4）操作系统将缓冲区中的数据转移到磁盘控制器上(数据在磁盘缓存中)。&lt;/p&gt;
&lt;p&gt;（5）磁盘控制器将数据写到磁盘的物理介质中(数据真正落到磁盘上)。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://xiaolong.li/categories/Redis/"/>
    
    
      <category term="redis" scheme="http://xiaolong.li/tags/redis/"/>
    
      <category term="rdb" scheme="http://xiaolong.li/tags/rdb/"/>
    
      <category term="aof" scheme="http://xiaolong.li/tags/aof/"/>
    
  </entry>
  
  <entry>
    <title>Zookeeper 实现消息队列</title>
    <link href="http://xiaolong.li/2021/08/12/Zookeeper-for-Message-queue/"/>
    <id>http://xiaolong.li/2021/08/12/Zookeeper-for-Message-queue/</id>
    <published>2021-08-12T08:08:26.000Z</published>
    <updated>2021-08-12T08:09:53.270Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Zookeeper 实现配置中心</title>
    <link href="http://xiaolong.li/2021/08/12/Zookeeper-for-Configuration/"/>
    <id>http://xiaolong.li/2021/08/12/Zookeeper-for-Configuration/</id>
    <published>2021-08-12T08:07:50.000Z</published>
    <updated>2021-08-12T08:09:23.885Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Zookeeper 实现注册中心</title>
    <link href="http://xiaolong.li/2021/08/12/Zookeeper-for-Registry/"/>
    <id>http://xiaolong.li/2021/08/12/Zookeeper-for-Registry/</id>
    <published>2021-08-12T08:05:44.000Z</published>
    <updated>2021-08-12T08:10:07.691Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Zookeeper 实现分布式事务</title>
    <link href="http://xiaolong.li/2021/08/12/Zookeeper-for-Distributed-transaction/"/>
    <id>http://xiaolong.li/2021/08/12/Zookeeper-for-Distributed-transaction/</id>
    <published>2021-08-12T08:04:04.000Z</published>
    <updated>2021-08-12T08:09:36.933Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Zookeeper 实现分布式锁</title>
    <link href="http://xiaolong.li/2021/08/12/Zookeeper-for-Distributed-lock/"/>
    <id>http://xiaolong.li/2021/08/12/Zookeeper-for-Distributed-lock/</id>
    <published>2021-08-12T08:03:23.000Z</published>
    <updated>2021-08-12T08:09:21.159Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Zookeeper 实现负载均衡</title>
    <link href="http://xiaolong.li/2021/08/12/Zookeeper-for-Load-balancing/"/>
    <id>http://xiaolong.li/2021/08/12/Zookeeper-for-Load-balancing/</id>
    <published>2021-08-12T08:03:01.000Z</published>
    <updated>2021-08-12T08:09:45.165Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>WebRTC 中的 RTP 及 RTCP 介绍</title>
    <link href="http://xiaolong.li/2021/08/12/Introduction-RTP-RTCP-in-WebRTC/"/>
    <id>http://xiaolong.li/2021/08/12/Introduction-RTP-RTCP-in-WebRTC/</id>
    <published>2021-08-12T02:22:05.000Z</published>
    <updated>2021-08-12T07:42:04.617Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><blockquote><p>WebRTC 技术是激烈的开放的 Web 战争中一大突破。- Brendan Eich, inventor of Java</p></blockquote><h4 id="UDP-还是-TCP？"><a href="#UDP-还是-TCP？" class="headerlink" title="UDP 还是 TCP？"></a>UDP 还是 TCP？</h4><p>如果抛开 WebRTC，让你自己实现一套实时互动直播系统，在选择网络传输协议时，你会选择使用 UDP 协议还是 TCP 协议呢？</p><p>这个问题在 2011 年至 2012 年一直是一件困扰着我们整个团队的大事儿，因为当时在国内很少有用 UDP 作为底层传输协议的。UDP 虽然传输快，但不可靠，尤其是在用户的网络质量很差的情况下，基本无法保障音视频的服务质量。</p><p>当时能想到的解决方案是，如果采用 UDP 作为底层传输协议，那就使用 RUDP（可靠性 UDP），只有这样才能保障传输过程中不丢包。但有人提出反对意见，认为如果想不丢包，就该使用 TCP，因为 RUDP 可靠性做到极致就变成 TCP 了，那为什么不直接使用 TCP 呢？</p><p>面对这种情况，2019 年的你会做何种选择呢？UDP 还是 TCP？你能拿出让人真正信服的理由吗？</p><p>现在让我告诉你正确答案：<strong>必须使用 UDP，必须使用 UDP，必须使用 UDP</strong>，重要的事情说三遍。</p><a id="more"></a><p>为什么一定要使用 UDP 呢？关于这个问题，你可以反向思考下，假如使用 TCP 会怎样呢？在极端网络情况下，TCP 为了传输的可靠性，它是如何做的呢？简单总结起来就是“发送 -&gt; 确认；超时 -&gt; 重发”的反复过程。</p><p>举个例子，A 与 B 通讯，A 首先向 B 发送数据，并启动一个定时器。当 B 收到 A 的数据后，B 需要给 A 回一个 ACK（确认）消息，反复这样操作，数据就源源不断地从 A 流向了 B。如果因为某些原因，A 一直收不到 B 的确认消息会怎么办呢？当 A 的定时器超时后，A 将重发之前没有被确认的消息，并重新设置定时器。</p><p>在 TCP 协议中，为了避免重传次数过多，定时器的超时时间会按 2 的指数增长。也就是说，假设第一次设置的超时时间是 1 秒，那么第二次就是 2 秒，第三次是 4 秒……第七次是 64 秒。如果第七次之后仍然超时，则断开 TCP 连接。你可以计算一下，从第一次超时，到最后断开连接，这之间一共经历了 2 分 07 秒，是不是很恐怖？</p><p>如果遇到前面的情况，A 与 B 之间的连接断了，那还算是个不错的情况，因为还可以再重新建立连接。但如果在第七次重传后，A 收到了 B 的 ACK 消息，那么 A 与 B 之间的数据传输的延迟就达到 1 分钟以上。对于这样的延迟，实时互动的直播系统是根本无法接受的。</p><p>基于以上的原因，在实现 <strong>实时互动直播系统的时候你必须使用 UDP 协议</strong> 。</p><h4 id="RTP-amp-RTCP"><a href="#RTP-amp-RTCP" class="headerlink" title="RTP &amp; RTCP"></a>RTP &amp; RTCP</h4><p>一般情况下，在实时互动直播系统传输音视频数据流时，我们并不直接将音视频数据流交给 UDP 传输，而是先给音视频数据加个 RTP 头，然后再交给 UDP 进行传输。为什么要这样做呢？</p><p>我们以视频帧为例，一个 I 帧的数据量是非常大的，最少也要几十 K（I/P/B 帧的概念我在前面《03 | 如何使用浏览器给自己拍照呢?》的文章中有过介绍）。而以太网的最大传输单元是多少呢？ 1.5K，所以要传输一个 I 帧需要几十个包。并且这几十个包传到对端后，还要重新组装成 I 帧，这样才能进行解码还原出一幅幅的图像。如果是我们自己实现的话，要完成这样的过程，至少需要以下几个标识。</p><blockquote><p>序号：用于标识传输包的序号，这样就可以知道这个包是第几个分片了。</p><p>起始标记：记录分帧的第一个 UDP 包。</p><p>结束标记：记录分帧的最后一个 UDP 包。</p></blockquote><p>有了上面这几个标识字段，我们就可以在发送端进行拆包，在接收端将视频帧重新再组装起来了。</p><h5 id="RTP-协议"><a href="#RTP-协议" class="headerlink" title="RTP 协议"></a>RTP 协议</h5><p>其实，这样的需求在很早之前就已经有了。因此，人们专门定义了一套规范，它就是 RTP 协议。下面让我们来详细看一下 RTP 协议吧。</p><p>如图所示，RTP 协议非常简单，我这里按字段的重要性从高往低的顺序讲解一下。</p><blockquote><p><strong>sequence number</strong>：序号，用于记录包的顺序。这与上面我们自己实现拆包、组包是同样的道理。</p><p><strong>timestamp</strong>：时间戳，同一个帧的不同分片的时间戳是相同的。这样就省去了前面所讲的 <strong>起始标记</strong> 和 <strong>结束标记</strong>。一定要记住，<strong>不同帧的时间戳肯定是不一样的</strong>。</p><p><strong>PT</strong>：Payload Type，数据的负载类型。音频流的 PT 值与视频的 PT 值是不同的，通过它就可以知道这个包存放的是什么类型的数据。</p><p>……</p></blockquote><p>这里，我并没有将 RTP 协议头中的所有字段的详细说明都列在这儿，如果你想了解所有字段的含义，可以到参考一节查看其他字段的含义。需要注意的是，这里没有将它们列出来并不代表它们不重要。恰恰相反，如果你想做音视频传输相关的工作，RTP 头中的每个字段的含义你都必须全部清楚。</p><p>知道了上面这些字段的含义后，下面我们还是来看一个具体的例子吧！假设你从网上接收到一组音视频数据，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:98,seq:13,ts:1122334455,ssrc=2345&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:111,seq:14,ts:1122334455,ssrc=888&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:98,seq:14,ts:1122334455,ssrc=2345&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:111,seq:15,ts:1122334455,ssrc=888&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:98,seq:15,ts:1122334455,ssrc=2345&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:111,seq:16,ts:1122334455,ssrc=888&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:98,seq:16,ts:1122334455,ssrc=2345&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:111,seq:17,ts:1122334455,ssrc=888&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:98,seq:17,ts:1122334455,ssrc=2345&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:111,seq:18,ts:1122334455,ssrc=888&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:98,seq:18,ts:1122334455,ssrc=2345&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:111,seq:19,ts:1122334455,ssrc=888&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:98,seq:19,ts:1122334455,ssrc=2345&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:111,seq:20,ts:1122334455,ssrc=888&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=1,PT:98,seq:20,ts:1122334455,ssrc=2345&#125;,</span><br></pre></td></tr></table></figure><p>假设 PT=98 是视频数据，PT=111 是音频数据，那么按照上面的规则你是不是很容易就能将视频帧组装起来呢？</p><h5 id="RTCP-协议"><a href="#RTCP-协议" class="headerlink" title="RTCP 协议"></a>RTCP 协议</h5><p>在使用 RTP 包传输数据时，难免会发生丢包、乱序、抖动等问题，下面我们来看一下使用的网络一般都会在什么情况下出现问题：</p><blockquote><p>网络线路质量问题引起丢包率高;</p><p>传输的数据超过了带宽的负载引起的丢包问题;</p><p>信号干扰（信号弱）引起的丢包问题;</p><p>跨运营商引入的丢包问题;</p><p>……</p></blockquote><p>WebRTC 对这些问题在底层都有相应的处理策略，但在处理这些问题之前，它首先要让各端都知道它们自己的网络质量到底是怎样的，这就是 RTCP 的作用。</p><p><strong>RTCP 有两个最重要的报文：RR（Reciever Report）和 SR(Sender Report)。通过这两个报文的交换，各端就知道自己的网络质量到底如何了。</strong></p><p>RTCP 支持的所有报文及其含义可以查看文章最后所附的参考一节。这里我们以 SR 报文为例，看看 SR 报文中都包括哪些信息。</p><p>下面我就简要说明一下该报文中字段的含义：</p><blockquote><p>V=2，指报文的版本。</p><p>P，表示填充位，如果该位置 1，则在 RTCP 报文的最后会有填充字节（内容是按字节对齐的）。</p><p>RC，全称 Report Count，指 RTCP 报文中接收报告的报文块个数。</p><p>PT=200，Payload Type，也就是说 SR 的值为 200。</p><p>……</p></blockquote><p>与 RTP 协议头一样，上面只介绍了 RTCP 头字段的含义，至于其他每个字段的含义请查看参考一节。同样的，对于 RTCP 头中的每个字段也必须都非常清楚，只有这样以后你在看 WebRTC 带宽评估相关的代码时，才不至于晕头转向。从上图中我们可以了解到，SR 报文分成三部分：Header、Sender info 和 Report block。在 NTP 时间戳之上的部分为 SR 报文的 Header 部分，SSRC_1 字段之上到 Header 之间的部分为 Sender info 部分，剩下的就是一个一个的 Report Block 了。那这每一部分是用于干什么的呢？</p><blockquote><p>Header 部分用于标识该报文的类型，比如是 SR 还是 RR。</p><p>Sender info 部分用于指明作为发送方，到底发了多少包。</p><p>Report block 部分指明发送方作为接收方时，它从各个 SSRC 接收包的情况。</p></blockquote><p>通过以上的分析，你可以发现 SR 报文并不仅是指发送方发了多少数据，它还报告了作为接收方，它接收到的数据的情况。当发送端收到对端的接收报告时，它就可以根据接收报告来评估它与对端之间的网络质量了，随后再根据网络质量做传输策略的调整。</p><p><strong>SR</strong> 报文与 <strong>RR</strong> 报文无疑是 RTCP 协议中最重要的两个报文，不过 RTCP 中的其他报文也都非常重要的，如果你想学好 WebRTC ，那么 RTCP 中的每个报文你都必须掌握。</p><p>比如，RTCP 类型为 206、子类型为 4 的 FIR 报文，其含义是 Full Intra Request (FIR) Command，即 <strong>完整帧请求</strong> 命令。它起什么作用？又在什么时候使用呢？</p><p>该报文也是一个特别关键的报文，我为什么这么说呢？试想一下，在一个房间里有 3 个人进行音视频聊天，然后又有一个人加入到房间里，这时如果不做任何处理的话，那么第四个人进入到房间后，在一段时间内很难直接看到其他三个人的视频画面了，这是为什么呢？</p><p>原因就在于解码器在解码时有一个上下文。在该上下文中，必须先拿到一个 IDR 帧之后才能将其后面的 P 帧、B 帧进行解码。也就是说，在没有 IDR 帧的情况下，对于收到的 P 帧、B 帧解码器只能干瞪眼了。</p><p>如何解决这个问题呢？这就引出了 FIR 报文。当第四个人加入到房间后，它首先发送 FIR 报文，当其他端收到该报文后，便立即产生各自的 IDR 帧发送给新加入的人，这样当新加入的人拿到房间中其他的 IDR 帧后，它的解码器就会解码成功，于是其他人的画面也就一下子全部展示出来了。所以你说它是不是很重要呢？</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;WebRTC 技术是激烈的开放的 Web 战争中一大突破。- Brendan Eich, inventor of Java&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;UDP-还是-TCP？&quot;&gt;&lt;a href=&quot;#UDP-还是-TCP？&quot; class=&quot;headerlink&quot; title=&quot;UDP 还是 TCP？&quot;&gt;&lt;/a&gt;UDP 还是 TCP？&lt;/h4&gt;&lt;p&gt;如果抛开 WebRTC，让你自己实现一套实时互动直播系统，在选择网络传输协议时，你会选择使用 UDP 协议还是 TCP 协议呢？&lt;/p&gt;
&lt;p&gt;这个问题在 2011 年至 2012 年一直是一件困扰着我们整个团队的大事儿，因为当时在国内很少有用 UDP 作为底层传输协议的。UDP 虽然传输快，但不可靠，尤其是在用户的网络质量很差的情况下，基本无法保障音视频的服务质量。&lt;/p&gt;
&lt;p&gt;当时能想到的解决方案是，如果采用 UDP 作为底层传输协议，那就使用 RUDP（可靠性 UDP），只有这样才能保障传输过程中不丢包。但有人提出反对意见，认为如果想不丢包，就该使用 TCP，因为 RUDP 可靠性做到极致就变成 TCP 了，那为什么不直接使用 TCP 呢？&lt;/p&gt;
&lt;p&gt;面对这种情况，2019 年的你会做何种选择呢？UDP 还是 TCP？你能拿出让人真正信服的理由吗？&lt;/p&gt;
&lt;p&gt;现在让我告诉你正确答案：&lt;strong&gt;必须使用 UDP，必须使用 UDP，必须使用 UDP&lt;/strong&gt;，重要的事情说三遍。&lt;/p&gt;
    
    </summary>
    
      <category term="WebRTC" scheme="http://xiaolong.li/categories/WebRTC/"/>
    
    
      <category term="RTP" scheme="http://xiaolong.li/tags/RTP/"/>
    
      <category term="RTCP" scheme="http://xiaolong.li/tags/RTCP/"/>
    
      <category term="WebRTC" scheme="http://xiaolong.li/tags/WebRTC/"/>
    
  </entry>
  
</feed>
