<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>NO WAY OUT | 无往不前</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://xiaolong.li/"/>
  <updated>2021-09-16T14:23:28.586Z</updated>
  <id>http://xiaolong.li/</id>
  
  <author>
    <name>xiaolong</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MySQL 索引及优化技巧</title>
    <link href="http://xiaolong.li/2021/09/16/mysql-index/"/>
    <id>http://xiaolong.li/2021/09/16/mysql-index/</id>
    <published>2021-09-16T11:17:59.000Z</published>
    <updated>2021-09-16T14:23:28.586Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h4 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h4><p>MySQL 性能优化包括很多方面，比如数据库设计、参数配置(软&amp;硬)、sql语句、读写分离、分表技术（水平拆分、垂直拆分）等，完整的 MySQL 优化需要很深的功底，掌握这些知识不是一朝一夕可以完成的事情。本文章主要针对 sql 语句优化中的索引优化开展。</p><a id="more"></a><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><h5 id="什么是索引？"><a href="#什么是索引？" class="headerlink" title="什么是索引？"></a>什么是索引？</h5><p>MySQL 官方对索引的定义：索引是帮助 MySQL 高效获取数据的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。我们可以理解索引就是一本书的目录，它会让你更快的找到需要的内容。</p><h5 id="为什么要用索引？"><a href="#为什么要用索引？" class="headerlink" title="为什么要用索引？"></a>为什么要用索引？</h5><p>在无索引的情况下，MySQL 会扫描整张表来查找符合 sql 条件的记录，其时间开销与表中数据量呈正相关，使用索引主要为了加快查询速度和保证数据的唯一性。</p><h5 id="索引种类"><a href="#索引种类" class="headerlink" title="索引种类"></a>索引种类</h5><p>从数据结构角度： </p><ol><li>B-Tree树索引(O(log(n)))</li><li>hash索引O(1)</li><li>fulltext索引 </li><li>R-Tree索引 </li></ol><p>从物理存储角度： </p><ol><li>聚集索引（clustered index） </li><li>非聚集索引（non-clustered index） </li></ol><p>从逻辑角度： </p><ol><li>主键索引：主键索引是一种特殊的唯一索引，不允许有空值 </li><li>普通索引或者单列索引 </li><li>多列索引（复合索引）：复合索引指多个字段上创建的索引</li><li>唯一索引或者非唯一索引 </li><li>空间索引：空间索引是对空间数据类型的字段建立的索引，MYSQL 中的空间数据类型有4种，分别是 GEOMETRY、POINT、LINESTRING、POLYGON。MYSQL 使用 SPATIAL 关键字进行扩展，使得能够用于创建正规索引类型的语法创建空间索引。创建空间索引的列，必须将其声明为 NOT NULL</li></ol><h5 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点:"></a>优缺点:</h5><p>优点：</p><ol><li>可以通过建立唯一索引或者主键索引,保证数据库表中每一行数据的唯一性</li><li>建立索引可以大大提高检索的数据,以及减少表的检索行数</li><li>在表连接的连接条件可以加速表与表直接的相连 4.减少查询中分组和排序的时间 5.建立索引,在查询中使用索引可以提高性能</li></ol><p>缺点：</p><ol><li>在创建索引和维护索引会耗费时间,随着数据量的增加而增加</li><li>索引文件会占用物理空间,除了数据表需要占用物理空间之外,每一个索引还会占用一定的物理空间</li></ol><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>此处不进行描述，具体参考：<a href="http://blog.codinglabs.org/articles/theory-of-mysql-index.html" target="_blank" rel="noopener">http://blog.codinglabs.org/articles/theory-of-mysql-index.html</a></p><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><h5 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h5><table><thead><tr><th>场景</th><th>描述</th></tr></thead><tbody><tr><td>全值匹配</td><td>查询条件和索引列完全匹配，如：联合索引(a,b),查询 a=? and b=?</td></tr><tr><td>匹配最左前缀</td><td>查询条件中的所有字段需要从左边起按顺序出现在多列索引中，如：联合索引(a,b),查询 a=?</td></tr><tr><td>匹配列前缀</td><td>查询条件只匹配某一索引列的开头部分，如：联合索引(a,b),查询 a like ’?%’</td></tr><tr><td>匹配范围值</td><td>查询条件匹配索引列的范围，如：联合索引(a,b),查询 a &gt; ?</td></tr><tr><td>精确匹配某一列并范围匹配另外一列</td><td>如：联合索引(a,b),查询 a =? and b&gt;?</td></tr><tr><td>多表做join操作时</td><td>如：表t1,索引(a),表t2,索引(b),查询 t1 left join t2 on t2.b = t1.a</td></tr><tr><td>order by操作时</td><td>如：联合索引(a,b),查询 a = ? order by b desc</td></tr><tr><td>group by操作时</td><td>如：联合索引(a,b),查询 a = ? group by b desc</td></tr></tbody></table><h5 id="explain介绍"><a href="#explain介绍" class="headerlink" title="explain介绍"></a>explain介绍</h5><p>和大家普及一下如何查看sql的索引使用情况，即sql的执行计划： Explain详解</p><table><thead><tr><th>属性名称</th><th>说明</th></tr></thead><tbody><tr><td>id</td><td>SELECT识别符。这是SELECT的查询序列号</td></tr><tr><td>select_type</td><td>SELECT类型,可以为以下任何一种: SIMPLE:简单SELECT(不使用UNION或子查询) PRIMARY:最外面的SELECT UNION:UNION中的第二个或后面的SELECT语句 DEPENDENT UNION:UNION中的第二个或后面的SELECT语句,取决于外面的查询 UNION RESULT:UNION 的结果 SUBQUERY:子查询中的第一个SELECT DEPENDENT SUBQUERY:子查询中的第一个SELECT,取决于外面的查询 DERIVED:导出表的SELECT(FROM子句的子查询)</td></tr><tr><td>table</td><td>输出的行所引用的表</td></tr><tr><td>type</td><td>联接类型。下面给出各种联接类型,按照从最佳类型到最坏类型进行排序: system:表仅有一行(=系统表)。这是const联接类型的一个特例。 const:表最多有一个匹配行,它将在查询开始时被读取。因为仅有一行,在这行的列值可被优化器剩余部分认为是常数。const表很快,因为它们只读取一次! eq_ref:对于每个来自于前面的表的行组合,从该表中读取一行。这可能是最好的联接类型,除了const类型。 ref:对于每个来自于前面的表的行组合,所有有匹配索引值的行将从这张表中读取。 ref_or_null:该联接类型如同ref,但是添加了MySQL可以专门搜索包含NULL值的行。 index_merge:该联接类型表示使用了索引合并优化方法。 unique_subquery:该类型替换了下面形式的IN子查询的ref: value IN (SELECT primary_key FROM single_table WHERE some_expr) unique_subquery是一个索引查找函数,可以完全替换子查询,效率更高。 index_subquery:该联接类型类似于unique_subquery。可以替换IN子查询,但只适合下列形式的子查询中的非唯一索引: value IN (SELECT key_column FROM single_table WHERE some_expr) range:只检索给定范围的行,使用一个索引来选择行。 index:该联接类型与ALL相同,除了只有索引树被扫描。这通常比ALL快,因为索引文件通常比数据文件小。 ALL:对于每个来自于先前的表的行组合,进行完整的表扫描。</td></tr><tr><td>possible_keys</td><td>查询可能使用的索引</td></tr><tr><td>key</td><td>查询真正使用到的索引，select_type为index_merge时，这里可能出现两个以上的索引，其他的 select_type 这里只会出现一个</td></tr><tr><td>key_len</td><td>用于处理查询的索引长度</td></tr><tr><td>ref</td><td>显示使用哪个列或常数与key一起从表中选择行</td></tr><tr><td>rows</td><td>查询中应该检索的记录数</td></tr><tr><td>extra</td><td>该列包含MySQL解决查询的详细信息 Distinct:MySQL发现第1个匹配行后,停止为当前的行组合搜索更多的行。 Not exists:MySQL能够对查询进行LEFT JOIN优化,发现1个匹配LEFT JOIN标准的行后,不再为前面的的行组合在该表内检查更多的行。 range checked for each record (index map: #):MySQL没有发现好的可以使用的索引,但发现如果来自前面的表的列值已知,可能部分索引可以使用。 Using filesort:MySQL需要额外的一次传递,以找出如何按排序顺序检索行。 Using index:从只使用索引树中的信息而不需要进一步搜索读取实际的行来检索表中的列信息。 Using temporary:为了解决查询,MySQL需要创建一个临时表来容纳结果。 Using where:WHERE 子句用于限制哪一个行匹配下一个表或发送到客户。 Using sort_union(…), Using union(…), Using intersect(…):这些函数说明如何为index_merge联接类型合并索引扫描。 Using index for group-by:类似于访问表的Using index方式,Using index for group-by表示MySQL发现了一个索引,可以用来查 询GROUP BY或DISTINCT查询的所有列,而不要额外搜索硬盘访问实际的表。</td></tr></tbody></table><h5 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h5><p>一般情况：一次查询至多使用一个索引，即每次查询时，不管建立了多少个索引，最多只会用到其中一个，如：<br>单列索引(a),(b),©,查询 a=? and b=? and c=?，只会用到单列索引(a)。特殊情况：索引合并会使用多个索引，如果执行计划中type列显示index_merge,则说明出现了索引合并；<br>建立索引的列，索引的选择性要高，即指索引中不重复的值的数目（也称基数，a）与整个表该列记录总数（b）的比值，比如一个列表（1,2,2,3），总数是4，不重复值数目为3，选择性为3/4，选择性的取值范围为(0, 1]，这个值越大，表示列中不重复值越多，越适合作为前缀索引，唯一索引（UNIQUE KEY）的选择性是1;<br>sql查询时一定不要出现隐式转换，当产生隐式转换时，查询不走索引，所谓隐式转换，即指where条件语句里，字段属性和赋给的条件，当数据类型不一样，这时候是没法直接比较的，需要进行一致转换,如：单列索引(a),字符类型，查询 a=1 ,这样的查询会把表中的a字段全部转换成整型，并且无法使用索引(a);<br>使用索引需要满足最左前缀原则，如：联合索引(a,b,c),查询 a=?或者a=? and b=? 或者a=? and b=? and c=?可以使用联合索引(a,b,c) ，但是b=?或者c=?或者b=? and c=?不能使用联合索引(a,b,c) ;<br>当查询条件是范围时，范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引，如：联合索引(a,b),查询 a&gt;? and b&gt;?，这样的查询可以用到联合索引中的a部分，b部分没有使用；<br>当查询条件是范围时，范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引，如：联合索引(a,b),查询 a&gt;? and b&gt;?，这样的查询可以用到联合索引中的a部分，b部分没有使用；<br>使用order by进行查询排序时，如果排序字段非索引列，执行计划的extra列会是“Using filesort”；<br>使用group by进行分组查询时，一般是先根据分组字段排序再进行分组，如果分组字段非索引列，执行计划的extra列会是“Using temporary; Using filesort”；<br>查询时优先使用覆盖索引，何为覆盖索引？即指所有数据都可以从索引中得到，而不需要去读物理记录。例如某个联合索引(a,b,c)建立在表tb1 的 a、b、c 列上，那么对于如下的sql 语句select a,b from tb1 where a = ? and b = ? and c =?,mysql可以直接从索引(a,b,c)中获取数据。使用explain 命令输出查询计划，如果extra列是“using index ”那就表示使用的是覆盖索引;<br>查询条件中含有函数或者表达式，mysql不会使用索引，如：索引(a),查询 left(a,6)=?, 同时 !=、&lt;&gt;不走索引，or前后的条件都要有索引整个SQL才会使用索引，只要有一个条件没索引那么整个SQL都不使用索引；<br>每个查询是否使用索引，不仅取决于索引建立是否合适，同时也取决于查询筛选记录占全表记录的大小，优化器会判断利用索引筛选出来的记录是否小于全表记录的30%，如果小于，使用索引，反之不会；<br>mysql不能使用索引中范围条件右边的列，如：联合索引(a,b,c),查询 a=? and b&gt;? and c=?,其中索引的a,b列可以用到，但是c列用不到；<br>索引数据类型选择通常遵循以下指导原则： 1)越小的数据类型通常更好：越小的数据类型通常在磁盘、内存和CPU缓存中都需要更少的空间，处理起来更快。2)简单的数据类型更好：整型数据比起字符，处理开销更小，因为字符串的比较更复杂。在MySQL中，应该用内置的日期和时间数据类型，而不是用字符串来存储时间；3)尽量避免NULL：应该指定列为NOT NULL，除非你想存储NULL。在MySQL中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂，同时NULL存储也是需要占用空间的。应该用0、一个特殊的值或者一个空串代替空值。</p><h4 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h4><ol><li>联合索引(a,b),查询 a=? and b=? 和b=? and a=?,哪个会命中索引？查询a=?和b=?，哪个会使用索引？ </li><li>联合索引(a,b),查询 a&gt;? and b&gt;? 和b&gt;? and a&gt;?, 索引是如何使用的？ </li><li>联合索引(end_time,user_id)，查询select type from um_user_vip_record where user_id =? and end_time &gt; now() order by end_time limit 1，索引的使用情况？ </li><li>以下sql如何优化：  </li><li>联合索引(a,b,c,d),以下查询的索引使用情况 A、where a=? and b=? and d&gt;? and c=? B、where a=? and b=? and d=? order by c C、where a=? and d=? group by c,b D、where a=? and e=? order by b,c E、where a=? and b=? and e=? order by b,c </li></ol><p>注：如何知道具体使用了索引的哪一列，可以根据执行计划的key_len得出！</p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h4&gt;&lt;p&gt;MySQL 性能优化包括很多方面，比如数据库设计、参数配置(软&amp;amp;硬)、sql语句、读写分离、分表技术（水平拆分、垂直拆分）等，完整的 MySQL 优化需要很深的功底，掌握这些知识不是一朝一夕可以完成的事情。本文章主要针对 sql 语句优化中的索引优化开展。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>gRPC 对比 WebSocket</title>
    <link href="http://xiaolong.li/2021/09/16/grpc-vs-websocket/"/>
    <id>http://xiaolong.li/2021/09/16/grpc-vs-websocket/</id>
    <published>2021-09-16T09:45:03.000Z</published>
    <updated>2021-09-16T14:11:41.996Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h4 id="gRPC"><a href="#gRPC" class="headerlink" title="gRPC"></a>gRPC</h4><p>gRPC 是一个远程过程调用框架，默认使用 protobuf3 进行数据的高效序列化与 service 定义，使用 HTTP/2 进行数据传输。 这里讨论的是 <a href="https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md" target="_blank" rel="noopener">gRPC over HTTP/2</a> 协议。</p><p>目前 gRPC 主要被用在微服务通信中，但是因为其优越的性能，它也很契合游戏、loT 等需要高性能低延迟的场景。</p><p>其实从协议先进程度上讲，gRPC 基本全面超越 REST:</p><ol><li>使用二进制进行数据序列化，比 json 更节约流量、序列化与反序列化也更快。</li><li>protobuf3 要求 api 被完全清晰的定义好，而 REST api 只能靠程序员自觉定义。</li><li>gRPC 官方就支持从 api 定义生成代码，而 REST api 需要借助 openapi-codegen 等第三方工具。</li><li>支持 4 种通信模式：一对一(unary)、客户端流、服务端流、双端流。更灵活</li></ol><a id="more"></a><p>只是 <strong>目前 gRPC 对 broswer 的支持仍然不是很好</strong>，如果你需要通过浏览器访问 api，那 gRPC 可能不是你的菜。 如果你的产品只打算面向 App 等可控的客户端，可以考虑上 gRPC。</p><p>对同时需要为浏览器和 APP 提供服务应用而言，也可以考虑 APP 使用 gRPC 协议，而浏览器使用 API 网关提供的 HTTP 接口，在 API 网关上进行 HTTP - gRPC 协议转换。</p><h5 id="gRPC-over-HTTP-2-定义"><a href="#gRPC-over-HTTP-2-定义" class="headerlink" title="gRPC over HTTP/2 定义"></a>gRPC over HTTP/2 定义</h5><p>详细的定义参见官方文档 <a href="https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md" target="_blank" rel="noopener">gRPC over HTTP/2</a> .</p><p>这里是简要说明几点：</p><ol><li>gRPC 完全隐藏了 HTTP/2 本身的 method、headers、path 等语义，这些信息对用户而言完全不可见了。<br>请求统一使用 POST，响应状态统一为 200。只要响应是标准的 gRPC 格式，响应中的 HTTP 状态码将被完全忽略。</li><li>gRPC 定义了自己的 status 状态码、格式固定的 path、还有它自己的 headers。</li></ol><h4 id="WebSocket"><a href="#WebSocket" class="headerlink" title="WebSocket"></a>WebSocket</h4><p>WebSocket 是一个双向通信协议，它在握手阶段采用 HTTP/1.1 协议（暂时不支持 HTTP/2）。</p><p>握手过程如下：</p><ol><li>首先客户端向服务端发起一个特殊的 HTTP 请求，其消息头如下：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /chat HTTP/1.1  // 请求行</span><br><span class="line">Host: server.example.com</span><br><span class="line">Upgrade: websocket  // required</span><br><span class="line">Connection: Upgrade // required</span><br><span class="line">Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ== // required，一个 16bits 编码得到的 base64 串</span><br><span class="line">Origin: http://example.com  // 用于防止未认证的跨域脚本使用浏览器 websocket api 与服务端进行通信</span><br><span class="line">Sec-WebSocket-Protocol: chat, superchat  // optional, 子协议协商字段</span><br><span class="line">Sec-WebSocket-Version: 13</span><br></pre></td></tr></table></figure><ol start="2"><li>如果服务端支持该版本的 WebSocket，会返回 101 响应，响应标头如下：</li></ol><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 <span class="number">101</span> Switching Protocols  // 状态行</span><br><span class="line"><span class="attribute">Upgrade</span>: websocket   // required</span><br><span class="line"><span class="attribute">Connection</span>: Upgrade  // required</span><br><span class="line"><span class="attribute">Sec-WebSocket-Accept</span>: s3pPLMBiTxaQ9kYGzzhZRbK+xOo= // required，加密后的 Sec-WebSocket-Key</span><br><span class="line"><span class="attribute">Sec-WebSocket-Protocol</span>: chat // 表明选择的子协议</span><br></pre></td></tr></table></figure><p>握手完成后，接下来的 TCP 数据包就都是 WebSocket 协议的帧了。</p><p>可以看到，这里的握手不是 TCP 的握手，而是在 TCP 连接内部，从 HTTP/1.1 upgrade 到 WebSocket 的握手。</p><p>WebSocket 提供两种协议：不加密的 ws:// 和 加密的 wss://. 因为是用 HTTP 握手，它和 HTTP 使用同样的端口：ws 是 80（HTTP），wss 是 443（HTTPS）</p><h4 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h4><p>gRPC 实际上并不是比较的相关部分，而是 gRPC 使用 的 HTTP/2 与 WebSockets 进行比较。这里借鉴 InfoQ 上的一篇文章 <a href="https://www.infoq.com/articles/websocket-and-http2-coexist/" target="_blank" rel="noopener">WebSocket 能否在 HTTP/2 中存活下来？</a></p><p>虽然 HTTP/2 提供了很多机制，它并不能完全取代现有的推/流媒体技术的需要。</p><p>关于 HTTP/2 的第一个重要的事情是它并不能替代所有的 HTTP 。verb、状态码和大部分头信息将保持与目前版本一致。HTTP/2 是意在提升数据在线路上传输的效率。</p><p>比较 HTTP/2 和 WebSocket ，可以看到很多类似之处：</p><table><thead><tr><th>-</th><th>HTTP/2</th><th>WebSocket</th></tr></thead><tbody><tr><td>Headers</td><td>Compressed (HPACK)</td><td>None</td></tr><tr><td>Binary</td><td>Yes</td><td>Binary or Textual</td></tr><tr><td>Multiplexing</td><td>Yes</td><td>Yes</td></tr><tr><td>Prioritization</td><td>Yes</td><td>No</td></tr><tr><td>Compression</td><td>Yes</td><td>Yes</td></tr><tr><td>Direction</td><td>CLient/Server + Server Push</td><td>Bidirectional</td></tr><tr><td>Full-duplex</td><td>Yes</td><td>Yes</td></tr></tbody></table><h4 id="如何选择"><a href="#如何选择" class="headerlink" title="如何选择"></a>如何选择</h4><p>WebSockets 肯定会在 HTTP/2 + SSE 的领域中生存下来，主要是因为它是一种已经被很好地应用的技术，并且在非常具体的使用情况下，它比 HTTP/2 更具优势，因为它已经被构建用于具有较少开销(如报头)的双向功能。</p><p>假设你想建立一个大型多人在线游戏，需要来自连接两端的大量消息。在这种情况下，WebSockets 的性能会好很多。</p><p>一般情况下，只要需要客户端和服务器之间的真正 <strong>低延迟</strong> ，接近实时的连接，就使用 WebSocket 。请记住，这可能需要重新考虑如何构建服务器端应用程序，以及将焦点转移到队列事件等技术上。</p><p>如果你使用的方案需要显示实时的市场消息，市场数据，聊天应用程序等，依靠 HTTP/2 + SSE 将为你提供高效的双向通信渠道，同时获得留在 HTTP 领域的各种好处：</p><p>当考虑到与现有 Web 基础设施的兼容性时，WebSocket 通常会变成一个痛苦的源头，因为它将 HTTP 连接升级到完全不同于 HTTP 的协议。</p><p>规模和安全性：Web 组件（防火墙，入侵检测，负载均衡）是以 HTTP 为基础构建，维护和配置的，这是大型/关键应用程序在弹性，安全性和可伸缩性方面更喜欢的环境。</p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;gRPC&quot;&gt;&lt;a href=&quot;#gRPC&quot; class=&quot;headerlink&quot; title=&quot;gRPC&quot;&gt;&lt;/a&gt;gRPC&lt;/h4&gt;&lt;p&gt;gRPC 是一个远程过程调用框架，默认使用 protobuf3 进行数据的高效序列化与 service 定义，使用 HTTP/2 进行数据传输。 这里讨论的是 &lt;a href=&quot;https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;gRPC over HTTP/2&lt;/a&gt; 协议。&lt;/p&gt;
&lt;p&gt;目前 gRPC 主要被用在微服务通信中，但是因为其优越的性能，它也很契合游戏、loT 等需要高性能低延迟的场景。&lt;/p&gt;
&lt;p&gt;其实从协议先进程度上讲，gRPC 基本全面超越 REST:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用二进制进行数据序列化，比 json 更节约流量、序列化与反序列化也更快。&lt;/li&gt;
&lt;li&gt;protobuf3 要求 api 被完全清晰的定义好，而 REST api 只能靠程序员自觉定义。&lt;/li&gt;
&lt;li&gt;gRPC 官方就支持从 api 定义生成代码，而 REST api 需要借助 openapi-codegen 等第三方工具。&lt;/li&gt;
&lt;li&gt;支持 4 种通信模式：一对一(unary)、客户端流、服务端流、双端流。更灵活&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Redis 高可用方案</title>
    <link href="http://xiaolong.li/2021/09/14/High-Availability-for-Redis/"/>
    <id>http://xiaolong.li/2021/09/14/High-Availability-for-Redis/</id>
    <published>2021-09-14T15:24:03.000Z</published>
    <updated>2021-09-16T14:11:58.571Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p>Redis 中为了实现高可用（High Availability，简称 HA ），采用了如下两个方式：</p><ol><li>哨兵( Sentinel )：可以管理多个 Redis 服务器，它提供了监控，提醒以及自动的故障转移的功能。</li><li>复制( Replication )：则是负责让一个 Redis 服务器可以配备多个备份的服务器。</li></ol><blockquote><p>主从模式（Redis 2.8 版本之前的模式）、哨兵 sentinel 模式（Redis 2.8 及之后的模式）、redis cluster模式（Redis 3.0版本之后）</p></blockquote><a id="more"></a><h4 id="主从模式"><a href="#主从模式" class="headerlink" title="主从模式"></a>主从模式</h4><p>同 Mysql 主从复制的原因一样，Redis 虽然读取写入的速度都特别快，但是也会产生读压力特别大的情况。为了分担读压力，Redis 支持主从复制，主从结构可以采用一主多从或者级联结构，Redis 主从复制可以根据是否是全量分为全量同步和增量同步。下图为级联结构。</p><p>全量同步<br>Redis全量复制- -般发生在Slave初始化阶段，这时Slave需 要将Master,上的所有数据都复制-份。具体步骤如下:<br>-从服务器连接主服务器，发送SYNC命令;<br>-主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令;<br>-主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令;<br>-从服务器收到快照文件后丢弃所有旧数据，载入收到的快照;<br>-主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令;<br>-从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令;</p><h4 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h4><h4 id="集群模式"><a href="#集群模式" class="headerlink" title="集群模式"></a>集群模式</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Redis 中为了实现高可用（High Availability，简称 HA ），采用了如下两个方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;哨兵( Sentinel )：可以管理多个 Redis 服务器，它提供了监控，提醒以及自动的故障转移的功能。&lt;/li&gt;
&lt;li&gt;复制( Replication )：则是负责让一个 Redis 服务器可以配备多个备份的服务器。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;主从模式（Redis 2.8 版本之前的模式）、哨兵 sentinel 模式（Redis 2.8 及之后的模式）、redis cluster模式（Redis 3.0版本之后）&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://xiaolong.li/categories/Redis/"/>
    
    
      <category term="redis" scheme="http://xiaolong.li/tags/redis/"/>
    
      <category term="高可用" scheme="http://xiaolong.li/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    
      <category term="哨兵" scheme="http://xiaolong.li/tags/%E5%93%A8%E5%85%B5/"/>
    
  </entry>
  
  <entry>
    <title>Redis 缓存穿透、缓存击穿、缓存雪崩和解决方案</title>
    <link href="http://xiaolong.li/2021/09/04/Redis-Cache-Penetration-Breakdown-Avalanches-and-Solutions/"/>
    <id>http://xiaolong.li/2021/09/04/Redis-Cache-Penetration-Breakdown-Avalanches-and-Solutions/</id>
    <published>2021-09-04T13:42:29.000Z</published>
    <updated>2021-09-04T14:28:40.325Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p>设计一个缓存系统，不得不要考虑的问题就是：缓存穿透、缓存击穿与失效时的雪崩效应。</p><h4 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h4><h5 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h5><blockquote><p>缓存穿透：是指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，进而给数据库带来压力。</p></blockquote><a id="more"></a><h5 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h5><p>解决穿透一般有三种方法：</p><ol><li>如果是非法请求，可以在API入口，对参数进行校验，过滤非法值。</li><li>如果查询数据库为空，可以给缓存设置个空值，或者默认值。但是如有有写请求进来的话，需要更新缓存哈，以保证缓存一致性，同时，最后给缓存设置适当的过期时间。（业务上比较常用，简单有效）</li><li>使用 布隆过滤器 快速判断数据是否存在。即一个查询请求过来时，先通过布隆过滤器判断值是否存在，存在才继续往下查。</li></ol><blockquote><p>布隆过滤器原理：它由初始值为 0 的位图数组和 N 个哈希函数组成。一个对一个 key 进行 N 个 hash 算法获取 N 个值，在比特数组中将这 N 个值散列后设定为 1，然后查的时候如果特定的这几个位置都为 1，那么布隆过滤器判断该 key 存在。</p></blockquote><h4 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h4><h5 id="原因-1"><a href="#原因-1" class="headerlink" title="原因"></a>原因</h5><blockquote><p>缓存雪奔：是指缓存中数据大批量到过期时间，而查询数据量巨大，请求都直接访问数据库，引起数据库压力过大甚至 down 机。</p></blockquote><p>当然，Redis 故障宕机也可能引起缓存雪奔。</p><h5 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h5><ol><li>考虑用加锁或者队列的方式保证缓存的单线程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。</li><li>可以给缓存设置过期时间时加上一个随机值时间，使得每个 key 的过期时间分布开来，不会集中在同一时刻失效。</li><li>Redis 高可用集群。</li></ol><h4 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h4><h5 id="原因-2"><a href="#原因-2" class="headerlink" title="原因"></a>原因</h5><blockquote><p>缓存击穿：是指热点 key 在某个时间点过期的时候，而恰好在这个时间点对这个 Key 有大量的并发请求过来，从而大量的请求打到数据库，进而给数据库带来压力。</p></blockquote><h5 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h5><ol><li>使用互斥锁方案。缓存失效时，不是立即去加载 db 数据，而是先使用某些带成功返回的原子操作命令，如 (Redis的setnx) 去操作，成功则再去加载 db 数据库数据和设置缓存，否则就去重试获取缓存。</li><li>“永不过期”，是指没有设置过期时间，但是热点数据快要过期时，异步线程去更新和设置过期时间。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;设计一个缓存系统，不得不要考虑的问题就是：缓存穿透、缓存击穿与失效时的雪崩效应。&lt;/p&gt;
&lt;h4 id=&quot;缓存穿透&quot;&gt;&lt;a href=&quot;#缓存穿透&quot; class=&quot;headerlink&quot; title=&quot;缓存穿透&quot;&gt;&lt;/a&gt;缓存穿透&lt;/h4&gt;&lt;h5 id=&quot;原因&quot;&gt;&lt;a href=&quot;#原因&quot; class=&quot;headerlink&quot; title=&quot;原因&quot;&gt;&lt;/a&gt;原因&lt;/h5&gt;&lt;blockquote&gt;
&lt;p&gt;缓存穿透：是指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，进而给数据库带来压力。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://xiaolong.li/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://xiaolong.li/tags/Redis/"/>
    
      <category term="缓存穿透" scheme="http://xiaolong.li/tags/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F/"/>
    
      <category term="缓存雪崩" scheme="http://xiaolong.li/tags/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9/"/>
    
      <category term="缓存击穿" scheme="http://xiaolong.li/tags/%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF/"/>
    
  </entry>
  
  <entry>
    <title>布隆过滤器</title>
    <link href="http://xiaolong.li/2021/09/01/Introduction-to-Bloom-Filter/"/>
    <id>http://xiaolong.li/2021/09/01/Introduction-to-Bloom-Filter/</id>
    <published>2021-09-01T13:15:31.000Z</published>
    <updated>2021-09-04T17:16:35.310Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><blockquote><p>Data structures are nothing different. They are like the bookshelves of your application where you can organize your data. Different data structures will give you different facility and benefits. To properly use the power and accessibility of the data structures you need to know the trade-offs of using one.</p></blockquote><blockquote class="blockquote-center"><p>不同的数据结构有不同的适用场景和优缺点，你需要仔细权衡自己的需求之后妥善适用它们</p></blockquote><p><strong>布隆过滤器就是践行这句话的代表</strong></p><a id="more"></a><h4 id="什么是布隆过滤器"><a href="#什么是布隆过滤器" class="headerlink" title="什么是布隆过滤器"></a>什么是布隆过滤器</h4><p>布隆过滤器本质上是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure），特点是高效地插入和查询，可以用来告诉你 <strong>某样东西一定不存在或者可能存在</strong>。</p><p>相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。</p><ul><li><p>优点：</p><blockquote><p>不需要存储 key ，空间占用很小<br>高效地插入和查询</p></blockquote></li><li><p>缺点：</p><blockquote><p>返回具有不确定性<br>元素删除相对困难</p></blockquote></li></ul><h4 id="布隆过滤器的原理"><a href="#布隆过滤器的原理" class="headerlink" title="布隆过滤器的原理"></a>布隆过滤器的原理</h4><p>假设有个集合 A，A 中有 n 个元素。利用 k 个哈希散列函数，将 A 中的每个元素映射到一个长度为 a 位的数组 B 中的不同位置上，这些位置上的二进制数均设置为 1 。如果待检查的元素，经过这 k 个哈希散列函数的映射后，发现其 k 个位置上的二进制数全部为 1 ，这个元素很可能属于集合 A ，反之，一定不属于集合 A。</p><h5 id="布隆过滤器的数据结构"><a href="#布隆过滤器的数据结构" class="headerlink" title="布隆过滤器的数据结构"></a>布隆过滤器的数据结构</h5><p>布隆过滤器是一个 bit 向量或者说 bit 数组：</p><p><img src="/images/algorithm/2021-09-01-bloom-origin.jpg" alt="image" title="布隆过滤器原始状态"></p><p>如果要映射一个 key 值到布隆过滤器中，需要使用多个不同的哈希函数生成多个哈希值，并对每个生成的哈希值指向的 bit 位置 1，例如针对值 <strong>Chinese</strong> 和三个不同的哈希函数分别生成了哈希值 1、4、7，则数据结构状态转变为：</p><p><img src="/images/algorithm/2021-09-01-bloom-status-chinese.jpg" alt="image" title="布隆过滤器添加 key 值 Chinese 后的状态"></p><p>现在再存一个 key 值为 <strong>English</strong>，三个哈希函数返回值分别是 2、4、8 ，则数据结构继续变为：</p><p><img src="/images/algorithm/2021-09-01-bloom-status-english.jpg" alt="image" title="布隆过滤器添加 key 值 English 后的状态"></p><blockquote><p>值得注意的是，4 这个 bit 位由于两个值的哈希函数都返回了这个 bit 位，因此它被覆盖了。</p></blockquote><p>现在，</p><ol><li>查询 <strong>Math</strong> 这个 key 值是否存在，如果三个哈希函数返回了 1、5、8 三个值，因为 5 这个 bit 位上的值为 0，说明没有任何一个值映射到这个 bit 位上，因此可以很确定地说 <strong>Math 这个 key 值不存在</strong>。</li><li>查询 <strong>Physics</strong> 这个 key 值是否存在，如果三个哈希函数返回了 1、4、7，检查发现这三个 bit 位上的值均为 1，那么可以说 <strong>Physics</strong> 存在了么？答案是不可以，只能是 <strong>Physics 这个 key 值可能存在</strong>。</li></ol><p>因为随着增加的值越来越多，被置为 1 的 bit 位也会越来越多，这样某个值 <strong>Chemistry</strong> 即使没有被存储过，但是万一哈希函数返回的三个 bit 位都被其他值置位了 1 ，那么程序还是会判断 Chemistry 这个值存在。</p><h5 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h5><blockquote><ol><li>首先需要 k 个 hash 函数，每个函数可以把 key 散列成为 1 个整数。</li><li>初始化时，需要一个长度为 n 比特的数组，每个比特位初始化为 0。</li><li>某个 key 加入集合时，用 k 个 hash 函数计算出k个散列值，并把数组中对应的比特位置为 1。</li><li>判断某个 key 是否在集合时，用 k 个 hash 函数计算出 k 个散列值，并查询数组中对应的比特位，如果所有的比特位都是 1 ，认为在集合中。</li></ol></blockquote><h5 id="支持删除吗"><a href="#支持删除吗" class="headerlink" title="支持删除吗"></a>支持删除吗</h5><p>传统的布隆过滤器并不支持删除操作。但是名为 Counting Bloom filter 的变种可以用来测试元素计数个数是否绝对小于某个阈值，它支持元素删除。</p><h5 id="如何选择哈希函数个数和布隆过滤器长度"><a href="#如何选择哈希函数个数和布隆过滤器长度" class="headerlink" title="如何选择哈希函数个数和布隆过滤器长度"></a>如何选择哈希函数个数和布隆过滤器长度</h5><p>很显然，过小的布隆过滤器很快所有的 bit 位均为 1，那么查询任何值都会返回“可能存在”，起不到过滤的目的了。布隆过滤器的长度会直接影响误报率，布隆过滤器越长其误报率越小。</p><p>另外，哈希函数的个数也需要权衡，个数越多则布隆过滤器 bit 位置位 1 的速度越快，且布隆过滤器的效率越低；但是如果太少的话，那么误报率会变高。</p><blockquote><p>k 为哈希函数个数，m 为布隆过滤器长度，n 为插入的元素个数，p 为误报率</p></blockquote><p>如何选择适合业务的 k 和 m 值：</p><p><img src="/images/algorithm/2021-09-01-bloom-m.jpg" alt="image"></p><p><img src="/images/algorithm/2021-09-01-bloom-k.jpg" alt="image"></p><p>布隆过滤器误报率 p 与位数组大小 m 和集合中插入元素个数 n 的关系图:</p><p><img src="/images/algorithm/2021-09-01-bloom.jpg" alt="image" title="布隆过滤器"></p><h4 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h4><p>常见的适用常见有，利用布隆过滤器减少磁盘 IO 或者网络请求，因为一旦一个值必定不存在的话，可以不用进行后续昂贵的查询请求。</p><p>另外，既然使用布隆过滤器来加速查找和判断是否存在，那么性能很低的哈希函数不是个好选择，推荐 MurmurHash、Fnv 这些。</p><p>目前布隆过滤器已经有相应实现的开源类库啦，如 Google 的 Guava 类库，Twitter 的 Algebird 类库，信手拈来即可，或者基于 Redis 自带的 Bitmaps 自行实现设计也是可以的。</p><h5 id="大-Value-拆分"><a href="#大-Value-拆分" class="headerlink" title="大 Value 拆分"></a>大 Value 拆分</h5><p>Redis 因其支持 setbit 和 getbit 操作，且纯内存性能高等特点，因此天然就可以作为布隆过滤器来使用。但是布隆过滤器的不当使用极易产生大 Value，增加 Redis 阻塞风险，因此生成环境中建议对体积庞大的布隆过滤器进行拆分。</p><p>拆分的形式方法多种多样，但是本质是不要将 Hash(Key) 之后的请求分散在多个节点的多个小 bitmap 上，而是应该拆分成多个小 bitmap 之后，对一个 Key 的所有哈希函数都落在这一个小 bitmap 上。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Data structures are nothing different. They are like the bookshelves of your application where you can organize your data. Different data structures will give you different facility and benefits. To properly use the power and accessibility of the data structures you need to know the trade-offs of using one.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;不同的数据结构有不同的适用场景和优缺点，你需要仔细权衡自己的需求之后妥善适用它们&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;布隆过滤器就是践行这句话的代表&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="布隆过滤器" scheme="http://xiaolong.li/tags/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>TCP 的粘包拆包以及解决方案</title>
    <link href="http://xiaolong.li/2021/08/23/TCP-stick-package-unpacking/"/>
    <id>http://xiaolong.li/2021/08/23/TCP-stick-package-unpacking/</id>
    <published>2021-08-22T16:01:48.000Z</published>
    <updated>2021-08-22T17:31:23.522Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p>TCP（transport control protocol，传输控制协议）是面向连接的，面向流的，提供高可靠性服务。收发两端（客户端和服务器端）都要有一一成对的socket，因此，发送端为了将多个发往接收端的包，更有效的发到对方，使用了优化方法（Nagle算法），将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包。这样，接收端，就难于分辨出来了，必须提供科学的拆包机制。即面向流的通信是无消息保护边界的。</p><p>TCP 底层并不了解上层业务数据的具体含义，它会根据 TCP 缓冲区的实际情况进行包的划分，所以在业务上认为一个完整的包可能会被 TCP 拆分为多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这就是 TCP <strong>粘包</strong> 和 <strong>拆包</strong>。</p><a id="more"></a><h4 id="为什么-UDP没有粘包？"><a href="#为什么-UDP没有粘包？" class="headerlink" title="为什么 UDP没有粘包？"></a>为什么 UDP没有粘包？</h4><p>粘包拆包问题在数据链路层、网络层以及传输层都有可能发生。日常的网络应用开发大都在传输层进行，由于 UDP 有消息保护边界，不会发生粘包拆包问题，因此粘包拆包问题只发生在 TCP 协议中。</p><h4 id="粘包拆包发生场景"><a href="#粘包拆包发生场景" class="headerlink" title="粘包拆包发生场景"></a>粘包拆包发生场景</h4><p>因为 TCP 是面向流，没有边界，而操作系统在发送 TCP 数据时，会通过缓冲区来进行优化，例如缓冲区为 1024 个字节大小。</p><p>如果一次请求发送的数据量比较小，没达到缓冲区大小，TCP 则会将多个请求合并为同一个请求进行发送，这就形成了粘包问题。</p><p>如果一次请求发送的数据量比较大，超过了缓冲区大小，TCP 就会将其拆分为多次发送，这就是拆包。</p><p>关于粘包和拆包可以参考下图的几种情况：</p><h5 id="正常数据包"><a href="#正常数据包" class="headerlink" title="正常数据包"></a>正常数据包</h5><blockquote><p>正常的理想情况，两个包恰好满足 TCP 缓冲区的大小或达到 TCP 等待时长，分别发送两个包</p></blockquote><p>服务端一共读到两个数据包，第一个包包含客户端发出的第一条消息的完整信息，第二个包包含客户端发出的第二条消息，那这种情况比较好处理，服务器只需要简单的从网络缓冲区去读就好了，第一次读到第一条消息的完整信息，消费完再从网络缓冲区将第二条完整消息读出来消费。这种情况没有发生粘包、拆包。</p><p><img src="/images/network/2021-08-23-tcp-packet-normal.png" alt="image"></p><h5 id="粘包"><a href="#粘包" class="headerlink" title="粘包"></a>粘包</h5><blockquote><p>两个包较小，间隔时间短，发生粘包，合并成一个包发送</p></blockquote><p>服务端一共就读到一个数据包，这个数据包包含客户端发出的两条消息的完整信息，这个时候服务端不知道如何区分原始的两个包，这种情况其实是发生了 TCP 粘包。</p><p><img src="/images/network/2021-08-23-tcp-packet-stick.png" alt="image"></p><h5 id="拆包"><a href="#拆包" class="headerlink" title="拆包"></a>拆包</h5><blockquote><p>一个包过大，超过缓存区大小，拆分成两个或多个包发送</p></blockquote><p><img src="/images/network/2021-08-23-tcp-packet-unpacking.png" alt="image"></p><h5 id="既有粘包又有拆包"><a href="#既有粘包又有拆包" class="headerlink" title="既有粘包又有拆包"></a>既有粘包又有拆包</h5><blockquote><p>packet_1 过大，进行了拆包处理，而拆出去的一部分又与 packet_2 进行粘包处理。</p></blockquote><p>服务端一共收到了两个数据包，第一个数据包只包含了第一条消息的一部分，第一条消息的后半部分和第二条消息都在第二个数据包中，或者是第一个数据包包含了第一条消息的完整信息和第二条消息的一部分信息，第二个数据包包含了第二条消息的剩下部分，这种情况其实是发送了 TCP 拆包，因为发生了一条消息被拆分在两个包里面发送了，同样上面的服务器逻辑对于这种情况是不好处理的。</p><p><img src="/images/network/2021-08-23-tcp-packet-stick-unpacking.png" alt="image"></p><h4 id="产生-TCP-粘包和拆包的原因"><a href="#产生-TCP-粘包和拆包的原因" class="headerlink" title="产生 TCP 粘包和拆包的原因"></a>产生 TCP 粘包和拆包的原因</h4><p>TCP 是以流的方式传输数据，传输的最小单位为一个报文段（segment）。TCP Header中有个 Options 标识位，常见的标识为 mss(Maximum Segment Size) 指的是，连接层每次传输的数据有个最大限制 MTU(Maximum Transmission Unit)，一般是 1500 比特，超过这个量要分成多个报文段，mss 则是这个最大限制减去 TCP 的 header，光是要传输的数据的大小，一般为 1460 比特。换算成字节，也就是 180 多字节。</p><p>TCP 为提高性能，发送端会将需要发送的数据发送到缓冲区，等待缓冲区满了之后，再将缓冲中的数据发送到接收方。同理，接收方也有缓冲区这样的机制，来接收数据。</p><p>发生 TCP 粘包、拆包主要是由于下面一些原因：</p><ol><li>应用程序写入的数据大于套接字缓冲区大小，这将会发生拆包。</li><li>应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发生粘包。</li><li>进行 mss（最大报文长度）大小的 TCP 分段，当 TCP 报文长度 - TCP 头部长度 &gt; mss 的时候将发生拆包。</li><li>接收方法不及时读取套接字缓冲区数据，这将发生粘包。</li></ol><h4 id="如何解决拆包粘包"><a href="#如何解决拆包粘包" class="headerlink" title="如何解决拆包粘包"></a>如何解决拆包粘包</h4><p>既然TCP 是无界的数据流，且协议本身无法避免粘包，拆包的发生，那么只能在应用层数据协议上加以控制。通常在制定传输数据时，可以使用如下方法：</p><ol><li>使用带消息头的协议、消息头存储消息开始标识及消息长度信息，服务端获取消息头的时候解析出消息长度，然后向后读取该长度的内容。</li><li>设置定长消息，服务端每次读取既定长度的内容作为一条完整消息。</li><li>设置消息边界，服务端从网络流中按消息编辑分离出消息内容。</li></ol><p>a)先基于第三种方法，假设区分数据边界的标识为换行符 “\n”（注意请求数据本身内部不能包含换行符），数据格式为 Json，例如下面是一个符合这个规则的请求包。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;type&quot;:&quot;message&quot;,&quot;content&quot;:&quot;hello&quot;&#125;\n</span><br></pre></td></tr></table></figure><p>注意上面的请求数据末尾有一个换行字符，代表一个请求的结束。</p><p>b)基于第一种方法，可以制定，首部固定 10 个字节长度用来保存整个数据包长度，位数不够则补 0 的数据协议</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0000000036&#123;&quot;type&quot;:&quot;message&quot;,&quot;content&quot;:&quot;hello&quot;&#125;</span><br></pre></td></tr></table></figure><p>c)基于第一种方法，可以制定，首部 4 字节网络字节序 unsigned int，标记整个包的长度</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">****&#123;&quot;type&quot;:&quot;message&quot;,&quot;content&quot;:&quot;hello all&quot;&#125;</span><br></pre></td></tr></table></figure><p>其中首部四字节 * 号代表一个网络字节序的 unsigned int 数据，为不可见字符，紧接着是 Json 的数据格式的包体数据。</p><h4 id="Netty对粘包和拆包问题的处理"><a href="#Netty对粘包和拆包问题的处理" class="headerlink" title="Netty对粘包和拆包问题的处理"></a>Netty对粘包和拆包问题的处理</h4><p>Netty 对解决粘包和拆包的方案做了抽象，提供了一些解码器（Decoder）来解决粘包和拆包的问题。如：</p><ul><li>LineBasedFrameDecoder：以行为单位进行数据包的解码；</li><li>DelimiterBasedFrameDecoder：以特殊的符号作为分隔来进行数据包的解码；</li><li>FixedLengthFrameDecoder：以固定长度进行数据包的解码；</li><li>LenghtFieldBasedFrameDecode：适用于消息头包含消息长度的协议（最常用）；</li></ul><p>基于 Netty 进行网络读写的程序，可以直接使用这些 Decoder 来完成数据包的解码。对于高并发、大流量的系统来说，每个数据包都不应该传输多余的数据（所以补齐的方式不可取），LenghtFieldBasedFrameDecode 更适合这样的场景。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>TCP 协议粘包拆包问题是因为 TCP 协议数据传输是基于字节流的，它不包含消息、数据包等概念，需要应用层协议自己设计消息的边界，即消息帧（Message Framing）。如果应用层协议没有使用基于长度、终结符信息或者消息边界等方式进行处理，则会导致多个消息的粘包和拆包。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;TCP（transport control protocol，传输控制协议）是面向连接的，面向流的，提供高可靠性服务。收发两端（客户端和服务器端）都要有一一成对的socket，因此，发送端为了将多个发往接收端的包，更有效的发到对方，使用了优化方法（Nagle算法），将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包。这样，接收端，就难于分辨出来了，必须提供科学的拆包机制。即面向流的通信是无消息保护边界的。&lt;/p&gt;
&lt;p&gt;TCP 底层并不了解上层业务数据的具体含义，它会根据 TCP 缓冲区的实际情况进行包的划分，所以在业务上认为一个完整的包可能会被 TCP 拆分为多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这就是 TCP &lt;strong&gt;粘包&lt;/strong&gt; 和 &lt;strong&gt;拆包&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="网络" scheme="http://xiaolong.li/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="TCP" scheme="http://xiaolong.li/tags/TCP/"/>
    
      <category term="粘包" scheme="http://xiaolong.li/tags/%E7%B2%98%E5%8C%85/"/>
    
      <category term="拆包" scheme="http://xiaolong.li/tags/%E6%8B%86%E5%8C%85/"/>
    
  </entry>
  
  <entry>
    <title>一文彻底搞懂 TCP 三次握手、四次挥手过程及原理</title>
    <link href="http://xiaolong.li/2021/08/20/Introduction-to-TCP/"/>
    <id>http://xiaolong.li/2021/08/20/Introduction-to-TCP/</id>
    <published>2021-08-20T03:23:39.000Z</published>
    <updated>2021-08-21T15:56:30.797Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h4 id="TCP-协议简述"><a href="#TCP-协议简述" class="headerlink" title="TCP 协议简述"></a>TCP 协议简述</h4><p>TCP 提供面向有连接的通信传输，面向有连接是指在传送数据之前必须先建立连接，数据传送完成后要释放连接。<br>无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在 TCP/IP 协议中，TCP 协议提供可靠的连接服务，连接是通过 <strong>三次握手</strong> 进行初始化的。<br>同时由于 TCP 协议是一种面向连接的、可靠的、基于字节流的运输层通信协议，TCP 是 <strong>全双工模式</strong>，所以需要 <strong>四次挥手</strong> 关闭连接。</p><a id="more"></a><h4 id="TCP-包首部"><a href="#TCP-包首部" class="headerlink" title="TCP 包首部"></a>TCP 包首部</h4><p>网络中传输的数据包由两部分组成：一部分是协议所要用到的首部，另一部分是上一层传过来的数据。首部的结构由协议的具体规范详细定义。在数据包的首部，明确标明了协议应该如何读取数据。反过来说，看到首部，也就能够了解该协议必要的信息以及所要处理的数据。包首部就像协议的脸。</p><p>所以在学习 TCP 协议之前，首先要知道 TCP 在网络传输中处于哪个位置，以及它的协议的规范，下面我们就看看 TCP 首部的网络传输起到的作用：</p><p><img src="/images/network/2021-08-20-tcp-msg.png" alt="image"></p><p>下面的图是 TCP 头部的规范定义，它定义了 TCP 协议如何读取和解析数据：</p><p><img src="/images/network/2021-08-20-tcp-header.png" alt="image"></p><p>TCP 首部承载这 TCP 协议需要的各项信息，下面我们来分析一下：</p><h5 id="TCP-端口号"><a href="#TCP-端口号" class="headerlink" title="TCP 端口号"></a>TCP 端口号</h5><p>TCP 的连接是需要四个要素确定唯一一个连接：</p><blockquote><p>（源IP，源端口号）+ （目地IP，目的端口号）</p></blockquote><p>所以 TCP 首部预留了两个 16 位作为端口号的存储，而 IP 地址由上一层 IP 协议负责传递，源端口号和目地端口各占 16 位两个字节，也就是端口的范围是 2^16=65535，另外 1024  以下是系统保留的，从 1024-65535 是用户使用的端口范围。</p><h5 id="TCP-的序号和确认号"><a href="#TCP-的序号和确认号" class="headerlink" title="TCP 的序号和确认号"></a>TCP 的序号和确认号</h5><p><strong>32位序号 seq</strong>：Sequence number 缩写 <strong>seq</strong> ，TCP 通信过程中某一个传输方向上的字节流的每个字节的序号，通过这个来确认发送的数据有序，比如现在序列号为 1000，发送了 1000，下一个序列号就是 2000。<br><strong>32位确认号 ack</strong>：Acknowledge number 缩写 <strong>ack</strong>，TCP 对上一次 seq 序号做出的确认号，用来响应 TCP 报文段，给收到的 TCP 报文段的序号 seq 加 1。</p><h4 id="TCP-的标志位"><a href="#TCP-的标志位" class="headerlink" title="TCP 的标志位"></a>TCP 的标志位</h4><p>每个 TCP 段都有一个目的，这是借助于 TCP 标志位选项来确定的，允许发送方或接收方指定哪些标志应该被使用，以便段被另一端正确处理。<br>用的最广泛的标志是 <strong>SYN</strong>，<strong>ACK</strong> 和 <strong>FIN</strong>，用于建立连接，确认成功的段传输，最后终止连接。</p><blockquote><p><strong>SYN</strong>：简写为S，同步标志位，用于建立会话连接，同步序列号；<br><strong>ACK</strong>：简写为.，确认标志位，对已接收的数据包进行确认；<br><strong>FIN</strong>：简写为F，完成标志位，表示我已经没有数据要发送了，即将关闭连接；<br><strong>PSH</strong>：简写为P，推送标志位，表示该数据包被对方接收后应立即交给上层应用，而不在缓冲区排队；<br><strong>RST</strong>：简写为R，重置标志位，用于连接复位、拒绝错误和非法的数据包；<br><strong>URG</strong>：简写为U，紧急标志位，表示数据包的紧急指针域有效，用来保证连接不被阻断，并督促中间设备尽快处理；</p></blockquote><h4 id="TCP-三次握手建立连接"><a href="#TCP-三次握手建立连接" class="headerlink" title="TCP 三次握手建立连接"></a>TCP 三次握手建立连接</h4><p>所谓三次握手 (Three-way Handshake)，是指建立一个 TCP 连接时，需要客户端和服务器总共发送3个报文。</p><p>三次握手的目的是连接服务器指定端口，建立 TCP 连接，并同步连接双方的序列号和确认号，交换 TCP 窗口大小信息。在 socket 编程中，客户端执行 connect() 时，将触发三次握手。</p><p>三次握手过程的示意图如下：</p><p><img src="/images/network/2021-08-20-tcp-established.png" alt="image"></p><h5 id="第一次握手"><a href="#第一次握手" class="headerlink" title="第一次握手"></a>第一次握手</h5><p>客户端将 TCP 报文标志位 SYN 置为 1，随机产生一个序号值 seq = J，保存在 TCP 首部的序列号 (Sequence Number) 字段里，指明客户端打算连接的服务器的端口，并将该数据包发送给服务器端，发送完毕后，客户端进入 SYN_SENT 状态，等待服务器端确认。</p><h5 id="第二次握手"><a href="#第二次握手" class="headerlink" title="第二次握手"></a>第二次握手</h5><p>服务器端收到数据包后由标志位 SYN = 1 知道客户端请求建立连接，服务器端将 TCP 报文标志位 SYN 和 ACK 都置为 1，ack = J + 1，随机产生一个序号值 seq = K ，并将该数据包发送给客户端以确认连接请求，服务器端进入 SYN_RCVD 状态。</p><h5 id="第三次握手"><a href="#第三次握手" class="headerlink" title="第三次握手"></a>第三次握手</h5><p>客户端收到确认后，检查 ack 是否为 J + 1 ，ACK 是否为 1，如果正确则将标志位 ACK 置为 1，ack=K+1，并将该数据包发送给服务器端，服务器端检查 ack 是否为 K+1，ACK 是否为 1，如果正确则连接建立成功，客户端和服务器端进入 ESTABLISHED 状态，完成三次握手，随后客户端与服务器端之间可以开始传输数据了。</p><blockquote class="blockquote-center"><p><strong>第三次握手允许携带数据</strong></p></blockquote><p>注意：上面写的 <strong>ack 和 ACK 不是同一个概念</strong>：</p><blockquote><p>小写的 ack 代表的是头部的确认号 Acknowledge number， 缩写 ack ，是对上一个包的序号进行确认的号，ack=seq+1。<br>大写的 ACK 是上面说的 TCP 首部的标志位，用于标志的 TCP 包是否对上一个包进行了确认操作，如果确认了，则把 ACK 标志位设置成1。</p></blockquote><p>下面我自己做实验，开一个 HTTP 服务，监听 80 端口，然后使用 Tcpdump 命令抓包，看一下 TCP 三次握手的过程：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">sudo tcpdump -n -t -S -i enp0s3  port 80 </span><br><span class="line"></span><br><span class="line">第一次握手，标志位Flags=S</span><br><span class="line">IP 10.0.2.2.51323 &gt; 10.0.2.15.80: Flags [S], seq 84689409, win 65535, options [mss 1460], length 0</span><br><span class="line">第二次握手，标志位Flags=[S.]</span><br><span class="line">IP 10.0.2.15.80 &gt; 10.0.2.2.51323: Flags [S.], seq 1893430205, ack 84689410, win 64240, options [mss 1460], length 0</span><br><span class="line">第三次握手，标志位Flags=[.]</span><br><span class="line">IP 10.0.2.2.51323 &gt; 10.0.2.15.80: Flags [.], ack 1893430206, win 65535, length 0</span><br><span class="line">建立连接后，客户端发送http请求 </span><br><span class="line">IP 10.0.2.2.51321 &gt; 10.0.2.15.80: Flags [P.], seq 1:753, ack 1, win 65535, length 752: HTTP: GET / HTTP/1.1</span><br></pre></td></tr></table></figure><p>tcpdump命令解析一下：</p><blockquote><p>-i: 指定抓包的网卡是enp0s3<br>-n: 把域名转成IP显示<br>-t: 不显示时间<br>-S: 序列号使用绝对数值，不指定-S的话，序列号会使用相对的数值<br>port: 指定监听端口是80<br>host: 指定监听的主机名</p></blockquote><p>实战中TCP的三次握手过程：</p><blockquote><p>第一次握手，客户端51323端口号向服务器端80号端口发起连接，此时标志位flags=S，即SYN=1标志，表示向服务端发起连接的请求，同时生成序列号seq=84689409<br>第二次握手，服务端标志位flags=[S.]，即SYN+ACK标志位设置为1，表示对上一个请求连接的报文进行确认，同时设置ack=seq+1=184689410，生成序列号seq=1893430205<br>第三次握手，客户端对服务端的响应进行确认，所以此时标志位是[.]即ACK=1，同时返回对上一个报文的seq的确认号，ack=1893430206<br>至此，三次握手完成，一个TCP连接建立完成，接下来就是双端传输数据了</p></blockquote><h5 id="为什么需要三次握手"><a href="#为什么需要三次握手" class="headerlink" title="为什么需要三次握手"></a>为什么需要三次握手</h5><p>假设 client 发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达 server。</p><p>本来这是一个早已失效的报文段。但 server 收到此失效的连接请求报文段后，就误认为是 client 再次发出的一个新的连接请求。于是就向 client 发出确认报文段，同意建立连接。</p><p>假设不采用“三次握手”，那么只要 server 发出确认，新的连接就建立了。由于现在 client 并没有发出建立连接的请求，因此不会理睬 server 的确认，也不会向 server 发送数据。但 server 却以为新的运输连接已经建立，并一直等待 client 发来数据。这样，server 的很多资源就白白浪费掉了。</p><p>所以，采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client 不会向 server 的确认发出确认。server 由于收不到确认，就知道 client 并没有要求建立连接。</p><h4 id="TCP-四次挥手关闭连接"><a href="#TCP-四次挥手关闭连接" class="headerlink" title="TCP 四次挥手关闭连接"></a>TCP 四次挥手关闭连接</h4><p>四次挥手即终止 TCP 连接，就是指断开一个 TCP 连接时，需要客户端和服务端总共发送 4 个包以确认连接的断开。</p><p>在 socket 编程中，这一过程由客户端或服务端任一方执行 close 来触发。</p><p>由于 TCP 连接是全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，A 发送一个 FIN 来终止连接，B 收到一个 FIN ，只是意味着 A-&gt;B 方向上没有数据流动了，即B不会再收到数据了，但是在这个 TCP 连接上 B 仍然能够发送数据，直到 B 也向 A 发送了 FIN ，才能说明需要关闭连接。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。</p><p>四次挥手过程的示意图如下：</p><p><img src="/images/network/2021-08-20-tcp-close.png" alt="image"></p><p>挥手请求可以是 Client 端，也可以是 Server 端发起的，我们假设是 Client 端发起：</p><h5 id="第一次挥手"><a href="#第一次挥手" class="headerlink" title="第一次挥手"></a>第一次挥手</h5><p>Client 端发起挥手请求，向 Server 端发送标志位是 FIN 报文段，设置序列号 seq ，此时，Client 端进入 FIN_WAIT_1 状态，这表示 Client 端没有数据要发送给 Server 端了。</p><h5 id="第二次挥手"><a href="#第二次挥手" class="headerlink" title="第二次挥手"></a>第二次挥手</h5><p>Server 端收到了 Client 端发送的 FIN 报文段，向 Client 端返回一个标志位是 ACK 的报文段，ack 设为 seq + 1，Client 端进入 FIN_WAIT_2 状态，Server 端告诉 Client 端，我确认并同意你的关闭请求。</p><h5 id="第三次挥手"><a href="#第三次挥手" class="headerlink" title="第三次挥手"></a>第三次挥手</h5><p>Server 端向 Client 端发送标志位是 FIN 的报文段，请求关闭连接，同时 Client 端进入 LAST_ACK 状态。</p><h5 id="第四次挥手"><a href="#第四次挥手" class="headerlink" title="第四次挥手"></a>第四次挥手</h5><p>Client 端收到 Server 端发送的 FIN 报文段，向 Server 端发送标志位是 ACK 的报文段，然后 Client 端进入 TIME_WAIT 状态。Server 端收到 Client 端的 ACK 报文段以后，就关闭连接。此时，Client 端 <strong>等待 2MSL</strong> 的时间后依然没有收到回复，则证明 Server 端已正常关闭，那好，Client 端也可以关闭连接了。</p><h5 id="为什么关闭的时候却是四次握手？"><a href="#为什么关闭的时候却是四次握手？" class="headerlink" title="为什么关闭的时候却是四次握手？"></a>为什么关闭的时候却是四次握手？</h5><p>建立连接时因为当 Server 端收到 Client 端的 SYN 连接请求报文后，可以直接发送 SYN + ACK 报文。其中 ACK 报文是用来应答的，SYN 报文是用来同步的，所以建立连接只需要三次握手。</p><p>由于TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议，TCP是全双工模式。这就意味着，关闭连接时，当 Client 端发出 FIN 报文段时，只是表示 Client 端告诉 Server 端数据已经发送完毕了。当 Server 端收到 FIN 报文并返回 ACK 报文段，表示它已经知道 Client 端没有数据发送了，但是 Server 端还是可以发送数据到 Client 端的，所以 Server 很可能并不会立即关闭 SOCKET ，直到 Server 端把数据也发送完毕。当 Server 端也发送了 FIN 报文段时，这个时候就表示 Server 端也没有数据要发送了，就会告诉 Client 端，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。</p><h5 id="为什么要等待-2MSL-？"><a href="#为什么要等待-2MSL-？" class="headerlink" title="为什么要等待 2MSL ？"></a>为什么要等待 2MSL ？</h5><p><strong>MSL</strong>：报文段最大生存时间，它是任何报文段被丢弃前在网络内的最长时间。</p><p>有以下两个原因：</p><p>第一点：保证 TCP 协议的全双工连接能够可靠关闭。由于 IP 协议的不可靠性或者是其它网络原因，导致了 Server 端没有收到 Client 端的 ACK 报文，那么 Server 端就会在超时之后重新发送 FIN ，如果此时 Client 端的连接已经关闭处于 CLOESD 状态，那么重发的 FIN 就找不到对应的连接了，从而导致连接错乱，所以，Client 端发送完最后的 ACK 不能直接进入 CLOSED 状态，而要保持 TIME_WAIT ，当再次收到 FIN 的收，能够保证对方收到 ACK ，最后正确关闭连接。</p><p>第二点：保证这次连接的重复数据段从网络中消失。如果 Client 端发送最后的 ACK 直接进入 CLOSED 状态，然后又再向 Server 端发起一个新连接，这时不能保证新连接的与刚关闭的连接的端口号是不同的，也就是新连接和老连接的端口号可能一样了，那么就可能出现问题：如果前一次的连接某些数据滞留在网络中，这些延迟数据在建立新连接后到达Client端，由于新老连接的端口号和IP都一样，TCP协议就认为延迟数据是属于新连接的，新连接就会接收到脏数据，这样就会导致数据包混乱。所以TCP连接需要在TIME_WAIT状态等待2倍MSL，才能保证本次连接的所有数据在网络中消失。</p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;TCP-协议简述&quot;&gt;&lt;a href=&quot;#TCP-协议简述&quot; class=&quot;headerlink&quot; title=&quot;TCP 协议简述&quot;&gt;&lt;/a&gt;TCP 协议简述&lt;/h4&gt;&lt;p&gt;TCP 提供面向有连接的通信传输，面向有连接是指在传送数据之前必须先建立连接，数据传送完成后要释放连接。&lt;br&gt;无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在 TCP/IP 协议中，TCP 协议提供可靠的连接服务，连接是通过 &lt;strong&gt;三次握手&lt;/strong&gt; 进行初始化的。&lt;br&gt;同时由于 TCP 协议是一种面向连接的、可靠的、基于字节流的运输层通信协议，TCP 是 &lt;strong&gt;全双工模式&lt;/strong&gt;，所以需要 &lt;strong&gt;四次挥手&lt;/strong&gt; 关闭连接。&lt;/p&gt;
    
    </summary>
    
      <category term="网络" scheme="http://xiaolong.li/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="TCP" scheme="http://xiaolong.li/tags/TCP/"/>
    
      <category term="三次握手" scheme="http://xiaolong.li/tags/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B/"/>
    
      <category term="四次挥手" scheme="http://xiaolong.li/tags/%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B/"/>
    
  </entry>
  
  <entry>
    <title>Redis 持久化机制</title>
    <link href="http://xiaolong.li/2021/08/15/Redis-Persistence/"/>
    <id>http://xiaolong.li/2021/08/15/Redis-Persistence/</id>
    <published>2021-08-15T15:15:23.000Z</published>
    <updated>2021-08-15T16:21:59.296Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p>Redis 是一个内存数据库，数据保存在内存中，但是我们都知道内存的数据变化是很快的，也容易发生丢失。幸好 Redis 还为我们提供了持久化的机制，分别是 RDB(Redis DataBase) 和 AOF(Append Only File)。</p><h4 id="持久化流程"><a href="#持久化流程" class="headerlink" title="持久化流程"></a>持久化流程</h4><p>Redis 的数据持久化就是可以将数据保存在磁盘上，主要有下面五个过程：</p><blockquote><p>（1）客户端向服务端发送写操作(数据在客户端的内存中)。</p><p>（2）数据库服务端接收到写请求的数据(数据在服务端的内存中)。</p><p>（3）服务端调用 write 这个系统调用，将数据往磁盘上写(数据在系统内存的缓冲区中)。</p><p>（4）操作系统将缓冲区中的数据转移到磁盘控制器上(数据在磁盘缓存中)。</p><p>（5）磁盘控制器将数据写到磁盘的物理介质中(数据真正落到磁盘上)。</p></blockquote><a id="more"></a><p>这 5 个过程是在理想条件下一个正常的保存流程，但是在大多数情况下，我们的机器等等都会有各种各样的故障，这里划分了两种情况：</p><blockquote><p>（1）Redis 数据库发生故障，只要在上面的第三步执行完毕，那么就可以持久化保存，剩下的两步由操作系统替我们完成。</p><p>（2）操作系统发生故障，必须上面 5 步都完成才可以。</p></blockquote><p>在这里只考虑了保存的过程可能发生的故障，其实保存的数据也有可能发生损坏，需要一定的恢复机制，不过在这里就不再延伸了。现在主要考虑的是 Redis 如何来实现上面 5 个保存磁盘的步骤。它提供了两种策略机制，也就是 RDB 和 AOF。</p><h4 id="RDB-机制"><a href="#RDB-机制" class="headerlink" title="RDB 机制"></a>RDB 机制</h4><p>RDB 其实就是把数据以快照的形式保存在磁盘上。什么是快照呢? 你可以理解成把当前时刻的数据拍成一张照片保存下来。</p><p>RDB 持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘。也是默认的持久化方式，这种方式是就是将内存中数据以快照的方式写入到二进制文件中,默认的文件名为 dump.rdb。</p><blockquote class="blockquote-center"><p>在安装了 Redis 之后，所有的配置都是在 redis.conf 文件中，里面保存了 RDB 和 AOF 两种持久化机制的各种配置</p></blockquote><p>既然 RDB 机制是通过把某个时刻的所有数据生成一个快照来保存，那么就应该有一种触发机制，是实现这个过程。对于 RDB 来说，提供了三种机制：save、bgsave、自动化。</p><h5 id="save-触发方式"><a href="#save-触发方式" class="headerlink" title="save 触发方式"></a>save 触发方式</h5><p>该命令会阻塞当前 Redis 服务器，执行 save 命令期间，Redis 不能处理其他命令，直到 RDB 过程完成为止。具体流程如下：</p><p><img src="/images/redis/2021-08-15-save-cmd.jpeg" alt="image" title="save命令"></p><p>执行完成时候如果存在老的 RDB 文件，就把新的替代掉旧的。我们的客户端可能都是几万或者是几十万，这种方式显然不可取。</p><h5 id="bgsave-触发方式"><a href="#bgsave-触发方式" class="headerlink" title="bgsave 触发方式"></a>bgsave 触发方式</h5><p>执行该命令时，Redis 会在后台异步进行快照操作，快照同时还可以响应客户端请求。具体流程如下：</p><p><img src="/images/redis/2021-08-15-bgsave-cmd.jpeg" alt="image" title="bgsave命令"></p><p>具体操作是 Redis 进程执行 fork 操作创建子进程，RDB 持久化过程由子进程负责，完成后自动结束。阻塞只发生在 fork 阶段，一般时间很短。基本上 Redis 内部所有的 RDB 操作都是采用 bgsave 命令。</p><h5 id="自动触发"><a href="#自动触发" class="headerlink" title="自动触发"></a>自动触发</h5><p>自动触发是由配置文件来完成的。在 redis.conf 配置文件中，有如下配置可以设置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt; 1、save：这里是用来配置触发 Redis的 RDB 持久化条件，也就是什么时候将内存中的数据保存到硬盘。比如“save m n”。表示m秒内数据集存在n次修改时，自动触发bgsave。</span><br><span class="line">默认如下配置：</span><br><span class="line"></span><br><span class="line">&apos;#&apos;  表示900 秒内如果至少有1个key的值发生变化，则保存save 900 </span><br><span class="line">&apos;1#&apos;  表示300 秒内如果至少有10个key的值变化，则保存save 300 </span><br><span class="line">&apos;10#&apos; 表示60 秒内如果至少有10000个key的值变化，则保存save 60 10000</span><br><span class="line"></span><br><span class="line">不需要持久化，那么你可以注释掉所有的 save 行来停用保存功能。</span><br><span class="line">&gt;</span><br><span class="line">&gt; 2、&apos;stop-writes-on-bgsave-error&apos;：默认值为yes。当启用了RDB且最后一次后台保存数据失败时，Redis是否停止接收数据，这会让用户意识到数据没有正确持久化到磁盘上，否则没有人会注意到灾难（disaster）发生了。如果Redis重启了，那么又可以重新开始接收数据了</span><br><span class="line">&gt;</span><br><span class="line">&gt; 3、&apos;rdbcompression&apos;：默认值是yes。对于存储到磁盘中的快照，可以设置是否进行压缩存储。</span><br><span class="line">&gt;</span><br><span class="line">&gt; 4、&apos;rdbchecksum&apos;：默认值是yes。在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。</span><br><span class="line">&gt;</span><br><span class="line">&gt; 5、&apos;dbfilename&apos;：设置快照的文件名，默认是 dump.rdb</span><br><span class="line">&gt;</span><br><span class="line">&gt; 6、&apos;dir&apos;：设置快照文件的存放路径，这个配置项一定是个目录，而不能是文件名。</span><br></pre></td></tr></table></figure><p>可以修改这些配置来实现我们想要的效果。因为第三种方式是配置的，所以对前两种进行一个对比：</p><table><thead><tr><th>命令</th><th>save</th><th>bgsave</th></tr></thead><tbody><tr><td>IO 类型</td><td>同步</td><td>异步</td></tr><tr><td>是否阻塞</td><td>是</td><td>是（阻塞发生在 fork 时）</td></tr><tr><td>复杂度</td><td>O(n)</td><td>O(n)</td></tr><tr><td>优点</td><td>不会消耗额外内存</td><td>不阻塞客户端命令</td></tr><tr><td>缺点</td><td>阻塞客户端命令</td><td>需要 fork ，消耗内存</td></tr></tbody></table><h4 id="RDB-的优势和劣势"><a href="#RDB-的优势和劣势" class="headerlink" title="RDB 的优势和劣势"></a>RDB 的优势和劣势</h4><p><strong>优势</strong> ：</p><blockquote><p>（1）RDB文件紧凑，全量备份，非常适合用于进行备份和灾难恢复。</p><p>（2）生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。</p><p>（3）RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</p></blockquote><p><strong>劣势</strong>：</p><p>RDB 快照是一次全量备份，存储的是内存数据的二进制序列化形式，存储上非常紧凑。当进行快照持久化时，会开启一个子进程专门负责快照持久化，子进程会拥有父进程的内存数据，父进程修改内存子进程不会反应出来，所以在快照持久化期间修改的数据不会被保存，可能丢失数据。</p><h4 id="AOF-机制"><a href="#AOF-机制" class="headerlink" title="AOF 机制"></a>AOF 机制</h4><p>全量备份总是耗时的，提供一种更加高效的方式 AOF，工作机制很简单，Redis 会将每一个收到的写命令都通过 write 函数追加到文件中。通俗的理解就是日志记录。</p><h5 id="持久化原理"><a href="#持久化原理" class="headerlink" title="持久化原理"></a>持久化原理</h5><p><img src="/images/redis/2021-08-15-aof-persistence.jpeg" alt="image" title="AOF 运行原理"></p><p>每当有一个写命令过来时，就直接保存在我们的 AOF 文件中。</p><h5 id="文件重写原理"><a href="#文件重写原理" class="headerlink" title="文件重写原理"></a>文件重写原理</h5><p>AOF 的方式也同时带来了另一个问题。持久化文件会变的越来越大。为了压缩 aof 的持久化文件。Redis提供了 bgrewriteaof 命令。将内存中的数据以命令的方式保存到临时文件中，同时会 fork 出一条新进程来将文件重写。</p><p><img src="/images/redis/2021-08-15-aof-rewrite-file.jpeg" alt="image" title="AOF文件重写原理"></p><p>重写 aof 文件的操作，并没有读取旧的 aof 文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的 aof 文件，这点和快照有点类似。</p><h5 id="触发机制"><a href="#触发机制" class="headerlink" title="触发机制"></a>触发机制</h5><p>AOF 也有三种触发机制，always、everysec、和 no。</p><blockquote><p>（1）每修改同步 always：同步持久化 每次发生数据变更会被立即记录到磁盘 性能较差但数据完整性比较好</p><p>（2）每秒同步 everysec：异步操作，每秒记录 如果一秒内宕机，有数据丢失</p><p>（3）不同 no：从不同步</p></blockquote><p>三种触发机制对比：</p><table><thead><tr><th>命令</th><th>always</th><th>everysec</th><th>no</th></tr></thead><tbody><tr><td>优点</td><td>不丢失数据</td><td>每秒一次 fsync <br> 最大丢一秒数据</td><td>不用运维</td></tr><tr><td>缺点</td><td>IO 开销较大<br>一般的 SATA 盘只有几百 TPS</td><td>丢一秒数据</td><td>不可控</td></tr></tbody></table><h5 id="AOF-的优势和劣势"><a href="#AOF-的优势和劣势" class="headerlink" title="AOF 的优势和劣势"></a>AOF 的优势和劣势</h5><p><strong>优势</strong>：</p><blockquote><p>（1）AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒通过一个后台线程执行一次 fsync 操作，最多丢失 1 秒钟的数据。</p><p>（2）AOF 日志文件没有任何磁盘寻址的开销，写入性能非常高，文件不容易破损。</p><p>（3）AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。</p><p>（4）AOF 日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如不小心用 flushall 命令清空了所有数据，只要这个时候后台 rewrite 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 flushall 命令给删了，然后再将该 AOF 文件放回去，就可以通过恢复机制，自动恢复所有数据。</p></blockquote><p><strong>劣势</strong>：</p><blockquote><p>（1）对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。</p><p>（2）AOF 开启后，支持的写 QPS 会比 RDB 支持的低，因为 AOF 一般会配置成每秒 fsync 一次日志文件，当然，每秒一次 fsync，性能也还是很高的</p><p>（3）AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。</p></blockquote><h4 id="RDB和AOF到底该如何选择"><a href="#RDB和AOF到底该如何选择" class="headerlink" title="RDB和AOF到底该如何选择"></a>RDB和AOF到底该如何选择</h4><p>一般根据需求不同选择的也不通，但是通常都是结合使用。总结：</p><table><thead><tr><th>命令</th><th>RDB</th><th>AOF</th></tr></thead><tbody><tr><td>启动优先级</td><td>低</td><td>高</td></tr><tr><td>体积</td><td>小</td><td>大</td></tr><tr><td>恢复速度</td><td>快</td><td>慢</td></tr><tr><td>数据安全性</td><td>宕机容易丢数据</td><td>根据策略决定</td></tr><tr><td>轻重</td><td>重</td><td>轻</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Redis 是一个内存数据库，数据保存在内存中，但是我们都知道内存的数据变化是很快的，也容易发生丢失。幸好 Redis 还为我们提供了持久化的机制，分别是 RDB(Redis DataBase) 和 AOF(Append Only File)。&lt;/p&gt;
&lt;h4 id=&quot;持久化流程&quot;&gt;&lt;a href=&quot;#持久化流程&quot; class=&quot;headerlink&quot; title=&quot;持久化流程&quot;&gt;&lt;/a&gt;持久化流程&lt;/h4&gt;&lt;p&gt;Redis 的数据持久化就是可以将数据保存在磁盘上，主要有下面五个过程：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;（1）客户端向服务端发送写操作(数据在客户端的内存中)。&lt;/p&gt;
&lt;p&gt;（2）数据库服务端接收到写请求的数据(数据在服务端的内存中)。&lt;/p&gt;
&lt;p&gt;（3）服务端调用 write 这个系统调用，将数据往磁盘上写(数据在系统内存的缓冲区中)。&lt;/p&gt;
&lt;p&gt;（4）操作系统将缓冲区中的数据转移到磁盘控制器上(数据在磁盘缓存中)。&lt;/p&gt;
&lt;p&gt;（5）磁盘控制器将数据写到磁盘的物理介质中(数据真正落到磁盘上)。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://xiaolong.li/categories/Redis/"/>
    
    
      <category term="redis" scheme="http://xiaolong.li/tags/redis/"/>
    
      <category term="rdb" scheme="http://xiaolong.li/tags/rdb/"/>
    
      <category term="aof" scheme="http://xiaolong.li/tags/aof/"/>
    
  </entry>
  
  <entry>
    <title>Zookeeper 实现消息队列</title>
    <link href="http://xiaolong.li/2021/08/12/Zookeeper-for-Message-queue/"/>
    <id>http://xiaolong.li/2021/08/12/Zookeeper-for-Message-queue/</id>
    <published>2021-08-12T08:08:26.000Z</published>
    <updated>2021-08-12T08:09:53.270Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Zookeeper 实现配置中心</title>
    <link href="http://xiaolong.li/2021/08/12/Zookeeper-for-Configuration/"/>
    <id>http://xiaolong.li/2021/08/12/Zookeeper-for-Configuration/</id>
    <published>2021-08-12T08:07:50.000Z</published>
    <updated>2021-08-12T08:09:23.885Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Zookeeper 实现注册中心</title>
    <link href="http://xiaolong.li/2021/08/12/Zookeeper-for-Registry/"/>
    <id>http://xiaolong.li/2021/08/12/Zookeeper-for-Registry/</id>
    <published>2021-08-12T08:05:44.000Z</published>
    <updated>2021-08-12T08:10:07.691Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Zookeeper 实现分布式事务</title>
    <link href="http://xiaolong.li/2021/08/12/Zookeeper-for-Distributed-transaction/"/>
    <id>http://xiaolong.li/2021/08/12/Zookeeper-for-Distributed-transaction/</id>
    <published>2021-08-12T08:04:04.000Z</published>
    <updated>2021-08-12T08:09:36.933Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Zookeeper 实现分布式锁</title>
    <link href="http://xiaolong.li/2021/08/12/Zookeeper-for-Distributed-lock/"/>
    <id>http://xiaolong.li/2021/08/12/Zookeeper-for-Distributed-lock/</id>
    <published>2021-08-12T08:03:23.000Z</published>
    <updated>2021-08-12T08:09:21.159Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Zookeeper 实现负载均衡</title>
    <link href="http://xiaolong.li/2021/08/12/Zookeeper-for-Load-balancing/"/>
    <id>http://xiaolong.li/2021/08/12/Zookeeper-for-Load-balancing/</id>
    <published>2021-08-12T08:03:01.000Z</published>
    <updated>2021-08-12T08:09:45.165Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>WebRTC 中的 RTP 及 RTCP 介绍</title>
    <link href="http://xiaolong.li/2021/08/12/Introduction-RTP-RTCP-in-WebRTC/"/>
    <id>http://xiaolong.li/2021/08/12/Introduction-RTP-RTCP-in-WebRTC/</id>
    <published>2021-08-12T02:22:05.000Z</published>
    <updated>2021-08-12T07:42:04.617Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><blockquote><p>WebRTC 技术是激烈的开放的 Web 战争中一大突破。- Brendan Eich, inventor of Java</p></blockquote><h4 id="UDP-还是-TCP？"><a href="#UDP-还是-TCP？" class="headerlink" title="UDP 还是 TCP？"></a>UDP 还是 TCP？</h4><p>如果抛开 WebRTC，让你自己实现一套实时互动直播系统，在选择网络传输协议时，你会选择使用 UDP 协议还是 TCP 协议呢？</p><p>这个问题在 2011 年至 2012 年一直是一件困扰着我们整个团队的大事儿，因为当时在国内很少有用 UDP 作为底层传输协议的。UDP 虽然传输快，但不可靠，尤其是在用户的网络质量很差的情况下，基本无法保障音视频的服务质量。</p><p>当时能想到的解决方案是，如果采用 UDP 作为底层传输协议，那就使用 RUDP（可靠性 UDP），只有这样才能保障传输过程中不丢包。但有人提出反对意见，认为如果想不丢包，就该使用 TCP，因为 RUDP 可靠性做到极致就变成 TCP 了，那为什么不直接使用 TCP 呢？</p><p>面对这种情况，2019 年的你会做何种选择呢？UDP 还是 TCP？你能拿出让人真正信服的理由吗？</p><p>现在让我告诉你正确答案：<strong>必须使用 UDP，必须使用 UDP，必须使用 UDP</strong>，重要的事情说三遍。</p><a id="more"></a><p>为什么一定要使用 UDP 呢？关于这个问题，你可以反向思考下，假如使用 TCP 会怎样呢？在极端网络情况下，TCP 为了传输的可靠性，它是如何做的呢？简单总结起来就是“发送 -&gt; 确认；超时 -&gt; 重发”的反复过程。</p><p>举个例子，A 与 B 通讯，A 首先向 B 发送数据，并启动一个定时器。当 B 收到 A 的数据后，B 需要给 A 回一个 ACK（确认）消息，反复这样操作，数据就源源不断地从 A 流向了 B。如果因为某些原因，A 一直收不到 B 的确认消息会怎么办呢？当 A 的定时器超时后，A 将重发之前没有被确认的消息，并重新设置定时器。</p><p>在 TCP 协议中，为了避免重传次数过多，定时器的超时时间会按 2 的指数增长。也就是说，假设第一次设置的超时时间是 1 秒，那么第二次就是 2 秒，第三次是 4 秒……第七次是 64 秒。如果第七次之后仍然超时，则断开 TCP 连接。你可以计算一下，从第一次超时，到最后断开连接，这之间一共经历了 2 分 07 秒，是不是很恐怖？</p><p>如果遇到前面的情况，A 与 B 之间的连接断了，那还算是个不错的情况，因为还可以再重新建立连接。但如果在第七次重传后，A 收到了 B 的 ACK 消息，那么 A 与 B 之间的数据传输的延迟就达到 1 分钟以上。对于这样的延迟，实时互动的直播系统是根本无法接受的。</p><p>基于以上的原因，在实现 <strong>实时互动直播系统的时候你必须使用 UDP 协议</strong> 。</p><h4 id="RTP-amp-RTCP"><a href="#RTP-amp-RTCP" class="headerlink" title="RTP &amp; RTCP"></a>RTP &amp; RTCP</h4><p>一般情况下，在实时互动直播系统传输音视频数据流时，我们并不直接将音视频数据流交给 UDP 传输，而是先给音视频数据加个 RTP 头，然后再交给 UDP 进行传输。为什么要这样做呢？</p><p>我们以视频帧为例，一个 I 帧的数据量是非常大的，最少也要几十 K（I/P/B 帧的概念我在前面《03 | 如何使用浏览器给自己拍照呢?》的文章中有过介绍）。而以太网的最大传输单元是多少呢？ 1.5K，所以要传输一个 I 帧需要几十个包。并且这几十个包传到对端后，还要重新组装成 I 帧，这样才能进行解码还原出一幅幅的图像。如果是我们自己实现的话，要完成这样的过程，至少需要以下几个标识。</p><blockquote><p>序号：用于标识传输包的序号，这样就可以知道这个包是第几个分片了。</p><p>起始标记：记录分帧的第一个 UDP 包。</p><p>结束标记：记录分帧的最后一个 UDP 包。</p></blockquote><p>有了上面这几个标识字段，我们就可以在发送端进行拆包，在接收端将视频帧重新再组装起来了。</p><h5 id="RTP-协议"><a href="#RTP-协议" class="headerlink" title="RTP 协议"></a>RTP 协议</h5><p>其实，这样的需求在很早之前就已经有了。因此，人们专门定义了一套规范，它就是 RTP 协议。下面让我们来详细看一下 RTP 协议吧。</p><p>如图所示，RTP 协议非常简单，我这里按字段的重要性从高往低的顺序讲解一下。</p><blockquote><p><strong>sequence number</strong>：序号，用于记录包的顺序。这与上面我们自己实现拆包、组包是同样的道理。</p><p><strong>timestamp</strong>：时间戳，同一个帧的不同分片的时间戳是相同的。这样就省去了前面所讲的 <strong>起始标记</strong> 和 <strong>结束标记</strong>。一定要记住，<strong>不同帧的时间戳肯定是不一样的</strong>。</p><p><strong>PT</strong>：Payload Type，数据的负载类型。音频流的 PT 值与视频的 PT 值是不同的，通过它就可以知道这个包存放的是什么类型的数据。</p><p>……</p></blockquote><p>这里，我并没有将 RTP 协议头中的所有字段的详细说明都列在这儿，如果你想了解所有字段的含义，可以到参考一节查看其他字段的含义。需要注意的是，这里没有将它们列出来并不代表它们不重要。恰恰相反，如果你想做音视频传输相关的工作，RTP 头中的每个字段的含义你都必须全部清楚。</p><p>知道了上面这些字段的含义后，下面我们还是来看一个具体的例子吧！假设你从网上接收到一组音视频数据，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:98,seq:13,ts:1122334455,ssrc=2345&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:111,seq:14,ts:1122334455,ssrc=888&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:98,seq:14,ts:1122334455,ssrc=2345&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:111,seq:15,ts:1122334455,ssrc=888&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:98,seq:15,ts:1122334455,ssrc=2345&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:111,seq:16,ts:1122334455,ssrc=888&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:98,seq:16,ts:1122334455,ssrc=2345&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:111,seq:17,ts:1122334455,ssrc=888&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:98,seq:17,ts:1122334455,ssrc=2345&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:111,seq:18,ts:1122334455,ssrc=888&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:98,seq:18,ts:1122334455,ssrc=2345&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:111,seq:19,ts:1122334455,ssrc=888&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:98,seq:19,ts:1122334455,ssrc=2345&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=0,PT:111,seq:20,ts:1122334455,ssrc=888&#125;,</span><br><span class="line">&#123;V=2,P=0,X=0,CC=0,M=1,PT:98,seq:20,ts:1122334455,ssrc=2345&#125;,</span><br></pre></td></tr></table></figure><p>假设 PT=98 是视频数据，PT=111 是音频数据，那么按照上面的规则你是不是很容易就能将视频帧组装起来呢？</p><h5 id="RTCP-协议"><a href="#RTCP-协议" class="headerlink" title="RTCP 协议"></a>RTCP 协议</h5><p>在使用 RTP 包传输数据时，难免会发生丢包、乱序、抖动等问题，下面我们来看一下使用的网络一般都会在什么情况下出现问题：</p><blockquote><p>网络线路质量问题引起丢包率高;</p><p>传输的数据超过了带宽的负载引起的丢包问题;</p><p>信号干扰（信号弱）引起的丢包问题;</p><p>跨运营商引入的丢包问题;</p><p>……</p></blockquote><p>WebRTC 对这些问题在底层都有相应的处理策略，但在处理这些问题之前，它首先要让各端都知道它们自己的网络质量到底是怎样的，这就是 RTCP 的作用。</p><p><strong>RTCP 有两个最重要的报文：RR（Reciever Report）和 SR(Sender Report)。通过这两个报文的交换，各端就知道自己的网络质量到底如何了。</strong></p><p>RTCP 支持的所有报文及其含义可以查看文章最后所附的参考一节。这里我们以 SR 报文为例，看看 SR 报文中都包括哪些信息。</p><p>下面我就简要说明一下该报文中字段的含义：</p><blockquote><p>V=2，指报文的版本。</p><p>P，表示填充位，如果该位置 1，则在 RTCP 报文的最后会有填充字节（内容是按字节对齐的）。</p><p>RC，全称 Report Count，指 RTCP 报文中接收报告的报文块个数。</p><p>PT=200，Payload Type，也就是说 SR 的值为 200。</p><p>……</p></blockquote><p>与 RTP 协议头一样，上面只介绍了 RTCP 头字段的含义，至于其他每个字段的含义请查看参考一节。同样的，对于 RTCP 头中的每个字段也必须都非常清楚，只有这样以后你在看 WebRTC 带宽评估相关的代码时，才不至于晕头转向。从上图中我们可以了解到，SR 报文分成三部分：Header、Sender info 和 Report block。在 NTP 时间戳之上的部分为 SR 报文的 Header 部分，SSRC_1 字段之上到 Header 之间的部分为 Sender info 部分，剩下的就是一个一个的 Report Block 了。那这每一部分是用于干什么的呢？</p><blockquote><p>Header 部分用于标识该报文的类型，比如是 SR 还是 RR。</p><p>Sender info 部分用于指明作为发送方，到底发了多少包。</p><p>Report block 部分指明发送方作为接收方时，它从各个 SSRC 接收包的情况。</p></blockquote><p>通过以上的分析，你可以发现 SR 报文并不仅是指发送方发了多少数据，它还报告了作为接收方，它接收到的数据的情况。当发送端收到对端的接收报告时，它就可以根据接收报告来评估它与对端之间的网络质量了，随后再根据网络质量做传输策略的调整。</p><p><strong>SR</strong> 报文与 <strong>RR</strong> 报文无疑是 RTCP 协议中最重要的两个报文，不过 RTCP 中的其他报文也都非常重要的，如果你想学好 WebRTC ，那么 RTCP 中的每个报文你都必须掌握。</p><p>比如，RTCP 类型为 206、子类型为 4 的 FIR 报文，其含义是 Full Intra Request (FIR) Command，即 <strong>完整帧请求</strong> 命令。它起什么作用？又在什么时候使用呢？</p><p>该报文也是一个特别关键的报文，我为什么这么说呢？试想一下，在一个房间里有 3 个人进行音视频聊天，然后又有一个人加入到房间里，这时如果不做任何处理的话，那么第四个人进入到房间后，在一段时间内很难直接看到其他三个人的视频画面了，这是为什么呢？</p><p>原因就在于解码器在解码时有一个上下文。在该上下文中，必须先拿到一个 IDR 帧之后才能将其后面的 P 帧、B 帧进行解码。也就是说，在没有 IDR 帧的情况下，对于收到的 P 帧、B 帧解码器只能干瞪眼了。</p><p>如何解决这个问题呢？这就引出了 FIR 报文。当第四个人加入到房间后，它首先发送 FIR 报文，当其他端收到该报文后，便立即产生各自的 IDR 帧发送给新加入的人，这样当新加入的人拿到房间中其他的 IDR 帧后，它的解码器就会解码成功，于是其他人的画面也就一下子全部展示出来了。所以你说它是不是很重要呢？</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;WebRTC 技术是激烈的开放的 Web 战争中一大突破。- Brendan Eich, inventor of Java&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;UDP-还是-TCP？&quot;&gt;&lt;a href=&quot;#UDP-还是-TCP？&quot; class=&quot;headerlink&quot; title=&quot;UDP 还是 TCP？&quot;&gt;&lt;/a&gt;UDP 还是 TCP？&lt;/h4&gt;&lt;p&gt;如果抛开 WebRTC，让你自己实现一套实时互动直播系统，在选择网络传输协议时，你会选择使用 UDP 协议还是 TCP 协议呢？&lt;/p&gt;
&lt;p&gt;这个问题在 2011 年至 2012 年一直是一件困扰着我们整个团队的大事儿，因为当时在国内很少有用 UDP 作为底层传输协议的。UDP 虽然传输快，但不可靠，尤其是在用户的网络质量很差的情况下，基本无法保障音视频的服务质量。&lt;/p&gt;
&lt;p&gt;当时能想到的解决方案是，如果采用 UDP 作为底层传输协议，那就使用 RUDP（可靠性 UDP），只有这样才能保障传输过程中不丢包。但有人提出反对意见，认为如果想不丢包，就该使用 TCP，因为 RUDP 可靠性做到极致就变成 TCP 了，那为什么不直接使用 TCP 呢？&lt;/p&gt;
&lt;p&gt;面对这种情况，2019 年的你会做何种选择呢？UDP 还是 TCP？你能拿出让人真正信服的理由吗？&lt;/p&gt;
&lt;p&gt;现在让我告诉你正确答案：&lt;strong&gt;必须使用 UDP，必须使用 UDP，必须使用 UDP&lt;/strong&gt;，重要的事情说三遍。&lt;/p&gt;
    
    </summary>
    
      <category term="WebRTC" scheme="http://xiaolong.li/categories/WebRTC/"/>
    
    
      <category term="RTP" scheme="http://xiaolong.li/tags/RTP/"/>
    
      <category term="RTCP" scheme="http://xiaolong.li/tags/RTCP/"/>
    
      <category term="WebRTC" scheme="http://xiaolong.li/tags/WebRTC/"/>
    
  </entry>
  
  <entry>
    <title>正向代理和反向代理的区别</title>
    <link href="http://xiaolong.li/2021/02/19/The-difference-between-forward-and-reverse-proxy/"/>
    <id>http://xiaolong.li/2021/02/19/The-difference-between-forward-and-reverse-proxy/</id>
    <published>2021-02-19T05:32:50.000Z</published>
    <updated>2021-08-31T11:34:21.830Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h4 id="什么是代理服务器？"><a href="#什么是代理服务器？" class="headerlink" title="什么是代理服务器？"></a>什么是代理服务器？</h4><p>所谓代理服务器就是位于发起请求的客户端与原始服务器端之间的一台跳板服务器，正向代理可以隐藏客户端，反向代理可以隐藏原始服务器。</p><a id="more"></a><h4 id="正向代理"><a href="#正向代理" class="headerlink" title="正向代理"></a>正向代理</h4><p>正向代理（Forward Proxy）类似一个跳板机，代理访问外部资源</p><p>比如我们国内访问谷歌，直接访问访问不到，我们可以通过一个正向代理服务器，请求发到代理服，代理服务器能够访问谷歌，这样由代理去谷歌取到返回数据，再返回给我们，这样我们就能访问谷歌了</p><p><img src="/images/network/2021-02-19-forward-proxy.jpg" alt="image" title="正向代理"></p><h5 id="正向代理的用途"><a href="#正向代理的用途" class="headerlink" title="正向代理的用途"></a>正向代理的用途</h5><blockquote><p>（1）访问原来无法访问的资源，如google</p><p>（2）可以做缓存，加速访问资源</p><p>（3）对客户端访问授权，上网进行认证</p><p>（4）代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息</p></blockquote><h4 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h4><p>反向代理（Reverse Proxy）实际运行方式是指以代理服务器来接受 internet 上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 internet 上请求连接的客户端，此时代理服务器对外就表现为一个服务器。</p><p><img src="/images/network/2021-02-19-reverse-proxy.jpg" alt="image" title="反向代理"></p><h5 id="反向代理的作用"><a href="#反向代理的作用" class="headerlink" title="反向代理的作用"></a>反向代理的作用</h5><blockquote><p>（1）保证内网的安全，阻止web攻击，大型网站，通常将反向代理作为公网访问地址，Web服务器是内网</p><p>（2）负载均衡，通过反向代理服务器来优化网站的负载</p></blockquote><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><blockquote class="blockquote-center"><p>正向代理即是客户端代理，代理客户端，服务端不知道实际发起请求的客户端</p><p>反向代理即是服务端代理，代理服务端，客户端不知道实际提供服务的服务端</p></blockquote><p>正向代理中，proxy 和 client 同属一个 LAN，对 server 透明<br>反向代理中，proxy 和 server 同属一个 LAN，对 client 透明</p><p>实际上 proxy 在两种代理中做的事都是代为收发请求和响应，不过从结构上来看正好左右互换了下，所以把后出现的那种代理方式叫成了反向代理</p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;什么是代理服务器？&quot;&gt;&lt;a href=&quot;#什么是代理服务器？&quot; class=&quot;headerlink&quot; title=&quot;什么是代理服务器？&quot;&gt;&lt;/a&gt;什么是代理服务器？&lt;/h4&gt;&lt;p&gt;所谓代理服务器就是位于发起请求的客户端与原始服务器端之间的一台跳板服务器，正向代理可以隐藏客户端，反向代理可以隐藏原始服务器。&lt;/p&gt;
    
    </summary>
    
      <category term="网络" scheme="http://xiaolong.li/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="正向代理" scheme="http://xiaolong.li/tags/%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86/"/>
    
      <category term="反向代理" scheme="http://xiaolong.li/tags/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"/>
    
      <category term="Nginx" scheme="http://xiaolong.li/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>Linux国内各大源站</title>
    <link href="http://xiaolong.li/2021/01/18/internal-linux-mirrors-website/"/>
    <id>http://xiaolong.li/2021/01/18/internal-linux-mirrors-website/</id>
    <published>2021-01-18T02:14:49.000Z</published>
    <updated>2021-08-15T16:16:16.960Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h5 id="企业源："><a href="#企业源：" class="headerlink" title="企业源："></a>企业源：</h5><p>阿里云开源镜像站： <a href="http://mirrors.aliyun.com/" target="_blank" rel="noopener">http://mirrors.aliyun.com/</a><br>搜狐开源镜像站：<a href="http://mirrors.sohu.com/" target="_blank" rel="noopener">http://mirrors.sohu.com/</a><br>网易开源镜像站：<a href="http://mirrors.163.com/" target="_blank" rel="noopener">http://mirrors.163.com/</a></p><a id="more"></a><h5 id="教育源："><a href="#教育源：" class="headerlink" title="教育源："></a>教育源：</h5><p>重庆大学：<br><a href="http://mirrors.cqu.edu.cn/" target="_blank" rel="noopener">http://mirrors.cqu.edu.cn/</a><br>北京理工大学：<br><a href="http://mirror.bit.edu.cn" target="_blank" rel="noopener">http://mirror.bit.edu.cn</a> (IPv4 only)<br><a href="http://mirror.bit6.edu.cn" target="_blank" rel="noopener">http://mirror.bit6.edu.cn</a> (IPv6 only)<br>北京交通大学：<br><a href="http://mirror.bjtu.edu.cn" target="_blank" rel="noopener">http://mirror.bjtu.edu.cn</a> (IPv4 only)<br><a href="http://mirror6.bjtu.edu.cn" target="_blank" rel="noopener">http://mirror6.bjtu.edu.cn</a> (IPv6 only)<br><a href="http://debian.bjtu.edu.cn" target="_blank" rel="noopener">http://debian.bjtu.edu.cn</a> (IPv4+IPv6)<br>兰州大学：<a href="http://mirror.lzu.edu.cn/" target="_blank" rel="noopener">http://mirror.lzu.edu.cn/</a><br>厦门大学：<a href="http://mirrors.xmu.edu.cn/" target="_blank" rel="noopener">http://mirrors.xmu.edu.cn/</a><br>上海交通大学：<br><a href="http://ftp.sjtu.edu.cn/" target="_blank" rel="noopener">http://ftp.sjtu.edu.cn/</a> (IPv4 only)<br><a href="http://ftp6.sjtu.edu.cn" target="_blank" rel="noopener">http://ftp6.sjtu.edu.cn</a> (IPv6 only)<br>清华大学：<br><a href="http://mirrors.tuna.tsinghua.edu.cn/" target="_blank" rel="noopener">http://mirrors.tuna.tsinghua.edu.cn/</a> (IPv4+IPv6)<br><a href="http://mirrors.6.tuna.tsinghua.edu.cn/" target="_blank" rel="noopener">http://mirrors.6.tuna.tsinghua.edu.cn/</a> (IPv6 only)<br><a href="http://mirrors.4.tuna.tsinghua.edu.cn/" target="_blank" rel="noopener">http://mirrors.4.tuna.tsinghua.edu.cn/</a> (IPv4 only)<br>天津大学：<a href="http://mirror.tju.edu.cn/" target="_blank" rel="noopener">http://mirror.tju.edu.cn/</a><br>中国科学技术大学：<br><a href="http://mirrors.ustc.edu.cn/" target="_blank" rel="noopener">http://mirrors.ustc.edu.cn/</a> (IPv4+IPv6)<br><a href="http://mirrors4.ustc.edu.cn/" target="_blank" rel="noopener">http://mirrors4.ustc.edu.cn/</a><br><a href="http://mirrors6.ustc.edu.cn/" target="_blank" rel="noopener">http://mirrors6.ustc.edu.cn/</a><br>西南大学：<a href="http://linux.swu.edu.cn/swudownload/Distributions/" target="_blank" rel="noopener">http://linux.swu.edu.cn/swudownload/Distributions/</a><br>东北大学：<br><a href="http://mirror.neu.edu.cn/" target="_blank" rel="noopener">http://mirror.neu.edu.cn/</a> (IPv4 only)<br><a href="http://mirror.neu6.edu.cn/" target="_blank" rel="noopener">http://mirror.neu6.edu.cn/</a> (IPv6 only)<br>电子科技大学：<a href="http://ubuntu.uestc.edu.cn/" target="_blank" rel="noopener">http://ubuntu.uestc.edu.cn/</a><br>青岛大学：<a href="http://mirror.qdu.edu.cn/" target="_blank" rel="noopener">http://mirror.qdu.edu.cn/</a><br>开源中国社区 <a href="http://mirrors.oss.org.cn/" target="_blank" rel="noopener">http://mirrors.oss.org.cn/</a><br>大连东软信息学院 <a href="http://mirrors.neusoft.edu.cn/" target="_blank" rel="noopener">http://mirrors.neusoft.edu.cn/</a><br>华中科技大学 <a href="http://mirrors.hust.edu.cn/" target="_blank" rel="noopener">http://mirrors.hust.edu.cn/</a><br>中山大学 <a href="http://mirrors.sysu.edu.cn/" target="_blank" rel="noopener">http://mirrors.sysu.edu.cn/</a><br>清华大学学生网管会 <a href="http://mirrors.tuna.tsinghua.edu.cn/" target="_blank" rel="noopener">http://mirrors.tuna.tsinghua.edu.cn/</a><br>浙江大学 <a href="http://mirrors.zju.edu.cn/web/" target="_blank" rel="noopener">http://mirrors.zju.edu.cn/web/</a></p><p>台湾淡江大学 <a href="http://ftp.tku.edu.tw/Linux/" target="_blank" rel="noopener">http://ftp.tku.edu.tw/Linux/</a></p><p>Linux运维派开源镜像 <a href="http://mirrors.skyshe.cn/" target="_blank" rel="noopener">http://mirrors.skyshe.cn/</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;企业源：&quot;&gt;&lt;a href=&quot;#企业源：&quot; class=&quot;headerlink&quot; title=&quot;企业源：&quot;&gt;&lt;/a&gt;企业源：&lt;/h5&gt;&lt;p&gt;阿里云开源镜像站： &lt;a href=&quot;http://mirrors.aliyun.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://mirrors.aliyun.com/&lt;/a&gt;&lt;br&gt;搜狐开源镜像站：&lt;a href=&quot;http://mirrors.sohu.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://mirrors.sohu.com/&lt;/a&gt;&lt;br&gt;网易开源镜像站：&lt;a href=&quot;http://mirrors.163.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://mirrors.163.com/&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Kafka-Cluster-building</title>
    <link href="http://xiaolong.li/2020/11/11/Kafka-Cluster-building/"/>
    <id>http://xiaolong.li/2020/11/11/Kafka-Cluster-building/</id>
    <published>2020-11-11T11:06:08.000Z</published>
    <updated>2021-08-07T16:32:49.021Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p><a href="https://cloud.tencent.com/developer/article/1023898" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1023898</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;p&gt;&lt;a href=&quot;https://cloud.tencent.com/developer/article/1023898&quot; target=&quot;_blank&quot; rel=&quot;noop
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>zookeeper集群搭建</title>
    <link href="http://xiaolong.li/2020/11/11/Zookeeper-Cluster-building/"/>
    <id>http://xiaolong.li/2020/11/11/Zookeeper-Cluster-building/</id>
    <published>2020-11-11T11:05:30.000Z</published>
    <updated>2021-08-07T16:32:49.024Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h4 id="为什么-zookeeper-集群的节点数是奇数"><a href="#为什么-zookeeper-集群的节点数是奇数" class="headerlink" title="为什么 zookeeper 集群的节点数是奇数"></a>为什么 zookeeper 集群的节点数是奇数</h4><p>zookeeper 集群通常是用来对用户的分布式应用程序提供协调服务的，为了保证数据的一致性，对 zookeeper 集群进行了这样三种角色划分：leader、follower、observer分别对应着主、从、观察者。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">leader : 负责进行投票的发起和决议，更新系统状态。</span><br><span class="line">follower : 用于接收客户端请求并向客户端返回结果以及在选举过程中参与投票。</span><br><span class="line">observer : 通常是针对于查询操作做负载的。 observer 与 follower 节点最大的不同在于 observer 没有投票权，在客户端发起的增删改操中， leader 节点是不会把消息传递给 observer 让其投票的。但是查询操作跟 follower 一样，客户端的查询到了 observer 节点， observer 节点会去访问 leader 节点取最新的数据然后返回给客户端。</span><br></pre></td></tr></table></figure><p>集群可以保证在每台机器数据保持一致的情况下，客户端每次发起的查询操作，集群节点都能返回同样的结果。但是对于客户端发起的增、删、改等能改变数据的操作，如果集群中的多台机器各自修改数据，那么就无法保证数据的一致性。</p><p>那么，对于增、删、改操作， zookeeper 集群规定只有 leader 节点才有权利去执行修改数据的操作，而 follower 节点即使接收到客户端发起的数据修改操作，也要将其转交给 leader 来处理， leader节点接收到修改数据的请求后，会向所有 follower 节点广播一条消息，让其执行操作， follower 节点执行完后，需要向 leader 节点回复执行结果。当 leader 节点收到半数以上的 follower 节点的确认消息后，便会判定该操作执行完毕，然后向所有 follower 节点广播该操作已经生效。</p><p>所以在 zookeeper 集群中， leader 节点是不可缺少的， leader 节点也是由所有 follower 节点选举产生，而且只有一个。</p><p>//todo leader节点选取逻辑</p><blockquote><p>zookeeper 集群中 leader 的选取逻辑，要求 <strong>可用节点数量</strong> &gt; <strong>总节点数量 / 2</strong>，注意，这里是 <strong>&gt;</strong> ,并非 <strong>&gt;=</strong> 。 </p></blockquote><p>为什么集群节点数量要奇数个，主要从以下两个方面考虑。</p><h5 id="防脑裂导致集群不可用"><a href="#防脑裂导致集群不可用" class="headerlink" title="防脑裂导致集群不可用"></a>防脑裂导致集群不可用</h5><p>在一个 zookeeper 集群中，可以有多个 follower 和 observe 节点，但是有且只能有一个 leader 节点。如果 leader 节点不可用或者宕机，剩下的所有节点机器会投票产生新的 leader 节点。</p><p>集群脑裂: 一个集群由于网络不通或者其他原因分裂成多个小集群的现象。</p><h5 id="容错率和成本控制"><a href="#容错率和成本控制" class="headerlink" title="容错率和成本控制"></a>容错率和成本控制</h5><p><a href="https://www.cnblogs.com/lishiqi-blog/p/12314111.html" target="_blank" rel="noopener">https://www.cnblogs.com/lishiqi-blog/p/12314111.html</a></p><p><a href="https://www.cnblogs.com/ysocean/p/9860529.html" target="_blank" rel="noopener">https://www.cnblogs.com/ysocean/p/9860529.html</a></p><p><a href="https://blog.csdn.net/jiangxiulilinux/article/details/96433560" target="_blank" rel="noopener">https://blog.csdn.net/jiangxiulilinux/article/details/96433560</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h4 id=&quot;为什么-zookeeper-集群的节点数是奇数&quot;&gt;&lt;a href=&quot;#为什么-zookeeper-集群的节点数是奇数&quot; class=&quot;headerlink&quot; tit
      
    
    </summary>
    
      <category term="教程" scheme="http://xiaolong.li/categories/%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="zookeeper" scheme="http://xiaolong.li/tags/zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>Introduction-to-h264-frame</title>
    <link href="http://xiaolong.li/2020/10/21/Introduction-to-h264-frame/"/>
    <id>http://xiaolong.li/2020/10/21/Introduction-to-h264-frame/</id>
    <published>2020-10-21T02:29:01.000Z</published>
    <updated>2021-08-07T16:32:49.021Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;
      
    
    </summary>
    
    
  </entry>
  
</feed>
